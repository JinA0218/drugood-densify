{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from main_merck_all_real_mixup import get_dataset\n",
    "from utils import set_seed, get_optimizer, InfIterator\n",
    "from arguments import get_arguments\n",
    "from main_origin import get_model\n",
    "from setenc import get_mixer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=Thu May 22 05:02:01 2025\n",
      "╒═════════════════════════════════════════════════════════════════════════════╕\n",
      "│ NVITOP 1.5.0      Driver Version: 535.183.01      CUDA Driver Version: 12.2 │\n",
      "├───────────────────────────────┬──────────────────────┬──────────────────────┤\n",
      "│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ Volatile Uncorr. ECC │\n",
      "│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │\n",
      "╞═══════════════════════════════╪══════════════════════╪══════════════════════╡\n",
      "│\u001b[31m   0  RTX A5000           Off  \u001b[0m│\u001b[31m 00000000:1B:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 30%   24C    P8    15W / 230W \u001b[0m│\u001b[31m  23.16GiB / 23.99GiB \u001b[0m│\u001b[31m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[31m   1  RTX A5000           Off  \u001b[0m│\u001b[31m 00000000:1C:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 30%   24C    P8    16W / 230W \u001b[0m│\u001b[31m  22.80GiB / 23.99GiB \u001b[0m│\u001b[31m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[33m   2  RTX A5000           Off  \u001b[0m│\u001b[33m 00000000:1D:00.0 Off \u001b[0m│\u001b[33m                  N/A \u001b[0m│\n",
      "│\u001b[33m 30%   24C    P8    13W / 230W \u001b[0m│\u001b[33m  12656MiB / 23.99GiB \u001b[0m│\u001b[33m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[32m   3  RTX A5000           Off  \u001b[0m│\u001b[32m 00000000:1E:00.0 Off \u001b[0m│\u001b[32m                  N/A \u001b[0m│\n",
      "│\u001b[32m 30%   31C    P2    59W / 230W \u001b[0m│\u001b[32m  299.6MiB / 23.99GiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[32m   4  RTX A5000           Off  \u001b[0m│\u001b[32m 00000000:89:00.0 Off \u001b[0m│\u001b[32m                  N/A \u001b[0m│\n",
      "│\u001b[32m 30%   23C    P8    17W / 230W \u001b[0m│\u001b[32m    192KiB / 23.99GiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[32m   5  RTX A5000           Off  \u001b[0m│\u001b[32m 00000000:8A:00.0 Off \u001b[0m│\u001b[32m                  N/A \u001b[0m│\n",
      "│\u001b[32m 30%   24C    P8    16W / 230W \u001b[0m│\u001b[32m    192KiB / 23.99GiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[32m   6  RTX A5000           Off  \u001b[0m│\u001b[32m 00000000:8B:00.0 Off \u001b[0m│\u001b[32m                  N/A \u001b[0m│\n",
      "│\u001b[32m 30%   23C    P8    16W / 230W \u001b[0m│\u001b[32m    192KiB / 23.99GiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[33m   7  RTX A5000           Off  \u001b[0m│\u001b[33m 00000000:8C:00.0 Off \u001b[0m│\u001b[33m                  N/A \u001b[0m│\n",
      "│\u001b[33m 30%   33C    P2    57W / 230W \u001b[0m│\u001b[33m  10002MiB / 23.99GiB \u001b[0m│\u001b[33m      0%      Default \u001b[0m│\n",
      "╘═══════════════════════════════╧══════════════════════╧══════════════════════╛\n",
      "\u001b[1m\u001b[36m[ CPU: ██████████████████████████████ MAX ]\u001b[0m  \u001b[1m( Load Average: 61.42 57.10 55.87 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: ███████ 23.2%       USED: 84.67GiB ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: ██████████████████████ MAX ]\u001b[0m\n",
      "\n",
      "╒══════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Processes:                                                      \u001b[1m\u001b[35mjinakim\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32mai20\u001b[0m │\n",
      "│ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM      TIME  COMMAND      │\n",
      "╞══════════════════════════════════════════════════════════════════════════════╡\n",
      "│\u001b[31m   0\u001b[0m \u001b[2m   7871 C   yumin 23.16GiB   0     0   0.0   2.1  44:13:32  /c1/yumin/..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[31m   1\u001b[0m \u001b[2m   7873 C   yumin 22.80GiB   0     0   0.0   3.0  44:13:32  /c1/yumin/..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[33m   2\u001b[0m \u001b[2m 471231 C   yumin 12648MiB   0     0   0.0   0.4  13:44:40  /c1/yumin/..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[32m   3\u001b[0m  687566 C jinakim 294.0MiB   0     0  1843   2.3      1:27  /c2/jinaki.. │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[33m   7\u001b[0m \u001b[2m   4571 C  namsan  5038MiB   1     0   0.0   1.1  45:34:34  /c2/namsan..\u001b[0m │\n",
      "│\u001b[33m   7\u001b[0m \u001b[2m 456870 C  namsan  4956MiB   0     0   0.0   1.2  15:16:12  /c2/namsan..\u001b[0m │\n",
      "╘══════════════════════════════════════════════════════════════════════════════╛\n",
      "\u001b[1m\u001b[31mERROR:\u001b[0m Failed to initialize `curses` (curs_set() returned ERR)\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y_hat, y, test=False):\n",
    "    return F.mse_loss(y.cuda().squeeze(), y_hat.cuda().squeeze())\n",
    "\n",
    "def test_ood(args, dataloader, contextloader=None, model=None, mixer_phi=None, embed_type=None): # , n_t=10, n_c=5\n",
    "    model.eval()\n",
    "    mixer_phi.eval()\n",
    "    embedding_list = []\n",
    "    label_list= []\n",
    "    loss_list = []\n",
    "    # print('model ', model)\n",
    "    # print('mixer_phi ', mixer_phi)\n",
    "    \n",
    "    if embed_type == \"ood1_none\" or embed_type == \"ood2_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                # if i == n_t: # NOTE RUNNING FULL DATASET\n",
    "                #     break\n",
    "                \n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 't_x.pt')\n",
    "                #     torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    \n",
    "    mse = sum(losses) / counts\n",
    "    return mse, embedding_list, label_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_measure_ood_test(args, model, mixer_phi, embed_type):\n",
    "    assert args.model_no_context == False\n",
    "    \n",
    "    args.embed_test = 'lastlayer_ours_best'\n",
    "    \n",
    "    path = f\"/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/{args.embed_test}_\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/{args.embed_test}_{args.sencoder}_{args.dataset}_{args.vec_type}_{args.mvalid_dataset}_{embed_type}.npz'\n",
    "    \n",
    "    if args.seed != 42:\n",
    "        f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/{args.embed_test}_{args.sencoder}_{args.dataset}_{args.vec_type}_{args.mvalid_dataset}_{embed_type}_{args.seed}.npz'\n",
    "        \n",
    "    \n",
    "    \n",
    "    if os.path.exists(f_path):\n",
    "        print(f\"⏩ {f_path} already exists. Skipping...\") \n",
    "        return\n",
    "    \n",
    "    if args.seed == 42:\n",
    "        print('### seed ', args.seed)\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        print('### seed ', args.seed)\n",
    "        set_seed(args.seed)\n",
    "    args.batch_size = 1\n",
    "    args.tsne_plot = True # because of get_dataset\n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    args.specify_ood_dataset = [d for d in all_candidates if d != args.dataset]\n",
    "    trainloader_test, _, mvalidloader_test, _, contextloader_test, ood1_trainloader_test, ood2_trainloader_test = get_dataset(args=args, test=True)\n",
    "    \n",
    "    assert \"ood\" in embed_type\n",
    "    \n",
    "    if 'ood1' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test_ood(args=args, dataloader=ood1_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type)\n",
    "    elif 'ood2' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test_ood(args=args, dataloader=ood2_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type)\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    all_embeddings = torch.cat(embedding_list, dim=0)\n",
    "    all_labels = np.concatenate(label_list, axis=0)\n",
    "    all_losses = torch.cat(loss_list, dim=0)\n",
    "\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_losses = torch.tensor(all_losses)\n",
    "                \n",
    "    all_embeddings_np = all_embeddings.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    all_losses_np = all_losses.numpy()\n",
    "    \n",
    "    loss_mean = all_losses_np.mean()\n",
    "    loss_var = all_losses_np.var(ddof=0)\n",
    "    loss_med = np.median(all_losses_np)\n",
    "    \n",
    "    np.savez(f_path, embeddings=all_embeddings_np, labels=all_labels_np, losses=all_losses_np, loss_mean=loss_mean, loss_var=loss_var, loss_med=loss_med)\n",
    "    \n",
    "    print(f'{args.dataset} {args.vec_type}=======')\n",
    "    if 'ood1' in embed_type:\n",
    "        print('ood1 ', args.specify_ood_dataset[0])\n",
    "    elif 'ood2' in embed_type:\n",
    "        print('ood2 ', args.specify_ood_dataset[1])\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    print('loss_mean ', loss_mean)\n",
    "    print('loss_var ', loss_var)\n",
    "    print('loss_med ', loss_med)\n",
    "    \n",
    "    print(f'>>> saved {f_path}')\n",
    "    \n",
    "    if 'ood1' in embed_type:\n",
    "        ood1_trainloader_test._iterator._shutdown_workers()\n",
    "    elif 'ood2' in embed_type:\n",
    "        ood2_trainloader_test._iterator._shutdown_workers()\n",
    "    else:\n",
    "        trainloader_test._iterator._shutdown_workers()\n",
    "        if 'context' in embed_type:\n",
    "            contextloader_test._iterator._shutdown_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_ood_test(data):\n",
    "    model = data['model']\n",
    "    mixer_phi = data['mixer_phi']\n",
    "    optimizer = data['optimizer']\n",
    "    # mixer_optimizer = data['mixer_optimizer']\n",
    "    \n",
    "    ltmse, lvmse, vmse, tmse = data['ltmse'], data['lvmse'], data['vmse'], data['tmse ']\n",
    "    \n",
    "    print('>> ltmse ', ltmse)\n",
    "    print('>> tmse ', tmse)\n",
    "    print('>> lvmse ', lvmse)\n",
    "    print('>> vmse ', vmse)\n",
    "    \n",
    "    args_ = data['args']\n",
    "\n",
    "    args = get_arguments()\n",
    "\n",
    "    for k, v in args_.items():\n",
    "        setattr(args, k, v)\n",
    "\n",
    "    os.environ['MIX_TYPE'] = 'MIXUP_BILEVEL'\n",
    "    if args.seed == 42:\n",
    "        print('### seed ', args.seed)\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        print('### seed ', args.seed)\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    model = get_model(args=args)\n",
    "    mixer_phi = get_mixer(args=args)\n",
    "    # optimizer = get_optimizer(optimizer=args.optimizer, model=model, lr=args.lr, wd=args.wd)\n",
    "    # optimizermixer = None if mixer_phi is None else get_optimizer(optimizer=args.optimizer, model=mixer_phi, lr=args.clr, wd=args.cwd)\n",
    "\n",
    "    model.load_state_dict(data['model'])\n",
    "    mixer_phi.load_state_dict(data['mixer_phi'])\n",
    "    # optimizer.load_state_dict(data['optimizer'])\n",
    "    # mixer_optimizer.load_state_dict(data['mixer_optimizer'])\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    mixer_phi = mixer_phi.to(args.device)\n",
    "    \n",
    "    # for (n_t, n_c) in [(5, 10), (5, 100), (10, 5), (10, 100), (100, 5), (100, 10)]:\n",
    "    \n",
    "    each_measure_ood_test(args, model, mixer_phi, \"ood1_none\") # , 500, 10\n",
    "    each_measure_ood_test(args, model, mixer_phi, \"ood2_none\") # , 500, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1'].pth\n",
      ">> ltmse  0.4400378761799082\n",
      ">> tmse  0.4400378761799082\n",
      ">> lvmse  0.38006476759910585\n",
      ">> vmse  0.38006476759910585\n",
      "### seed  42\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  42\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_692159/3650483332.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_losses = torch.tensor(all_losses)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.4942312\n",
      "loss_var  2.6640227\n",
      "loss_med  0.9404555\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none.npz\n",
      "### seed  42\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.1135063\n",
      "loss_var  1.8985587\n",
      "loss_med  0.50650084\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_0.pth\n",
      ">> ltmse  0.4400378761799082\n",
      ">> tmse  0.4400378761799082\n",
      ">> lvmse  0.38006476759910585\n",
      ">> vmse  0.38006476759910585\n",
      "### seed  0\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  0\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.4942312\n",
      "loss_var  2.6640227\n",
      "loss_med  0.9404555\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_0.npz\n",
      "### seed  0\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.1135063\n",
      "loss_var  1.8985587\n",
      "loss_med  0.50650084\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_0.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_1.pth\n",
      ">> ltmse  0.493261072267478\n",
      ">> tmse  0.493261072267478\n",
      ">> lvmse  0.37604954044024147\n",
      ">> vmse  0.37604954044024147\n",
      "### seed  1\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  1\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.6820334\n",
      "loss_var  3.5720327\n",
      "loss_med  0.96946883\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_1.npz\n",
      "### seed  1\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.0530947\n",
      "loss_var  1.5628799\n",
      "loss_med  0.51679105\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_1.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_2.pth\n",
      ">> ltmse  0.450061698957183\n",
      ">> tmse  0.450061698957183\n",
      ">> lvmse  0.3733809272448222\n",
      ">> vmse  0.3733809272448222\n",
      "### seed  2\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  2\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.2821281\n",
      "loss_var  2.029594\n",
      "loss_med  0.7737895\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_2.npz\n",
      "### seed  2\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.3242556\n",
      "loss_var  2.2772968\n",
      "loss_med  0.78806674\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_2.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_3.pth\n",
      ">> ltmse  0.4764181119748677\n",
      ">> tmse  0.4764181119748677\n",
      ">> lvmse  0.3964301427205404\n",
      ">> vmse  0.3964301427205404\n",
      "### seed  3\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  3\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.1867257\n",
      "loss_var  1.6507037\n",
      "loss_med  0.75282407\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_3.npz\n",
      "### seed  3\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.1736814\n",
      "loss_var  1.9610034\n",
      "loss_med  0.58167267\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_3.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_4.pth\n",
      ">> ltmse  0.458012872800298\n",
      ">> tmse  0.458012872800298\n",
      ">> lvmse  0.38078077634175617\n",
      ">> vmse  0.38078077634175617\n",
      "### seed  4\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  4\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.0406634\n",
      "loss_var  1.3502306\n",
      "loss_med  0.64710593\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_4.npz\n",
      "### seed  4\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.2465754\n",
      "loss_var  2.0815442\n",
      "loss_med  0.6814586\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_4.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_5.pth\n",
      ">> ltmse  0.44974054768346416\n",
      ">> tmse  0.44974054768346416\n",
      ">> lvmse  0.375997938712438\n",
      ">> vmse  0.375997938712438\n",
      "### seed  5\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  5\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.1104114\n",
      "loss_var  1.607022\n",
      "loss_med  0.6631253\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_5.npz\n",
      "### seed  5\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.0975707\n",
      "loss_var  1.8716595\n",
      "loss_med  0.5054086\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_5.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_6.pth\n",
      ">> ltmse  0.4357617714951957\n",
      ">> tmse  0.4357617714951957\n",
      ">> lvmse  0.3789832671483358\n",
      ">> vmse  0.3789832671483358\n",
      "### seed  6\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  6\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.3413512\n",
      "loss_var  2.1380072\n",
      "loss_med  0.8423054\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_6.npz\n",
      "### seed  6\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.0548855\n",
      "loss_var  1.876712\n",
      "loss_med  0.4209419\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_6.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_7.pth\n",
      ">> ltmse  0.4556522985448365\n",
      ">> tmse  0.4556522985448365\n",
      ">> lvmse  0.36681912938753763\n",
      ">> vmse  0.36681912938753763\n",
      "### seed  7\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  7\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.2018234\n",
      "loss_var  1.737366\n",
      "loss_med  0.7473371\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_7.npz\n",
      "### seed  7\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.1495553\n",
      "loss_var  2.060821\n",
      "loss_med  0.5024189\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_7.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_8.pth\n",
      ">> ltmse  0.4522987850066246\n",
      ">> tmse  0.4522987850066246\n",
      ">> lvmse  0.38148927489916484\n",
      ">> vmse  0.38148927489916484\n",
      "### seed  8\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  8\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.2835844\n",
      "loss_var  2.006739\n",
      "loss_med  0.7762666\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_8.npz\n",
      "### seed  8\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.2455968\n",
      "loss_var  2.156789\n",
      "loss_med  0.67718035\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_8.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_strans_nk1_bit_['3a4', 'cb1']_9.pth\n",
      ">> ltmse  0.4084597815459279\n",
      ">> tmse  0.4084597815459279\n",
      ">> lvmse  0.38501469095547997\n",
      ">> vmse  0.38501469095547997\n",
      "### seed  9\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "### seed  9\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood1  hivprot\n",
      "loss_mean  1.2931693\n",
      "loss_var  1.9669349\n",
      "loss_med  0.79810643\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood1_none_9.npz\n",
      "### seed  9\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      "nk1 bit=======\n",
      "ood2  dpp4\n",
      "loss_mean  1.2253219\n",
      "loss_var  1.9849474\n",
      "loss_med  0.65127873\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_OOD_FULL_TEST_MIXUP_BILEVEL/lastlayer_ours_best_strans_nk1_bit_['3a4', 'cb1']_ood2_none_9.npz\n",
      "\n",
      "🏁 All models loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory containing .pth files\n",
    "tsne_model_dir = '/c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/'\n",
    "os.makedirs(tsne_model_dir, exist_ok=True)\n",
    "# List all .pth files\n",
    "pth_files = sorted([f for f in os.listdir(tsne_model_dir) if f.endswith('.pth')])\n",
    "\n",
    "# Load each file\n",
    "for i, f in enumerate(pth_files):\n",
    "    # if i > 5:\n",
    "    #     break\n",
    "    file_path = os.path.join(tsne_model_dir, f)\n",
    "    print(f\"🚀 Loading {file_path}\")\n",
    "    \n",
    "    data = torch.load(file_path, map_location=\"cpu\")\n",
    "    \n",
    "    measure_ood_test(data)\n",
    "    # save_features(data)\n",
    "    # Now 'data' contains the loaded model or state dict or whatever was saved\n",
    "    # You can process it here if needed\n",
    "    # For example, just printing some keys if it's a checkpoint\n",
    "    # if isinstance(data, dict):\n",
    "    #     print(f\"✅ Loaded {f}: keys = {list(data.keys())}\")\n",
    "    # else:\n",
    "    #     print(f\"✅ Loaded {f}: type = {type(data)}\")\n",
    "\n",
    "print(\"\\n🏁 All models loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=Wed May 21 01:16:50 2025\n",
      "╒═════════════════════════════════════════════════════════════════════════════╕\n",
      "│ NVITOP 1.5.0      Driver Version: 535.183.01      CUDA Driver Version: 12.2 │\n",
      "├───────────────────────────────┬──────────────────────┬──────────────────────┤\n",
      "│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ Volatile Uncorr. ECC │\n",
      "│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │\n",
      "╞═══════════════════════════════╪══════════════════════╪══════════════════════╡\n",
      "│\u001b[31m   0  RTX A5000           Off  \u001b[0m│\u001b[31m 00000000:1B:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 41%   71C    P2   213W / 230W \u001b[0m│\u001b[31m  23.45GiB / 23.99GiB \u001b[0m│\u001b[31m     83%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[31m   1  RTX A5000           Off  \u001b[0m│\u001b[31m 00000000:1C:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 45%   62C    P2    71W / 230W \u001b[0m│\u001b[31m  22.80GiB / 23.99GiB \u001b[0m│\u001b[31m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[31m   2  RTX A5000           Off  \u001b[0m│\u001b[31m 00000000:1D:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 50%   75C    P2   221W / 230W \u001b[0m│\u001b[31m  18910MiB / 23.99GiB \u001b[0m│\u001b[31m    100%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[31m   3  RTX A5000           Off  \u001b[0m│\u001b[31m 00000000:1E:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 30%   53C    P2   229W / 230W \u001b[0m│\u001b[31m  20436MiB / 23.99GiB \u001b[0m│\u001b[31m    100%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[33m   4  RTX A5000           Off  \u001b[0m│\u001b[33m 00000000:89:00.0 Off \u001b[0m│\u001b[33m                  N/A \u001b[0m│\n",
      "│\u001b[33m 35%   61C    P2   140W / 230W \u001b[0m│\u001b[33m  19018MiB / 23.99GiB \u001b[0m│\u001b[33m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[33m   5  RTX A5000           Off  \u001b[0m│\u001b[33m 00000000:8A:00.0 Off \u001b[0m│\u001b[33m                  N/A \u001b[0m│\n",
      "│\u001b[33m 35%   60C    P2   134W / 230W \u001b[0m│\u001b[33m  19018MiB / 23.99GiB \u001b[0m│\u001b[33m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[31m   6  RTX A5000           Off  \u001b[0m│\u001b[31m 00000000:8B:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 30%   57C    P2   177W / 230W \u001b[0m│\u001b[31m  16794MiB / 23.99GiB \u001b[0m│\u001b[31m    100%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[33m   7  RTX A5000           Off  \u001b[0m│\u001b[33m 00000000:8C:00.0 Off \u001b[0m│\u001b[33m                  N/A \u001b[0m│\n",
      "│\u001b[33m 30%   36C    P2    57W / 230W \u001b[0m│\u001b[33m   6982MiB / 23.99GiB \u001b[0m│\u001b[33m      0%      Default \u001b[0m│\n",
      "╘═══════════════════════════════╧══════════════════════╧══════════════════════╛\n",
      "\u001b[1m\u001b[36m[ CPU: ████████████████████████████▋ 95%  ]\u001b[0m  \u001b[1m( Load Average: 72.50 76.09 77.40 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: █████████ 30.2%     USED: 102.5GiB ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: ▏ 0.1%                     ]\u001b[0m\n",
      "\n",
      "╒══════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Processes:                                                      \u001b[1m\u001b[35mjinakim\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32mai20\u001b[0m │\n",
      "│ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM      TIME  COMMAND      │\n",
      "╞══════════════════════════════════════════════════════════════════════════════╡\n",
      "│\u001b[31m   0\u001b[0m  313822 C jinakim 294.0MiB   0     0   0.0   0.2     12:40  /c2/jinaki.. │\n",
      "│\u001b[31m   0\u001b[0m \u001b[2m   7871 C   yumin 23.16GiB  74    78  99.1   2.2  16:28:22  /c1/yumin/..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[31m   1\u001b[0m \u001b[2m   7873 C   yumin 22.80GiB   0     0 102.6   3.2  16:28:22  /c1/yumin/..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[31m   2\u001b[0m \u001b[2m 221628 C dohyeon 18888MiB  98    35 108.0   2.5   3:04:12  python tra..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[31m   3\u001b[0m \u001b[2m 137083 C   yumin 20430MiB  99    42 121.5   0.7   5:36:57  /c1/yumin/..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[33m   4\u001b[0m \u001b[2m 307769 C jiongd+ 19012MiB  14    13  94.0   0.6     19:05  /c1/jiongd..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[33m   5\u001b[0m \u001b[2m 307776 C jiongd+ 19012MiB  23    22   0.0   0.6     19:05  /c1/jiongd..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[31m   6\u001b[0m  313824 C jinakim 276.0MiB   0     0   0.0   0.2     12:39  /c2/jinaki.. │\n",
      "│\u001b[31m   6\u001b[0m \u001b[2m 302951 C jiongd+ 16510MiB  67    37  83.5   0.5     20:06  python bea..\u001b[0m │\n",
      "├──────────────────────────────────────────────────────────────────────────────┤\n",
      "│\u001b[33m   7\u001b[0m \u001b[2m   4571 C  namsan  4990MiB   0     0   0.0   1.5  17:49:23  /c2/namsan..\u001b[0m │\n",
      "│\u001b[33m   7\u001b[0m \u001b[2m 263732 C  namsan  1984MiB   2     0   0.0   1.4   1:52:44  /c2/namsan..\u001b[0m │\n",
      "╘══════════════════════════════════════════════════════════════════════════════╛\n",
      "\u001b[1m\u001b[31mERROR:\u001b[0m Failed to initialize `curses` (curs_set() returned ERR)\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# # try:\n",
    "# #     import cupy as cp\n",
    "# #     from cuml.manifold import TSNE as cuTSNE\n",
    "# #     gpu_available = True\n",
    "# #     print(\"✅ Using GPU cuML TSNE\")\n",
    "# # except ImportError:\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# gpu_available = False\n",
    "# print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "#     groups[prefix].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined.pdf\")\n",
    "    \n",
    "#     # if \"dpp4_bit\" in save_path:\n",
    "#     #     continue\n",
    "#     # --- Skip if already exists ---\n",
    "#     if os.path.exists(save_path):\n",
    "#         print(f\"⏩ {save_path} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "#         #####\n",
    "#         if 'ood' in file_path:\n",
    "#             continue\n",
    "        \n",
    "#         # if 'train' not in file_path and 'context' not in file_path:\n",
    "#         #     continue\n",
    "#         #####\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "\n",
    "#         print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     # if gpu_available:\n",
    "#     #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "#     #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "#     #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "#     #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "#     # else:\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     import matplotlib.patches as mpatches\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Set global font\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     # Define color mapping\n",
    "#     color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}  # orange and blue\n",
    "#     colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "#     # Set point sizes\n",
    "#     sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Slight soft grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Hide axis labels but keep grid\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # --- Add better legend ---\n",
    "#     import matplotlib.lines as mlines\n",
    "\n",
    "#     # Define custom legend handles (use Line2D for circles)\n",
    "#     orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#     red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "#     # Add legend inside plot (upper right)\n",
    "#     plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "#             loc='upper right',  # inside the plot, top right\n",
    "#             framealpha=0.6,\n",
    "#             prop={'size': 12},\n",
    "#             handletextpad=0.4,\n",
    "#             borderpad=0.5)\n",
    "\n",
    "#     # Tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save figure\n",
    "#     plt.savefig(save_path, dpi=300)\n",
    "#     print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# # try:\n",
    "# #     import cupy as cp\n",
    "# #     from cuml.manifold import TSNE as cuTSNE\n",
    "# #     gpu_available = True\n",
    "# #     print(\"✅ Using GPU cuML TSNE\")\n",
    "# # except ImportError:\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# gpu_available = False\n",
    "# print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "    \n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "#     if 'ood' not in f:\n",
    "#         groups[prefix].append(f)\n",
    "    \n",
    "#     prefix_ = '_'.join(parts[:3])\n",
    "#     if prefix_ in prefix and 'ood' in f:\n",
    "#         groups[prefix].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all.pdf\")\n",
    "    \n",
    "#     # if \"dpp4_bit\" in save_path:\n",
    "#     #     continue\n",
    "#     # --- Skip if already exists ---\n",
    "#     if os.path.exists(save_path):\n",
    "#         print(f\"⏩ {save_path} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "#         if len(group_files) != 5:\n",
    "#             print('group_files ', len(group_files))\n",
    "#             continue\n",
    "#         #####\n",
    "#         # if 'ood' in file_path:\n",
    "#         #     continue\n",
    "        \n",
    "#         # if 'train' not in file_path and 'context' not in file_path:\n",
    "#         #     continue\n",
    "#         #####\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "\n",
    "#         print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     # if gpu_available:\n",
    "#     #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "#     #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "#     #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "#     #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "#     # else:\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     import matplotlib.patches as mpatches\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Set global font\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     # Define color mapping\n",
    "#     color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "#     colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "#     # Set point sizes\n",
    "#     sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Slight soft grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Hide axis labels but keep grid\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # --- Add better legend ---\n",
    "#     import matplotlib.lines as mlines\n",
    "\n",
    "#     # Define custom legend handles (use Line2D for circles)\n",
    "#     orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#     red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "#     green_circle = mlines.Line2D([], [], color='#48b33c', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "#     bluegreen_circle = mlines.Line2D([], [], color='#3cadb3', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "#     # Add legend inside plot (upper right)\n",
    "#     plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "#             loc='upper right',  # inside the plot, top right\n",
    "#             framealpha=0.6,\n",
    "#             prop={'size': 12},\n",
    "#             handletextpad=0.4,\n",
    "#             borderpad=0.5)\n",
    "\n",
    "#     # Tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save figure\n",
    "#     plt.savefig(save_path, dpi=300)\n",
    "#     print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need to change load path : tsne path changed!!!!!\n"
     ]
    }
   ],
   "source": [
    "# TODO need to change load path : tsne path changed!!!!!\n",
    "print('need to change load path : tsne path changed!!!!!')\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.colors as mcolors\n",
    "# import matplotlib.lines as mlines\n",
    "# import matplotlib as mpl\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # --- Global matplotlib settings ---\n",
    "# mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "# mpl.rcParams['axes.titlesize'] = 16\n",
    "# mpl.rcParams['axes.labelsize'] = 13\n",
    "# mpl.rcParams['xtick.labelsize'] = 10\n",
    "# mpl.rcParams['ytick.labelsize'] = 10\n",
    "# mpl.rcParams['legend.fontsize'] = 12\n",
    "# mpl.rcParams['figure.titlesize'] = 16\n",
    "# mpl.rcParams['figure.dpi'] = 300\n",
    "# mpl.rcParams['savefig.dpi'] = 300\n",
    "# mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "# mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "# mpl.rcParams['legend.title_fontsize'] = 13\n",
    "# mpl.rcParams['grid.alpha'] = 0.3\n",
    "# mpl.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "# # --- Set your directory ---\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files manually ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     if 'dsets_nk1_bit_10_100' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "#     elif 'dsets_nk1_bit_500_10_ood1' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "#     elif 'dsets_nk1_bit_500_10_ood2' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     base_save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined\")\n",
    "\n",
    "#     print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "#     all_losses = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "\n",
    "#         if len(group_files) != 5:\n",
    "#             print('⚠️ Skipping group_files', len(group_files))\n",
    "#             continue\n",
    "\n",
    "#         data = np.load(file_path)\n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "#         losses = data['losses']\n",
    "\n",
    "#         print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}, losses {losses.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "#         all_losses.append(losses)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "\n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "#     all_losses = np.concatenate(all_losses, axis=0)\n",
    "\n",
    "#     print(f\"✅ Combined embeddings shape: {all_embeddings.shape}, labels shape: {all_labels.shape}, losses shape: {all_losses.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Fixed normal class colors ---\n",
    "#     fixed_color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}\n",
    "\n",
    "#     # --- Function to plot each OOD separately ---\n",
    "#     def plot_one_ood(ood_mask, ood_label):\n",
    "#         if not np.any(ood_mask):\n",
    "#             print(f\"⚠️ No OOD{ood_label} points to plot.\")\n",
    "#             return\n",
    "\n",
    "#         losses_ood = all_losses[ood_mask]\n",
    "#         upper_clip = np.percentile(losses_ood, 95)\n",
    "#         norm = mcolors.Normalize(vmin=losses_ood.min(), vmax=upper_clip)\n",
    "#         cmap = cm.get_cmap('viridis')\n",
    "\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "\n",
    "#         # --- Prepare points ---\n",
    "#         colors = []\n",
    "#         alphas = []\n",
    "#         sizes = []\n",
    "\n",
    "#         for label, loss in zip(all_labels, all_losses):\n",
    "#             if label in fixed_color_map:\n",
    "#                 colors.append(fixed_color_map[label])\n",
    "#                 alphas.append(0.4)  # lighter background\n",
    "#                 sizes.append(20 if label in [0, -1] else 40)\n",
    "#             elif label == ood_label:\n",
    "#                 clipped_loss = min(loss, upper_clip)\n",
    "#                 colors.append(cmap(norm(clipped_loss)))\n",
    "#                 alphas.append(1.0)\n",
    "#                 sizes.append(30)\n",
    "#             else:\n",
    "#                 colors.append(None)\n",
    "#                 alphas.append(None)\n",
    "#                 sizes.append(None)\n",
    "\n",
    "#         # --- Plot OOD points first for colorbar ---\n",
    "#         ood_coords = []\n",
    "#         ood_colors = []\n",
    "#         for i in range(len(embeddings_2d)):\n",
    "#             if all_labels[i] == ood_label:\n",
    "#                 ood_coords.append(embeddings_2d[i])\n",
    "#                 clipped_loss = min(all_losses[i], upper_clip)\n",
    "#                 ood_colors.append(clipped_loss)\n",
    "\n",
    "#         if ood_coords:\n",
    "#             ood_coords = np.array(ood_coords)\n",
    "#             ood_colors = np.array(ood_colors)\n",
    "\n",
    "#             scatter = plt.scatter(ood_coords[:, 0], ood_coords[:, 1],\n",
    "#                                   c=ood_colors, cmap=cmap, norm=norm, s=30, alpha=1.0)\n",
    "\n",
    "#         # --- Plot normal points ---\n",
    "#         for i in range(len(embeddings_2d)):\n",
    "#             if colors[i] is None or all_labels[i] == ood_label:\n",
    "#                 continue\n",
    "#             plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1],\n",
    "#                         color=colors[i], s=sizes[i], alpha=alphas[i])\n",
    "\n",
    "#         plt.grid(True)\n",
    "#         plt.gca().set_xticklabels([])\n",
    "#         plt.gca().set_yticklabels([])\n",
    "#         plt.xlabel(\"\")\n",
    "#         plt.ylabel(\"\")\n",
    "#         plt.box(False)\n",
    "\n",
    "#         # --- Legend ---\n",
    "#         orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#         blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#         red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "#         plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "#                    loc='upper right',\n",
    "#                    framealpha=0.6,\n",
    "#                    prop={'size': 11},\n",
    "#                    handletextpad=0.4,\n",
    "#                    borderpad=0.5)\n",
    "\n",
    "#         # --- Prettier colorbar ---\n",
    "#         if ood_coords.size > 0:\n",
    "#             cbar = plt.colorbar(scatter, shrink=0.65, pad=0.01, aspect=35)\n",
    "#             cbar.set_label('Out-Of-Distribution Loss Value', fontsize=13, weight='bold', labelpad=8)\n",
    "#             cbar.outline.set_visible(False)  # no outer box\n",
    "#             cbar.ax.tick_params(labelsize=9, width=0.5, length=3)  # slim ticks\n",
    "#             if losses_ood.max() > 10:\n",
    "#                 cbar.ax.yaxis.set_major_formatter(FormatStrFormatter('%.1e'))\n",
    "\n",
    "#         # --- Title and layout ---\n",
    "#         plt.title(f'TSNE Plot - OOD{ood_label}', fontsize=16, weight='bold', pad=15)\n",
    "#         plt.tight_layout()\n",
    "\n",
    "#         final_save_path = f\"{base_save_path}_ood{ood_label}.pdf\"\n",
    "#         plt.savefig(final_save_path, dpi=300)\n",
    "#         print(f\"✅ Saved clean t-SNE plot for OOD{ood_label} to {final_save_path}\")\n",
    "#         plt.close()\n",
    "\n",
    "#         # --- Loss statistics ---\n",
    "#         mean_loss = losses_ood.mean()\n",
    "#         var_loss = losses_ood.var(ddof=0)  # use ddof=0 for population variance\n",
    "#         median_loss = np.median(losses_ood)\n",
    "\n",
    "#         print(f\"📈 Loss statistics for OOD{ood_label}:\")\n",
    "#         print(f\"  Mean   : {mean_loss:.6f}\")\n",
    "#         print(f\"  Variance: {var_loss:.6f}\")\n",
    "#         print(f\"  Median : {median_loss:.6f}\")\n",
    "\n",
    "#     # --- Plot separately for OOD1 and OOD2 ---\n",
    "#     ood1_mask = (all_labels == 3)\n",
    "#     ood2_mask = (all_labels == 4)\n",
    "\n",
    "#     plot_one_ood(ood1_mask, ood_label=3)\n",
    "#     plot_one_ood(ood2_mask, ood_label=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
