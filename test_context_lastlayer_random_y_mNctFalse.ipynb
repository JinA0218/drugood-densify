{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from main_merck_all_real_nk1_n_context_n_mvalid import get_dataset\n",
    "from utils import set_seed, get_optimizer, InfIterator\n",
    "from arguments import get_arguments\n",
    "from main_origin import get_model\n",
    "from setenc import get_mixer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y_hat, y, test=False):\n",
    "    return F.mse_loss(y.cuda().squeeze(), y_hat.cuda().squeeze())\n",
    "\n",
    "def test(args, dataloader, contextloader=None, model=None, mixer_phi=None, embed_type=None, n_t=10, n_c=5):\n",
    "    model.eval()\n",
    "    mixer_phi.eval()\n",
    "    embedding_list = []\n",
    "    label_list= []\n",
    "    loss_list = []\n",
    "    # print('model ', model)\n",
    "    # print('mixer_phi ', mixer_phi)\n",
    "    if embed_type == \"train_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 't_x.pt')\n",
    "                    torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"ood1_none\" or embed_type == \"ood2_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 't_x.pt')\n",
    "                #     torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"train_context\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'tc_x.pt')\n",
    "                    torch.save(y, 'tc_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                        \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'tc_x_c.pt')\n",
    "                        torch.save(y_c, 'tc_y_c.pt')\n",
    "                        \n",
    "                        \n",
    "                    # print('$$$$$$')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    # context_samples.append(x_c)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    elif embed_type == \"context_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'c_x.pt')\n",
    "                    torch.save(y, 'c_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                    \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'c_x_c.pt')\n",
    "                        torch.save(y_c, 'c_y_c.pt')\n",
    "                    # print('====')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    \n",
    "                    # context_samples.append(x_c)\n",
    "                    \n",
    "                    # B, S, H = x_c.size() <- did this in model\n",
    "                    # x_c = x_c.view(B*S, H)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x_c.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    mse = sum(losses) / counts\n",
    "    return mse, embedding_list, label_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_one_datapoint_features(args, model, mixer_phi, embed_type, n_t, n_c):\n",
    "    assert args.model_no_context == False\n",
    "    \n",
    "    args.embed_test = 'lastlayer_ours_best'\n",
    "    \n",
    "    path = f\"/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1/{args.embed_test}_\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    if args.seed == 42:\n",
    "        f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}.npz'\n",
    "    else:\n",
    "        f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}_{args.seed}.npz'\n",
    "    \n",
    "    if os.path.exists(f_path):\n",
    "        print(f\"â© {f_path} already exists. Skipping...\") \n",
    "        return\n",
    "    \n",
    "    if args.seed == 42:\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        set_seed(args.seed)\n",
    "    args.batch_size = 1\n",
    "    args.tsne_plot = True # because of get_dataset\n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    args.specify_ood_dataset = [d for d in all_candidates if d != args.dataset]\n",
    "    trainloader_test, _, mvalidloader_test, _, contextloader_test, ood1_trainloader_test, ood2_trainloader_test = get_dataset(args=args, test=True)\n",
    "    \n",
    "    if \"ood\" not in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood1' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood1_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood2' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood2_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    all_embeddings = torch.cat(embedding_list, dim=0)\n",
    "    all_labels = np.concatenate(label_list, axis=0)\n",
    "    all_losses = torch.cat(loss_list, dim=0)\n",
    "\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_losses = torch.tensor(all_losses)\n",
    "                \n",
    "    all_embeddings_np = all_embeddings.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    all_losses_np = all_losses.numpy()\n",
    "    \n",
    "    \n",
    "    np.savez(f_path, embeddings=all_embeddings_np, labels=all_labels_np, losses=all_losses_np)\n",
    "    print(f'>>> saved {f_path}')\n",
    "    \n",
    "    if 'ood1' in embed_type:\n",
    "        ood1_trainloader_test._iterator._shutdown_workers()\n",
    "    elif 'ood2' in embed_type:\n",
    "        ood2_trainloader_test._iterator._shutdown_workers()\n",
    "    else:\n",
    "        trainloader_test._iterator._shutdown_workers()\n",
    "        if 'context' in embed_type:\n",
    "            contextloader_test._iterator._shutdown_workers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(data):\n",
    "\n",
    "    model = data['model']\n",
    "    mixer_phi = data['mixer_phi']\n",
    "    optimizer = data['optimizer']\n",
    "    mixer_optimizer = data['mixer_optimizer']\n",
    "    \n",
    "    ltmse, lvmse, vmse, tmse = data['ltmse'], data['lvmse'], data['vmse'], data['tmse ']\n",
    "    \n",
    "    print('>> ltmse ', ltmse)\n",
    "    print('>> tmse ', tmse)\n",
    "    print('>> lvmse ', lvmse)\n",
    "    print('>> vmse ', vmse)\n",
    "    \n",
    "    args_ = data['args']\n",
    "\n",
    "    print('args_ ', args_)\n",
    "\n",
    "    args = get_arguments()\n",
    "\n",
    "    for k, v in args_.items():\n",
    "        setattr(args, k, v)\n",
    "    \n",
    "\n",
    "    print('args ', args)\n",
    "\n",
    "    if args.seed == 42:\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    model = get_model(args=args)\n",
    "    mixer_phi = get_mixer(args=args)\n",
    "    # optimizer = get_optimizer(optimizer=args.optimizer, model=model, lr=args.lr, wd=args.wd)\n",
    "    # optimizermixer = None if mixer_phi is None else get_optimizer(optimizer=args.optimizer, model=mixer_phi, lr=args.clr, wd=args.cwd)\n",
    "\n",
    "    model.load_state_dict(data['model'])\n",
    "    mixer_phi.load_state_dict(data['mixer_phi'])\n",
    "    # optimizer.load_state_dict(data['optimizer'])\n",
    "    # mixer_optimizer.load_state_dict(data['mixer_optimizer'])\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    mixer_phi = mixer_phi.to(args.device)\n",
    "    \n",
    "    # for (n_t, n_c) in [(5, 10), (5, 100), (10, 5), (10, 100), (100, 5), (100, 10)]:\n",
    "    # for (n_t, n_c) in [(5, 10), (5, 50), (5, 100), (10, 5), (10, 40), (10, 100), (40, 5), (40, 10), (100, 5),]:\n",
    "    for (n_t, n_c) in [(10, 100),]:\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"context_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_context\", n_t, n_c)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood1_none\", 500, 10)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood2_none\", 500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=Sun May 25 17:54:43 2025\n",
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ NVITOP 1.5.0       Driver Version: 555.42.06      CUDA Driver Version: 12.5 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ GPU  Name        Persistence-Mâ”‚ Bus-Id        Disp.A â”‚ Volatile Uncorr. ECC â”‚\n",
      "â”‚ Fan  Temp  Perf  Pwr:Usage/Capâ”‚         Memory-Usage â”‚ GPU-Util  Compute M. â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚\u001b[33m   0  RTX A6000           Off  \u001b[0mâ”‚\u001b[33m 00000000:1E:00.0 Off \u001b[0mâ”‚\u001b[33m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[33m 30%   22C    P8    17W / 300W \u001b[0mâ”‚\u001b[33m   6091MiB / 47.99GiB \u001b[0mâ”‚\u001b[33m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   1  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:1F:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   34C    P2    64W / 300W \u001b[0mâ”‚\u001b[31m  45.91GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[33m   2  RTX A6000           Off  \u001b[0mâ”‚\u001b[33m 00000000:20:00.0 Off \u001b[0mâ”‚\u001b[33m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[33m 36%   58C    P2    93W / 300W \u001b[0mâ”‚\u001b[33m  23.86GiB / 47.99GiB \u001b[0mâ”‚\u001b[33m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   3  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:21:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   22C    P8    18W / 300W \u001b[0mâ”‚\u001b[31m  42.09GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   4  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:22:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   25C    P8    34W / 300W \u001b[0mâ”‚\u001b[31m  44.88GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   5  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:23:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 35%   63C    P2   298W / 300W \u001b[0mâ”‚\u001b[31m  37.36GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m    100%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[33m   6  RTX A6000           Off  \u001b[0mâ”‚\u001b[33m 00000000:24:00.0 Off \u001b[0mâ”‚\u001b[33m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[33m 30%   34C    P8    20W / 300W \u001b[0mâ”‚\u001b[33m  30.85GiB / 47.99GiB \u001b[0mâ”‚\u001b[33m      0%      Default \u001b[0mâ”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
      "\u001b[1m\u001b[36m[ CPU: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž 64.3%         ]\u001b[0m  \u001b[1m( Load Average: 180.5 180.3 181.4 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ 45.0%               ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ MAX ]\u001b[0m\n",
      "\n",
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ Processes:                                                      \u001b[1m\u001b[35mjinakim\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32mai16\u001b[0m â”‚\n",
      "â”‚ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM       TIME  COMMAND     â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚\u001b[33m   0\u001b[0m 2745748 C jinakim 316.0MiB   0     0   0.0   0.4       7:42  /c2/jinak.. â”‚\n",
      "â”‚\u001b[33m   0\u001b[0m \u001b[2m2036449 C  namsan  5760MiB   0     0   0.0   1.2  26.3 days  /c2/namsa..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   1\u001b[0m \u001b[2m3158080 C soyeong 45.90GiB   0     0 101.7   2.6   5.0 days  python /c..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[33m   2\u001b[0m \u001b[2m2660891 C dohyeon 23.82GiB   0     0  99.8   4.7    1:38:40  python tr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   3\u001b[0m \u001b[2m2595210 C    suji 42.06GiB   0     0 103.0  14.9    4:23:53  python sr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   4\u001b[0m \u001b[2m1639820 C yukyeo+ 44.86GiB   0     0   0.0   1.2   64:05:40  python tr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   5\u001b[0m \u001b[2m2666077 C dohyeon 37.32GiB 100    37 106.0   4.7    1:34:09  python tr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[33m   6\u001b[0m \u001b[2m3175157 C soyeong 30.84GiB   0     0  1021   2.5   5.0 days  python /c..\u001b[0m â”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
      "\u001b[1m\u001b[31mERROR:\u001b[0m Failed to initialize `curses` (curs_set() returned ERR)\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_dpp4_bit_['None'].pth\n",
      ">> ltmse  0.9322767276635672\n",
      ">> tmse  1.0995820981074662\n",
      ">> lvmse  0.9546905491087172\n",
      ">> vmse  0.5368905299239688\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'dpp4', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'dsets', 'sencoder_layer': 'max', 'vec_type': 'bit', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 8, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 16, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='dpp4', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='dsets', sencoder_layer='max', vec_type='bit', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=8, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=16, device='cuda')\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2745748/71459262.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_losses = torch.tensor(all_losses)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_100_train_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_100_context_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_100_train_context.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_dpp4_count_['None'].pth\n",
      ">> ltmse  0.9810517033621268\n",
      ">> tmse  1.1915678806001808\n",
      ">> lvmse  0.977295438448588\n",
      ">> vmse  0.6924604309929742\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'dpp4', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'dsets', 'sencoder_layer': 'max', 'vec_type': 'count', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 4, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 1, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='dpp4', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='dsets', sencoder_layer='max', vec_type='count', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=4, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=1, device='cuda')\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_100_train_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_100_context_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_100_train_context.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_hivprot_bit_['None'].pth\n",
      ">> ltmse  0.34530533850193024\n",
      ">> tmse  0.3842411290353803\n",
      ">> lvmse  1.5526102781295776\n",
      ">> vmse  0.6521486520767212\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'hivprot', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'dsets', 'sencoder_layer': 'max', 'vec_type': 'bit', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 8, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 6, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='hivprot', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='dsets', sencoder_layer='max', vec_type='bit', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=8, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=6, device='cuda')\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_100_train_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_100_context_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_100_train_context.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_hivprot_count_['None'].pth\n",
      ">> ltmse  0.4782168293622003\n",
      ">> tmse  0.8429577190484574\n",
      ">> lvmse  2.0066731452941893\n",
      ">> vmse  0.6482634663581848\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'hivprot', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'dsets', 'sencoder_layer': 'max', 'vec_type': 'count', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 8, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 6, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='hivprot', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='dsets', sencoder_layer='max', vec_type='count', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=8, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=6, device='cuda')\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_100_train_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_100_context_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_100_train_context.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['None'].pth\n",
      ">> ltmse  0.3674501709182044\n",
      ">> tmse  0.36651846266936683\n",
      ">> lvmse  0.8353371580441793\n",
      ">> vmse  0.48244362473487856\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'nk1', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'dsets', 'sencoder_layer': 'max', 'vec_type': 'bit', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 4, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 16, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='nk1', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='dsets', sencoder_layer='max', vec_type='bit', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=4, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=16, device='cuda')\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_count_['None'].pth\n",
      ">> ltmse  0.5053501120660974\n",
      ">> tmse  0.4258817619290845\n",
      ">> lvmse  1.7838222901026408\n",
      ">> vmse  0.636421549320221\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'nk1', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'dsets', 'sencoder_layer': 'max', 'vec_type': 'count', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 8, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 1, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='nk1', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='dsets', sencoder_layer='max', vec_type='count', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=8, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=1, device='cuda')\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_100_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_100_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_100_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_strans_dpp4_bit_['None'].pth\n",
      ">> ltmse  0.8743963679357962\n",
      ">> tmse  1.0355678479653991\n",
      ">> lvmse  0.7725735306739807\n",
      ">> vmse  0.5162967211670346\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'dpp4', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'strans', 'sencoder_layer': 'max', 'vec_type': 'bit', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 4, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 1, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='dpp4', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='strans', sencoder_layer='max', vec_type='bit', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=4, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=1, device='cuda')\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_bit_10_100_train_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_bit_10_100_context_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_bit_10_100_train_context.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_bit_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_strans_dpp4_count_['None'].pth\n",
      ">> ltmse  1.030184405706914\n",
      ">> tmse  1.4783894029981057\n",
      ">> lvmse  1.8629433181550767\n",
      ">> vmse  0.9414777821964688\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'dpp4', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'strans', 'sencoder_layer': 'max', 'vec_type': 'count', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 8, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 16, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='dpp4', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='strans', sencoder_layer='max', vec_type='count', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=8, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=16, device='cuda')\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_count_10_100_train_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_count_10_100_context_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_count_10_100_train_context.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_dpp4_count_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_strans_hivprot_bit_['None'].pth\n",
      ">> ltmse  0.5266326201051029\n",
      ">> tmse  0.43331493103682106\n",
      ">> lvmse  1.938984203338623\n",
      ">> vmse  0.44838978052139283\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'hivprot', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'strans', 'sencoder_layer': 'max', 'vec_type': 'bit', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 1, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 1, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='hivprot', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='strans', sencoder_layer='max', vec_type='bit', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=1, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=1, device='cuda')\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_bit_10_100_train_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_bit_10_100_context_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_bit_10_100_train_context.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_bit_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_strans_hivprot_count_['None'].pth\n",
      ">> ltmse  0.6176918309126327\n",
      ">> tmse  1.1798364244290251\n",
      ">> lvmse  2.1202345371246336\n",
      ">> vmse  0.7512752771377563\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'hivprot', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'strans', 'sencoder_layer': 'max', 'vec_type': 'count', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 8, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 1, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='hivprot', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='strans', sencoder_layer='max', vec_type='count', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=8, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=1, device='cuda')\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_count_10_100_train_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_count_10_100_context_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_count_10_100_train_context.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_hivprot_count_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_strans_nk1_bit_['None'].pth\n",
      ">> ltmse  0.4131239465732446\n",
      ">> tmse  0.3784391390330073\n",
      ">> lvmse  1.2931367039680481\n",
      ">> vmse  0.5303236325581868\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'nk1', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'strans', 'sencoder_layer': 'max', 'vec_type': 'bit', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 8, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 1, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='nk1', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='strans', sencoder_layer='max', vec_type='bit', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=8, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=1, device='cuda')\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_bit_10_100_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_bit_10_100_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_bit_10_100_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_bit_500_10_ood2_none.npz\n",
      "ðŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_strans_nk1_count_['None'].pth\n",
      ">> ltmse  0.4744759358208755\n",
      ">> tmse  0.5007398740105007\n",
      ">> lvmse  1.4488638718922933\n",
      ">> vmse  0.7109489560127258\n",
      "args_  {'run': 0, 'seed': 42, 'root': '/c2/jinakim/dataset_backup/antimalaria/', 'model': 'mlp', 'dataset': 'nk1', 'split_type': 'spectral', 'fingerprint': 'ecfp', 'batch_size': 64, 'num_outputs': 1, 'sencoder': 'strans', 'sencoder_layer': 'max', 'vec_type': 'count', 'epochs': 100, 'optimizer': 'adamwschedulefree', 'num_workers': 8, 'lr': 0.001, 'wd': 0.0001, 'clr': 1e-05, 'cwd': 0.001, 'hidden_dim': 64, 'in_features': 6560, 'num_layers': 3, 'dropout': 0.5, 'batchnorm': False, 'ln': False, 'initialize_weights': False, 'mixer_phi': True, 'outer_episodes': 50, 'inner_episodes': 10, 'n_context': 4, 'early_stopping_episodes': 10, 'num_inner_dataset': 1, 'same_setting': True, 'low_sim': None, 'exclude_mval_data_in_context': False, 'mvalid_dataset': ['None'], 'context_dataset': None, 'specify_ood_dataset': None, 'embed_test': 'ours_best', 'tsne_plot': False, 'mixing_layer': 0, 'model_no_context': False, 'n_mvalid': 1, 'device': 'cuda'}\n",
      "args  Namespace(run=0, seed=42, root='/c2/jinakim/dataset_backup/antimalaria/', model='mlp', dataset='nk1', split_type='spectral', fingerprint='ecfp', batch_size=64, num_outputs=1, sencoder='strans', sencoder_layer='max', vec_type='count', epochs=100, optimizer='adamwschedulefree', num_workers=8, lr=0.001, wd=0.0001, clr=1e-05, cwd=0.001, hidden_dim=64, in_features=6560, num_layers=3, dropout=0.5, batchnorm=False, ln=False, initialize_weights=False, mixer_phi=True, outer_episodes=50, inner_episodes=10, n_context=4, early_stopping_episodes=10, num_inner_dataset=1, same_setting=True, low_sim=None, exclude_mval_data_in_context=False, mvalid_dataset=['None'], context_dataset=None, specify_ood_dataset=None, embed_test='ours_best', tsne_plot=False, mixing_layer=0, model_no_context=False, n_mvalid=1, device='cuda')\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_count_10_100_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_count_10_100_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_count_10_100_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/strans_nk1_count_500_10_ood2_none.npz\n",
      "\n",
      "ðŸ All models loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory containing .pth files\n",
    "tsne_model_dir = '/c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/'\n",
    "os.makedirs(tsne_model_dir, exist_ok=True)\n",
    "# List all .pth files\n",
    "# pth_files = [\"Model_dsets_nk1_bit_['3a4', 'cb1'].pth\"]\n",
    "# pth_files = [\"Model_dsets_nk1_bit_['hivint', 'tdi'].pth\"]\n",
    "pth_files = sorted([f for f in os.listdir(tsne_model_dir) if f.endswith('.pth')])\n",
    "\n",
    "# Load each file\n",
    "for i, f in enumerate(pth_files):\n",
    "    # if i > 5:\n",
    "    #     break\n",
    "    file_path = os.path.join(tsne_model_dir, f)\n",
    "    print(f\"ðŸš€ Loading {file_path}\")\n",
    "    \n",
    "    data = torch.load(file_path)\n",
    "    save_features(data)\n",
    "    # Now 'data' contains the loaded model or state dict or whatever was saved\n",
    "    # You can process it here if needed\n",
    "    # For example, just printing some keys if it's a checkpoint\n",
    "    # if isinstance(data, dict):\n",
    "    #     print(f\"âœ… Loaded {f}: keys = {list(data.keys())}\")\n",
    "    # else:\n",
    "    #     print(f\"âœ… Loaded {f}: type = {type(data)}\")\n",
    "\n",
    "print(\"\\nðŸ All models loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ cuML not available, falling back to CPU openTSNE\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_bit_500_10\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_100_5\n",
      "âœ… Loaded dsets_dpp4_count_100_5_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_count_100_5_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_count_100_5_train_none.npz: embeddings (100, 64), labels (100,)\n",
      "âœ… Combined embeddings shape: (1100, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_100_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_10_100\n",
      "âœ… Loaded dsets_dpp4_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (2010, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_100_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_10_40\n",
      "âœ… Loaded dsets_dpp4_count_10_40_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_dpp4_count_10_40_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_dpp4_count_10_40_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (810, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_40_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_10_5\n",
      "âœ… Loaded dsets_dpp4_count_10_5_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_dpp4_count_10_5_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_dpp4_count_10_5_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (110, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_40_10\n",
      "âœ… Loaded dsets_dpp4_count_40_10_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_dpp4_count_40_10_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_dpp4_count_40_10_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "âœ… Combined embeddings shape: (840, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_40_10_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_40_5\n",
      "âœ… Loaded dsets_dpp4_count_40_5_context_none.npz: embeddings (200, 64), labels (200,)\n",
      "âœ… Loaded dsets_dpp4_count_40_5_train_context.npz: embeddings (200, 64), labels (200,)\n",
      "âœ… Loaded dsets_dpp4_count_40_5_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "âœ… Combined embeddings shape: (440, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_40_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_500_10\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_5_100\n",
      "âœ… Loaded dsets_dpp4_count_5_100_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_count_5_100_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_count_5_100_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (1005, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_5_100_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_5_10\n",
      "âœ… Loaded dsets_dpp4_count_5_10_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_dpp4_count_5_10_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_dpp4_count_5_10_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (105, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_5_10_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count_5_50\n",
      "âœ… Loaded dsets_dpp4_count_5_50_context_none.npz: embeddings (250, 64), labels (250,)\n",
      "âœ… Loaded dsets_dpp4_count_5_50_train_context.npz: embeddings (250, 64), labels (250,)\n",
      "âœ… Loaded dsets_dpp4_count_5_50_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (505, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_5_50_tsne_combined.pdf\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_bit_500_10\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_100_5\n",
      "âœ… Loaded dsets_hivprot_count_100_5_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_count_100_5_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_count_100_5_train_none.npz: embeddings (100, 64), labels (100,)\n",
      "âœ… Combined embeddings shape: (1100, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_100_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_10_100\n",
      "âœ… Loaded dsets_hivprot_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (2010, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_100_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_10_40\n",
      "âœ… Loaded dsets_hivprot_count_10_40_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_hivprot_count_10_40_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_hivprot_count_10_40_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (810, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_40_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_10_5\n",
      "âœ… Loaded dsets_hivprot_count_10_5_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_hivprot_count_10_5_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_hivprot_count_10_5_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (110, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_40_10\n",
      "âœ… Loaded dsets_hivprot_count_40_10_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_hivprot_count_40_10_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_hivprot_count_40_10_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "âœ… Combined embeddings shape: (840, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_40_10_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_40_5\n",
      "âœ… Loaded dsets_hivprot_count_40_5_context_none.npz: embeddings (200, 64), labels (200,)\n",
      "âœ… Loaded dsets_hivprot_count_40_5_train_context.npz: embeddings (200, 64), labels (200,)\n",
      "âœ… Loaded dsets_hivprot_count_40_5_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "âœ… Combined embeddings shape: (440, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_40_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_500_10\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_5_100\n",
      "âœ… Loaded dsets_hivprot_count_5_100_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_count_5_100_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_count_5_100_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (1005, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_5_100_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_5_10\n",
      "âœ… Loaded dsets_hivprot_count_5_10_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_hivprot_count_5_10_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_hivprot_count_5_10_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (105, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_5_10_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count_5_50\n",
      "âœ… Loaded dsets_hivprot_count_5_50_context_none.npz: embeddings (250, 64), labels (250,)\n",
      "âœ… Loaded dsets_hivprot_count_5_50_train_context.npz: embeddings (250, 64), labels (250,)\n",
      "âœ… Loaded dsets_hivprot_count_5_50_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (505, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_5_50_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_100_100\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_100_10\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_100_40\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_100_50\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_5000_10\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_500_10\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "â© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_100_5\n",
      "âœ… Loaded dsets_nk1_count_100_5_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_count_100_5_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_count_100_5_train_none.npz: embeddings (100, 64), labels (100,)\n",
      "âœ… Combined embeddings shape: (1100, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_100_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_10_100\n",
      "âœ… Loaded dsets_nk1_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (2010, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_100_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_10_40\n",
      "âœ… Loaded dsets_nk1_count_10_40_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_nk1_count_10_40_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_nk1_count_10_40_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (810, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_40_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_10_5\n",
      "âœ… Loaded dsets_nk1_count_10_5_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_nk1_count_10_5_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_nk1_count_10_5_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Combined embeddings shape: (110, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_40_10\n",
      "âœ… Loaded dsets_nk1_count_40_10_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_nk1_count_40_10_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "âœ… Loaded dsets_nk1_count_40_10_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "âœ… Combined embeddings shape: (840, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_40_10_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_40_5\n",
      "âœ… Loaded dsets_nk1_count_40_5_context_none.npz: embeddings (200, 64), labels (200,)\n",
      "âœ… Loaded dsets_nk1_count_40_5_train_context.npz: embeddings (200, 64), labels (200,)\n",
      "âœ… Loaded dsets_nk1_count_40_5_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "âœ… Combined embeddings shape: (440, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_40_5_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_500_10\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_5_100\n",
      "âœ… Loaded dsets_nk1_count_5_100_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_count_5_100_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_count_5_100_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (1005, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_5_100_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_5_10\n",
      "âœ… Loaded dsets_nk1_count_5_10_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_nk1_count_5_10_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "âœ… Loaded dsets_nk1_count_5_10_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (105, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_5_10_tsne_combined.pdf\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count_5_50\n",
      "âœ… Loaded dsets_nk1_count_5_50_context_none.npz: embeddings (250, 64), labels (250,)\n",
      "âœ… Loaded dsets_nk1_count_5_50_train_context.npz: embeddings (250, 64), labels (250,)\n",
      "âœ… Loaded dsets_nk1_count_5_50_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "âœ… Combined embeddings shape: (505, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_5_50_tsne_combined.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"âœ… Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"â© {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nðŸš€ Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        #####\n",
    "        if 'ood' in file_path:\n",
    "            continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"âœ… Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    \n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "    if 'ood' not in f:\n",
    "        groups[prefix].append(f)\n",
    "    \n",
    "    prefix_ = '_'.join(parts[:3])\n",
    "    if prefix_ in prefix and 'ood' in f:\n",
    "        groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"â© {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nðŸš€ Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        if len(group_files) != 5:\n",
    "            print('group_files ', len(group_files))\n",
    "            continue\n",
    "        #####\n",
    "        # if 'ood' in file_path:\n",
    "        #     continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "    green_circle = mlines.Line2D([], [], color='#48b33c', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "    bluegreen_circle = mlines.Line2D([], [], color='#3cadb3', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood1_baseline_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none.npz'\n",
    "ood1_ours_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none.npz'\n",
    "ood2_baseline_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood2_none.npz'\n",
    "ood2_ours_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none.npz'\n",
    "\n",
    "compare_histogram(ood1_baseline_path, ood1_ours_path, 1)\n",
    "compare_histogram(ood2_baseline_path, ood2_ours_path, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ cuML not available, falling back to CPU openTSNE\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_10_100\n",
      "âœ… Loaded dsets_nk1_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_tsne_combined_all_final.pdf\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_tsne_combined_all_final.png\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# # try:\n",
    "# #     import cupy as cp\n",
    "# #     from cuml.manifold import TSNE as cuTSNE\n",
    "# #     gpu_available = True\n",
    "# #     print(\"âœ… Using GPU cuML TSNE\")\n",
    "# # except ImportError:\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# gpu_available = False\n",
    "# print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "    \n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "#     if 'dsets_nk1_bit_10_100' in prefix:\n",
    "#         prefix_ = '_'.join(parts[:3])\n",
    "        \n",
    "#         if 'ood' not in f:\n",
    "#             groups[prefix].append(f)\n",
    "        \n",
    "#         # print('prefix ', prefix)\n",
    "#         # print('prefix_ ', prefix_)\n",
    "#         # print('f')\n",
    "#     # if prefix_ in prefix and 'ood' in f:\n",
    "#     #     groups[prefix].append(f)\n",
    "    \n",
    "#     if 'dsets_nk1_bit_500_10_ood1_none.npz' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "#     if 'dsets_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path_pdf = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all_final.pdf\")\n",
    "#     save_path_png = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all_final.png\")\n",
    "    \n",
    "#     # if \"dpp4_bit\" in save_path:\n",
    "#     #     continue\n",
    "#     # --- Skip if already exists ---\n",
    "#     if os.path.exists(save_path_pdf):\n",
    "#         print(f\"â© {save_path_pdf} already exists. Skipping...\")\n",
    "#         continue\n",
    "    \n",
    "#     if os.path.exists(save_path_png):\n",
    "#         print(f\"â© {save_path_png} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\nðŸš€ Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "#         if len(group_files) != 5:\n",
    "#             print('group_files ', len(group_files))\n",
    "#             continue\n",
    "#         #####\n",
    "#         # if 'ood' in file_path:\n",
    "#         #     continue\n",
    "        \n",
    "#         # if 'train' not in file_path and 'context' not in file_path:\n",
    "#         #     continue\n",
    "#         #####\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "\n",
    "#         print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     # if gpu_available:\n",
    "#     #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "#     #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "#     #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "#     #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "#     # else:\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     import matplotlib.patches as mpatches\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Set global font\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     # Define color mapping\n",
    "#     # color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "#     color_map = {0: '#FFA500', 1: '#2E8B57', -1: '#9B30FF', 3:'#D62728', 4:'#808080'}  # orange and blue\n",
    "#     colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "#     # Set point sizes\n",
    "#     # sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "#     sizes = []\n",
    "#     for label in all_labels:\n",
    "#         if label == 1:         # mixup (w/o context)\n",
    "#             sizes.append(60)   # larger to emphasize\n",
    "#         elif label == -1:      # mixup (context)\n",
    "#             sizes.append(30)\n",
    "#         elif label == 0:       # mixup\n",
    "#             sizes.append(30)\n",
    "#         elif label in [3, 4]:  # OOD\n",
    "#             sizes.append(40)   # fairly large to stand out\n",
    "#         else:\n",
    "#             sizes.append(15)   # default fallback\n",
    "\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Slight soft grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Hide axis labels but keep grid\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # --- Add better legend ---\n",
    "#     import matplotlib.lines as mlines\n",
    "\n",
    "#     # Define custom legend handles (use Line2D for circles)\n",
    "#     orange_circle = mlines.Line2D([], [], color='#FFA500', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#2E8B57', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#     red_circle = mlines.Line2D([], [], color='#9B30FF', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "#     green_circle = mlines.Line2D([], [], color='#D62728', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "#     bluegreen_circle = mlines.Line2D([], [], color='#808080', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "#     # Add legend inside plot (upper right)\n",
    "#     plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "#             loc='upper right',  # inside the plot, top right\n",
    "#             framealpha=0.6,\n",
    "#             prop={'size': 12},\n",
    "#             handletextpad=0.4,\n",
    "#             borderpad=0.5)\n",
    "\n",
    "#     # Tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save figure\n",
    "#     plt.savefig(save_path_pdf, dpi=300)\n",
    "#     print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path_pdf}\")\n",
    "#     plt.savefig(save_path_png, dpi=300)\n",
    "#     print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path_png}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit_10_100\n",
      "âœ… Loaded dsets_nk1_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_nk1_bit_10_100\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by prefix ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     if 'dsets_nk1_bit_10_100' in f or 'dsets_nk1_bit_500_10_ood1_none.npz' in f or 'dsets_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# # --- Function to save plot with label exclusions ---\n",
    "# def plot_tsne(embeddings_2d, all_labels, excluded_labels, save_prefix):\n",
    "#     filtered_indices = [i for i, label in enumerate(all_labels) if label not in excluded_labels]\n",
    "#     filtered_embeddings = embeddings_2d[filtered_indices]\n",
    "#     filtered_labels = all_labels[filtered_indices]\n",
    "\n",
    "#     color_map = {0: '#ffb347', 1: '#0000CD', -1: '#228B22', 3: '#8B008B', 4: '#808080'}\n",
    "#     sizes = []\n",
    "#     colors = []\n",
    "#     for label in filtered_labels:\n",
    "#         sizes.append(70 if label == 1 else 18 if label in [3, 4] else 13)\n",
    "#         colors.append(color_map[label])\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.scatter(filtered_embeddings[:, 0], filtered_embeddings[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.box(False)\n",
    "\n",
    "#     import matplotlib.lines as mlines\n",
    "#     legend_handles = [\n",
    "#         mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours'),\n",
    "#         mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)'),\n",
    "#         mlines.Line2D([], [], color='#228B22', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "#     ]\n",
    "#     if 3 not in excluded_labels:\n",
    "#         legend_handles.append(mlines.Line2D([], [], color='#8B008B', marker='o', linestyle='None', markersize=8, label='OOD'))\n",
    "#     if 4 not in excluded_labels:\n",
    "#         legend_handles.append(mlines.Line2D([], [], color='#B22222', marker='o', linestyle='None', markersize=8, label='OOD'))\n",
    "\n",
    "#     plt.legend(handles=legend_handles, loc='upper right', framealpha=0.6, prop={'size': 12})\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"{save_prefix}.pdf\", dpi=300)\n",
    "#     plt.savefig(f\"{save_prefix}.png\", dpi=300)\n",
    "#     plt.close()\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     print(f\"\\nðŸš€ Processing group {prefix}\")\n",
    "#     all_embeddings, all_labels = [], []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "#         data = np.load(file_path)\n",
    "#         all_embeddings.append(data['embeddings'])\n",
    "#         all_labels.append(data['labels'])\n",
    "#         print(f\"âœ… Loaded {f}: embeddings {data['embeddings'].shape}, labels {data['labels'].shape}\")\n",
    "\n",
    "#     if not all_embeddings:\n",
    "#         continue\n",
    "\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # Run t-SNE using scikit-learn\n",
    "#     tsne = TSNE(n_components=2, random_state=42)\n",
    "#     embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "#     # Save three filtered plots\n",
    "#     base_path = os.path.join(tsne_dir, f\"{prefix}_tsne\")\n",
    "#     plot_tsne(embeddings_2d, all_labels, excluded_labels=[3, 4], save_prefix=f\"{base_path}_no_ood\")\n",
    "#     plot_tsne(embeddings_2d, all_labels, excluded_labels=[4], save_prefix=f\"{base_path}_no_ood2\")\n",
    "#     plot_tsne(embeddings_2d, all_labels, excluded_labels=[3], save_prefix=f\"{base_path}_no_ood1\")\n",
    "#     print(f\"âœ… Saved all t-SNE variations for {prefix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Processing group dsets_dpp4_bit\n",
      "âœ… Loaded dsets_dpp4_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_dpp4_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_dpp4_bit\n",
      "\n",
      "ðŸš€ Processing group dsets_dpp4_count\n",
      "âœ… Loaded dsets_dpp4_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_dpp4_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_dpp4_count\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_bit\n",
      "âœ… Loaded dsets_hivprot_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_hivprot_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_hivprot_bit\n",
      "\n",
      "ðŸš€ Processing group dsets_hivprot_count\n",
      "âœ… Loaded dsets_hivprot_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_hivprot_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_hivprot_count\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_bit\n",
      "âœ… Loaded dsets_nk1_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_nk1_bit\n",
      "\n",
      "ðŸš€ Processing group dsets_nk1_count\n",
      "âœ… Loaded dsets_nk1_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_nk1_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_nk1_count\n",
      "\n",
      "ðŸš€ Processing group strans_dpp4_bit\n",
      "âœ… Loaded strans_dpp4_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_dpp4_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_dpp4_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded strans_dpp4_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded strans_dpp4_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for strans_dpp4_bit\n",
      "\n",
      "ðŸš€ Processing group strans_dpp4_count\n",
      "âœ… Loaded strans_dpp4_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_dpp4_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_dpp4_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded strans_dpp4_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded strans_dpp4_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for strans_dpp4_count\n",
      "\n",
      "ðŸš€ Processing group strans_hivprot_bit\n",
      "âœ… Loaded strans_hivprot_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_hivprot_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_hivprot_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded strans_hivprot_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded strans_hivprot_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for strans_hivprot_bit\n",
      "\n",
      "ðŸš€ Processing group strans_hivprot_count\n",
      "âœ… Loaded strans_hivprot_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_hivprot_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_hivprot_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded strans_hivprot_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded strans_hivprot_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for strans_hivprot_count\n",
      "\n",
      "ðŸš€ Processing group strans_nk1_bit\n",
      "âœ… Loaded strans_nk1_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_nk1_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_nk1_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded strans_nk1_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded strans_nk1_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for strans_nk1_bit\n",
      "\n",
      "ðŸš€ Processing group strans_nk1_count\n",
      "âœ… Loaded strans_nk1_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_nk1_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded strans_nk1_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded strans_nk1_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded strans_nk1_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for strans_nk1_count\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by prefix ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    if len(parts) < 4:\n",
    "        continue  # Skip malformed filenames\n",
    "\n",
    "    method = parts[0]  # dsets or strans\n",
    "    dataset = parts[1]  # e.g., dpp4\n",
    "    vector = parts[2]   # bit or count\n",
    "    key = f\"{method}_{dataset}_{vector}\"\n",
    "    groups[key].append(f)\n",
    "\n",
    "# --- Function to save plot with label exclusions ---\n",
    "def plot_tsne(embeddings_2d, all_labels, excluded_labels, save_prefix, specify_ood_dataset):\n",
    "    filtered_indices = [i for i, label in enumerate(all_labels) if label not in excluded_labels]\n",
    "    filtered_embeddings = embeddings_2d[filtered_indices]\n",
    "    filtered_labels = all_labels[filtered_indices]\n",
    "\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#228B22', 3: '#8B008B', 4: '#B22222'}\n",
    "    sizes = []\n",
    "    colors = []\n",
    "    for label in filtered_labels:\n",
    "        sizes.append(70 if label == 1 else 18 if label in [3, 4] else 13)\n",
    "        colors.append(color_map[label])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_embeddings[:, 0], filtered_embeddings[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.box(False)\n",
    "\n",
    "    import matplotlib.lines as mlines\n",
    "    legend_handles = [\n",
    "        mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours'),\n",
    "        mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)'),\n",
    "        mlines.Line2D([], [], color='#228B22', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "    ]\n",
    "    if 3 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#8B008B', marker='o', linestyle='None', markersize=8, label=f'OOD ({specify_ood_dataset[0]})'))\n",
    "    if 4 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#B22222', marker='o', linestyle='None', markersize=8, label=f'OOD ({specify_ood_dataset[1]})'))\n",
    "\n",
    "    plt.legend(handles=legend_handles, loc='upper right', framealpha=0.6, prop={'size': 12})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_prefix}_ALL.pdf\", dpi=300)\n",
    "    # plt.savefig(f\"{save_prefix}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    print(f\"\\nðŸš€ Processing group {prefix}\")\n",
    "    all_embeddings, all_labels = [], []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        data = np.load(file_path)\n",
    "        all_embeddings.append(data['embeddings'])\n",
    "        all_labels.append(data['labels'])\n",
    "        print(f\"âœ… Loaded {f}: embeddings {data['embeddings'].shape}, labels {data['labels'].shape}\")\n",
    "\n",
    "    if not all_embeddings:\n",
    "        continue\n",
    "\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # Run t-SNE using scikit-learn\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Save three filtered plots\n",
    "    base_path = os.path.join(tsne_dir, f\"{prefix}_tsne\")\n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    specify_ood_dataset = [d for d in all_candidates if d not in prefix]\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[], save_prefix=f\"{base_path}\", specify_ood_dataset=specify_ood_dataset)\n",
    "\n",
    "    # plot_tsne(embeddings_2d, all_labels, excluded_labels=[3, 4], save_prefix=f\"{base_path}_no_ood\")\n",
    "    # plot_tsne(embeddings_2d, all_labels, excluded_labels=[4], save_prefix=f\"{base_path}_no_ood2\")\n",
    "    # plot_tsne(embeddings_2d, all_labels, excluded_labels=[3], save_prefix=f\"{base_path}_no_ood1\")\n",
    "    print(f\"âœ… Saved all t-SNE variations for {prefix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
