{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from main_merck_all_real import get_dataset\n",
    "from utils import set_seed, get_optimizer, InfIterator\n",
    "from arguments import get_arguments\n",
    "from main_origin import get_model\n",
    "from setenc import get_mixer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y_hat, y, test=False):\n",
    "    return F.mse_loss(y.cuda().squeeze(), y_hat.cuda().squeeze())\n",
    "\n",
    "def test(args, dataloader, contextloader=None, model=None, mixer_phi=None, embed_type=None, n_t=10, n_c=5):\n",
    "    model.eval()\n",
    "    mixer_phi.eval()\n",
    "    embedding_list = []\n",
    "    label_list= []\n",
    "    loss_list = []\n",
    "    # print('model ', model)\n",
    "    # print('mixer_phi ', mixer_phi)\n",
    "    if embed_type == \"train_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 't_x.pt')\n",
    "                    torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"ood1_none\" or embed_type == \"ood2_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 't_x.pt')\n",
    "                #     torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"train_context\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'tc_x.pt')\n",
    "                    torch.save(y, 'tc_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                        \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'tc_x_c.pt')\n",
    "                        torch.save(y_c, 'tc_y_c.pt')\n",
    "                        \n",
    "                        \n",
    "                    # print('$$$$$$')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    # context_samples.append(x_c)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    elif embed_type == \"context_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'c_x.pt')\n",
    "                    torch.save(y, 'c_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                    \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'c_x_c.pt')\n",
    "                        torch.save(y_c, 'c_y_c.pt')\n",
    "                    # print('====')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    \n",
    "                    # context_samples.append(x_c)\n",
    "                    \n",
    "                    # B, S, H = x_c.size() <- did this in model\n",
    "                    # x_c = x_c.view(B*S, H)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x_c.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    mse = sum(losses) / counts\n",
    "    return mse, embedding_list, label_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_one_datapoint_features(args, model, mixer_phi, embed_type, n_t, n_c):\n",
    "    assert args.model_no_context == False\n",
    "    \n",
    "    args.embed_test = 'lastlayer_ours_best'\n",
    "    \n",
    "    path = f\"/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1/{args.embed_test}_\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    if args.seed == 42:\n",
    "        f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}.npz'\n",
    "    else:\n",
    "        f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}_{args.seed}.npz'\n",
    "    \n",
    "    if os.path.exists(f_path):\n",
    "        print(f\"⏩ {f_path} already exists. Skipping...\") \n",
    "        return\n",
    "    \n",
    "    if args.seed == 42:\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        set_seed(args.seed)\n",
    "    args.batch_size = 1\n",
    "    args.tsne_plot = True # because of get_dataset\n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    args.specify_ood_dataset = [d for d in all_candidates if d != args.dataset]\n",
    "    trainloader_test, _, mvalidloader_test, _, contextloader_test, ood1_trainloader_test, ood2_trainloader_test = get_dataset(args=args, test=True)\n",
    "    \n",
    "    if \"ood\" not in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood1' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood1_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood2' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood2_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    all_embeddings = torch.cat(embedding_list, dim=0)\n",
    "    all_labels = np.concatenate(label_list, axis=0)\n",
    "    all_losses = torch.cat(loss_list, dim=0)\n",
    "\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_losses = torch.tensor(all_losses)\n",
    "                \n",
    "    all_embeddings_np = all_embeddings.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    all_losses_np = all_losses.numpy()\n",
    "    \n",
    "    \n",
    "    np.savez(f_path, embeddings=all_embeddings_np, labels=all_labels_np, losses=all_losses_np)\n",
    "    print(f'>>> saved {f_path}')\n",
    "    \n",
    "    if 'ood1' in embed_type:\n",
    "        ood1_trainloader_test._iterator._shutdown_workers()\n",
    "    elif 'ood2' in embed_type:\n",
    "        ood2_trainloader_test._iterator._shutdown_workers()\n",
    "    else:\n",
    "        trainloader_test._iterator._shutdown_workers()\n",
    "        if 'context' in embed_type:\n",
    "            contextloader_test._iterator._shutdown_workers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(data):\n",
    "\n",
    "    model = data['model']\n",
    "    mixer_phi = data['mixer_phi']\n",
    "    optimizer = data['optimizer']\n",
    "    mixer_optimizer = data['mixer_optimizer']\n",
    "    \n",
    "    ltmse, lvmse, vmse, tmse = data['ltmse'], data['lvmse'], data['vmse'], data['tmse ']\n",
    "    \n",
    "    print('>> ltmse ', ltmse)\n",
    "    print('>> tmse ', tmse)\n",
    "    print('>> lvmse ', lvmse)\n",
    "    print('>> vmse ', vmse)\n",
    "    \n",
    "    args_ = data['args']\n",
    "\n",
    "    args = get_arguments()\n",
    "\n",
    "    for k, v in args_.items():\n",
    "        setattr(args, k, v)\n",
    "\n",
    "    if args.seed == 42:\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    model = get_model(args=args)\n",
    "    mixer_phi = get_mixer(args=args)\n",
    "    # optimizer = get_optimizer(optimizer=args.optimizer, model=model, lr=args.lr, wd=args.wd)\n",
    "    # optimizermixer = None if mixer_phi is None else get_optimizer(optimizer=args.optimizer, model=mixer_phi, lr=args.clr, wd=args.cwd)\n",
    "\n",
    "    model.load_state_dict(data['model'])\n",
    "    mixer_phi.load_state_dict(data['mixer_phi'])\n",
    "    # optimizer.load_state_dict(data['optimizer'])\n",
    "    # mixer_optimizer.load_state_dict(data['mixer_optimizer'])\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    mixer_phi = mixer_phi.to(args.device)\n",
    "    \n",
    "    # for (n_t, n_c) in [(5, 10), (5, 100), (10, 5), (10, 100), (100, 5), (100, 10)]:\n",
    "    # for (n_t, n_c) in [(5, 10), (5, 50), (5, 100), (10, 5), (10, 40), (10, 100), (40, 5), (40, 10), (100, 5),]:\n",
    "    for (n_t, n_c) in [(10, 100),]:\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"context_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_context\", n_t, n_c)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood1_none\", 500, 10)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood2_none\", 500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_0.pth\n",
      ">> ltmse  0.4183902328160928\n",
      ">> tmse  0.4232667506366655\n",
      ">> lvmse  0.2904639701048533\n",
      ">> vmse  0.28735986749331155\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_694555/71459262.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_losses = torch.tensor(all_losses)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_0.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_0.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_0.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_0.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_0.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_1.pth\n",
      ">> ltmse  0.41538338675938624\n",
      ">> tmse  0.40172440789450053\n",
      ">> lvmse  1.2874340097109476\n",
      ">> vmse  0.5021938800811767\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_1.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_1.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_1.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_1.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_1.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_2.pth\n",
      ">> ltmse  0.330110787880653\n",
      ">> tmse  0.38004695784741793\n",
      ">> lvmse  0.6410058975219727\n",
      ">> vmse  0.4542206605275472\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_2.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_2.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_2.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_2.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_2.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_3.pth\n",
      ">> ltmse  0.38749864831052977\n",
      ">> tmse  0.35848932348448653\n",
      ">> lvmse  0.8753785133361817\n",
      ">> vmse  0.6702957113583883\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_3.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_3.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_3.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_3.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_3.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_4.pth\n",
      ">> ltmse  0.3375574534532727\n",
      ">> tmse  0.3538180144115545\n",
      ">> lvmse  0.5753152728080749\n",
      ">> vmse  0.42457122306029\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_4.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_4.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_4.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_4.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_4.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_5.pth\n",
      ">> ltmse  0.3711286497973967\n",
      ">> tmse  0.4306569819686295\n",
      ">> lvmse  0.8985251188278198\n",
      ">> vmse  0.431103515625\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_5.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_5.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_5.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_5.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_5.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_6.pth\n",
      ">> ltmse  0.3402354040603409\n",
      ">> tmse  0.3727251723967213\n",
      ">> lvmse  0.47314394215742744\n",
      ">> vmse  0.3901380091905594\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_6.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_6.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_6.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_6.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_6.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_7.pth\n",
      ">> ltmse  0.3426607055463891\n",
      ">> tmse  0.3995719993489793\n",
      ">> lvmse  0.7555177330970764\n",
      ">> vmse  0.5263815800348918\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_7.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_7.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_7.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_7.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_7.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_8.pth\n",
      ">> ltmse  0.3392701374090415\n",
      ">> tmse  0.3740021299922663\n",
      ">> lvmse  0.6228271981080373\n",
      ">> vmse  0.4581676801045736\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_8.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_8.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_8.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_8.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_8.npz\n",
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/Model_dsets_nk1_bit_['3a4', 'cb1']_9.pth\n",
      ">> ltmse  0.38683933768494017\n",
      ">> tmse  0.39759707597420846\n",
      ">> lvmse  0.29545204440752665\n",
      ">> vmse  0.28914978007475534\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none_9.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none_9.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context_9.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_9.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_9.npz\n",
      "\n",
      "🏁 All models loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory containing .pth files\n",
    "tsne_model_dir = '/c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue/ours_best/'\n",
    "os.makedirs(tsne_model_dir, exist_ok=True)\n",
    "# List all .pth files\n",
    "# pth_files = [\"Model_dsets_nk1_bit_['3a4', 'cb1'].pth\"]\n",
    "# pth_files = [\"Model_dsets_nk1_bit_['hivint', 'tdi'].pth\"]\n",
    "pth_files = sorted([f for f in os.listdir(tsne_model_dir) if f.endswith('.pth')])\n",
    "\n",
    "# Load each file\n",
    "for i, f in enumerate(pth_files):\n",
    "    # if i > 5:\n",
    "    #     break\n",
    "    file_path = os.path.join(tsne_model_dir, f)\n",
    "    print(f\"🚀 Loading {file_path}\")\n",
    "    \n",
    "    data = torch.load(file_path)\n",
    "    save_features(data)\n",
    "    # Now 'data' contains the loaded model or state dict or whatever was saved\n",
    "    # You can process it here if needed\n",
    "    # For example, just printing some keys if it's a checkpoint\n",
    "    # if isinstance(data, dict):\n",
    "    #     print(f\"✅ Loaded {f}: keys = {list(data.keys())}\")\n",
    "    # else:\n",
    "    #     print(f\"✅ Loaded {f}: type = {type(data)}\")\n",
    "\n",
    "print(\"\\n🏁 All models loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ cuML not available, falling back to CPU openTSNE\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "🚀 Processing group dsets_dpp4_bit_500_10\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_100_5\n",
      "✅ Loaded dsets_dpp4_count_100_5_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_dpp4_count_100_5_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_dpp4_count_100_5_train_none.npz: embeddings (100, 64), labels (100,)\n",
      "✅ Combined embeddings shape: (1100, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_100_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_10_100\n",
      "✅ Loaded dsets_dpp4_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_dpp4_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_dpp4_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (2010, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_100_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_10_40\n",
      "✅ Loaded dsets_dpp4_count_10_40_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_dpp4_count_10_40_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_dpp4_count_10_40_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (810, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_40_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_10_5\n",
      "✅ Loaded dsets_dpp4_count_10_5_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_dpp4_count_10_5_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_dpp4_count_10_5_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (110, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_10_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_40_10\n",
      "✅ Loaded dsets_dpp4_count_40_10_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_dpp4_count_40_10_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_dpp4_count_40_10_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "✅ Combined embeddings shape: (840, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_40_10_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_40_5\n",
      "✅ Loaded dsets_dpp4_count_40_5_context_none.npz: embeddings (200, 64), labels (200,)\n",
      "✅ Loaded dsets_dpp4_count_40_5_train_context.npz: embeddings (200, 64), labels (200,)\n",
      "✅ Loaded dsets_dpp4_count_40_5_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "✅ Combined embeddings shape: (440, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_40_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_500_10\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_5_100\n",
      "✅ Loaded dsets_dpp4_count_5_100_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_dpp4_count_5_100_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_dpp4_count_5_100_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (1005, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_5_100_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_5_10\n",
      "✅ Loaded dsets_dpp4_count_5_10_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_dpp4_count_5_10_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_dpp4_count_5_10_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (105, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_5_10_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_dpp4_count_5_50\n",
      "✅ Loaded dsets_dpp4_count_5_50_context_none.npz: embeddings (250, 64), labels (250,)\n",
      "✅ Loaded dsets_dpp4_count_5_50_train_context.npz: embeddings (250, 64), labels (250,)\n",
      "✅ Loaded dsets_dpp4_count_5_50_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (505, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_dpp4_count_5_50_tsne_combined.pdf\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "🚀 Processing group dsets_hivprot_bit_500_10\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_100_5\n",
      "✅ Loaded dsets_hivprot_count_100_5_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_hivprot_count_100_5_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_hivprot_count_100_5_train_none.npz: embeddings (100, 64), labels (100,)\n",
      "✅ Combined embeddings shape: (1100, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_100_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_10_100\n",
      "✅ Loaded dsets_hivprot_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_hivprot_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_hivprot_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (2010, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_100_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_10_40\n",
      "✅ Loaded dsets_hivprot_count_10_40_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_hivprot_count_10_40_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_hivprot_count_10_40_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (810, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_40_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_10_5\n",
      "✅ Loaded dsets_hivprot_count_10_5_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_hivprot_count_10_5_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_hivprot_count_10_5_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (110, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_10_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_40_10\n",
      "✅ Loaded dsets_hivprot_count_40_10_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_hivprot_count_40_10_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_hivprot_count_40_10_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "✅ Combined embeddings shape: (840, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_40_10_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_40_5\n",
      "✅ Loaded dsets_hivprot_count_40_5_context_none.npz: embeddings (200, 64), labels (200,)\n",
      "✅ Loaded dsets_hivprot_count_40_5_train_context.npz: embeddings (200, 64), labels (200,)\n",
      "✅ Loaded dsets_hivprot_count_40_5_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "✅ Combined embeddings shape: (440, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_40_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_500_10\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_5_100\n",
      "✅ Loaded dsets_hivprot_count_5_100_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_hivprot_count_5_100_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_hivprot_count_5_100_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (1005, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_5_100_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_5_10\n",
      "✅ Loaded dsets_hivprot_count_5_10_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_hivprot_count_5_10_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_hivprot_count_5_10_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (105, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_5_10_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_hivprot_count_5_50\n",
      "✅ Loaded dsets_hivprot_count_5_50_context_none.npz: embeddings (250, 64), labels (250,)\n",
      "✅ Loaded dsets_hivprot_count_5_50_train_context.npz: embeddings (250, 64), labels (250,)\n",
      "✅ Loaded dsets_hivprot_count_5_50_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (505, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_hivprot_count_5_50_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_bit_100_100\n",
      "\n",
      "🚀 Processing group dsets_nk1_bit_100_10\n",
      "\n",
      "🚀 Processing group dsets_nk1_bit_100_40\n",
      "\n",
      "🚀 Processing group dsets_nk1_bit_100_50\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "🚀 Processing group dsets_nk1_bit_5000_10\n",
      "\n",
      "🚀 Processing group dsets_nk1_bit_500_10\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "⏩ /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_100_5\n",
      "✅ Loaded dsets_nk1_count_100_5_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_nk1_count_100_5_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_nk1_count_100_5_train_none.npz: embeddings (100, 64), labels (100,)\n",
      "✅ Combined embeddings shape: (1100, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_100_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_10_100\n",
      "✅ Loaded dsets_nk1_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_nk1_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_nk1_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (2010, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_100_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_10_40\n",
      "✅ Loaded dsets_nk1_count_10_40_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_nk1_count_10_40_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_nk1_count_10_40_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (810, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_40_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_10_5\n",
      "✅ Loaded dsets_nk1_count_10_5_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_nk1_count_10_5_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_nk1_count_10_5_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Combined embeddings shape: (110, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_10_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_40_10\n",
      "✅ Loaded dsets_nk1_count_40_10_context_none.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_nk1_count_40_10_train_context.npz: embeddings (400, 64), labels (400,)\n",
      "✅ Loaded dsets_nk1_count_40_10_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "✅ Combined embeddings shape: (840, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_40_10_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_40_5\n",
      "✅ Loaded dsets_nk1_count_40_5_context_none.npz: embeddings (200, 64), labels (200,)\n",
      "✅ Loaded dsets_nk1_count_40_5_train_context.npz: embeddings (200, 64), labels (200,)\n",
      "✅ Loaded dsets_nk1_count_40_5_train_none.npz: embeddings (40, 64), labels (40,)\n",
      "✅ Combined embeddings shape: (440, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_40_5_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_500_10\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_5_100\n",
      "✅ Loaded dsets_nk1_count_5_100_context_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_nk1_count_5_100_train_context.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_nk1_count_5_100_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (1005, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_5_100_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_5_10\n",
      "✅ Loaded dsets_nk1_count_5_10_context_none.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_nk1_count_5_10_train_context.npz: embeddings (50, 64), labels (50,)\n",
      "✅ Loaded dsets_nk1_count_5_10_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (105, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_5_10_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group dsets_nk1_count_5_50\n",
      "✅ Loaded dsets_nk1_count_5_50_context_none.npz: embeddings (250, 64), labels (250,)\n",
      "✅ Loaded dsets_nk1_count_5_50_train_context.npz: embeddings (250, 64), labels (250,)\n",
      "✅ Loaded dsets_nk1_count_5_50_train_none.npz: embeddings (5, 64), labels (5,)\n",
      "✅ Combined embeddings shape: (505, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_count_5_50_tsne_combined.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"✅ Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"⏩ {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        #####\n",
    "        if 'ood' in file_path:\n",
    "            continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"✅ Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    \n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "    if 'ood' not in f:\n",
    "        groups[prefix].append(f)\n",
    "    \n",
    "    prefix_ = '_'.join(parts[:3])\n",
    "    if prefix_ in prefix and 'ood' in f:\n",
    "        groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"⏩ {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        if len(group_files) != 5:\n",
    "            print('group_files ', len(group_files))\n",
    "            continue\n",
    "        #####\n",
    "        # if 'ood' in file_path:\n",
    "        #     continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "    green_circle = mlines.Line2D([], [], color='#48b33c', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "    bluegreen_circle = mlines.Line2D([], [], color='#3cadb3', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood1_baseline_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none.npz'\n",
    "ood1_ours_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none.npz'\n",
    "ood2_baseline_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood2_none.npz'\n",
    "ood2_ours_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none.npz'\n",
    "\n",
    "compare_histogram(ood1_baseline_path, ood1_ours_path, 1)\n",
    "compare_histogram(ood2_baseline_path, ood2_ours_path, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ cuML not available, falling back to CPU openTSNE\n",
      "\n",
      "🚀 Processing group dsets_nk1_bit_10_100\n",
      "✅ Loaded dsets_nk1_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_nk1_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_nk1_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Loaded dsets_nk1_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_nk1_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Combined embeddings shape: (3010, 64)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_tsne_combined_all_final.pdf\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_10_100_tsne_combined_all_final.png\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# # try:\n",
    "# #     import cupy as cp\n",
    "# #     from cuml.manifold import TSNE as cuTSNE\n",
    "# #     gpu_available = True\n",
    "# #     print(\"✅ Using GPU cuML TSNE\")\n",
    "# # except ImportError:\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# gpu_available = False\n",
    "# print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "    \n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "#     if 'dsets_nk1_bit_10_100' in prefix:\n",
    "#         prefix_ = '_'.join(parts[:3])\n",
    "        \n",
    "#         if 'ood' not in f:\n",
    "#             groups[prefix].append(f)\n",
    "        \n",
    "#         # print('prefix ', prefix)\n",
    "#         # print('prefix_ ', prefix_)\n",
    "#         # print('f')\n",
    "#     # if prefix_ in prefix and 'ood' in f:\n",
    "#     #     groups[prefix].append(f)\n",
    "    \n",
    "#     if 'dsets_nk1_bit_500_10_ood1_none.npz' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "#     if 'dsets_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path_pdf = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all_final.pdf\")\n",
    "#     save_path_png = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all_final.png\")\n",
    "    \n",
    "#     # if \"dpp4_bit\" in save_path:\n",
    "#     #     continue\n",
    "#     # --- Skip if already exists ---\n",
    "#     if os.path.exists(save_path_pdf):\n",
    "#         print(f\"⏩ {save_path_pdf} already exists. Skipping...\")\n",
    "#         continue\n",
    "    \n",
    "#     if os.path.exists(save_path_png):\n",
    "#         print(f\"⏩ {save_path_png} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "#         if len(group_files) != 5:\n",
    "#             print('group_files ', len(group_files))\n",
    "#             continue\n",
    "#         #####\n",
    "#         # if 'ood' in file_path:\n",
    "#         #     continue\n",
    "        \n",
    "#         # if 'train' not in file_path and 'context' not in file_path:\n",
    "#         #     continue\n",
    "#         #####\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "\n",
    "#         print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     # if gpu_available:\n",
    "#     #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "#     #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "#     #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "#     #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "#     # else:\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     import matplotlib.patches as mpatches\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Set global font\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     # Define color mapping\n",
    "#     # color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "#     color_map = {0: '#FFA500', 1: '#2E8B57', -1: '#9B30FF', 3:'#D62728', 4:'#808080'}  # orange and blue\n",
    "#     colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "#     # Set point sizes\n",
    "#     # sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "#     sizes = []\n",
    "#     for label in all_labels:\n",
    "#         if label == 1:         # mixup (w/o context)\n",
    "#             sizes.append(60)   # larger to emphasize\n",
    "#         elif label == -1:      # mixup (context)\n",
    "#             sizes.append(30)\n",
    "#         elif label == 0:       # mixup\n",
    "#             sizes.append(30)\n",
    "#         elif label in [3, 4]:  # OOD\n",
    "#             sizes.append(40)   # fairly large to stand out\n",
    "#         else:\n",
    "#             sizes.append(15)   # default fallback\n",
    "\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Slight soft grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Hide axis labels but keep grid\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # --- Add better legend ---\n",
    "#     import matplotlib.lines as mlines\n",
    "\n",
    "#     # Define custom legend handles (use Line2D for circles)\n",
    "#     orange_circle = mlines.Line2D([], [], color='#FFA500', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#2E8B57', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#     red_circle = mlines.Line2D([], [], color='#9B30FF', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "#     green_circle = mlines.Line2D([], [], color='#D62728', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "#     bluegreen_circle = mlines.Line2D([], [], color='#808080', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "#     # Add legend inside plot (upper right)\n",
    "#     plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "#             loc='upper right',  # inside the plot, top right\n",
    "#             framealpha=0.6,\n",
    "#             prop={'size': 12},\n",
    "#             handletextpad=0.4,\n",
    "#             borderpad=0.5)\n",
    "\n",
    "#     # Tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save figure\n",
    "#     plt.savefig(save_path_pdf, dpi=300)\n",
    "#     print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path_pdf}\")\n",
    "#     plt.savefig(save_path_png, dpi=300)\n",
    "#     print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path_png}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Processing group dsets_nk1_bit_10_100\n",
      "✅ Loaded dsets_nk1_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_nk1_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "✅ Loaded dsets_nk1_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "✅ Loaded dsets_nk1_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Loaded dsets_nk1_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "✅ Combined embeddings shape: (3010, 64)\n",
      "✅ Saved all t-SNE variations for dsets_nk1_bit_10_100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by prefix ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    if 'dsets_nk1_bit_10_100' in f or 'dsets_nk1_bit_500_10_ood1_none.npz' in f or 'dsets_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "        groups['dsets_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# --- Function to save plot with label exclusions ---\n",
    "def plot_tsne(embeddings_2d, all_labels, excluded_labels, save_prefix):\n",
    "    filtered_indices = [i for i, label in enumerate(all_labels) if label not in excluded_labels]\n",
    "    filtered_embeddings = embeddings_2d[filtered_indices]\n",
    "    filtered_labels = all_labels[filtered_indices]\n",
    "\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#228B22', 3: '#8B008B', 4: '#808080'}\n",
    "    sizes = []\n",
    "    colors = []\n",
    "    for label in filtered_labels:\n",
    "        sizes.append(70 if label == 1 else 18 if label in [3, 4] else 13)\n",
    "        colors.append(color_map[label])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_embeddings[:, 0], filtered_embeddings[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.box(False)\n",
    "\n",
    "    import matplotlib.lines as mlines\n",
    "    legend_handles = [\n",
    "        mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours'),\n",
    "        mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)'),\n",
    "        mlines.Line2D([], [], color='#228B22', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "    ]\n",
    "    if 3 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#8B008B', marker='o', linestyle='None', markersize=8, label='OOD'))\n",
    "    if 4 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#808080', marker='o', linestyle='None', markersize=8, label='OOD'))\n",
    "\n",
    "    plt.legend(handles=legend_handles, loc='upper right', framealpha=0.6, prop={'size': 12})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_prefix}.pdf\", dpi=300)\n",
    "    plt.savefig(f\"{save_prefix}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    print(f\"\\n🚀 Processing group {prefix}\")\n",
    "    all_embeddings, all_labels = [], []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        data = np.load(file_path)\n",
    "        all_embeddings.append(data['embeddings'])\n",
    "        all_labels.append(data['labels'])\n",
    "        print(f\"✅ Loaded {f}: embeddings {data['embeddings'].shape}, labels {data['labels'].shape}\")\n",
    "\n",
    "    if not all_embeddings:\n",
    "        continue\n",
    "\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # Run t-SNE using scikit-learn\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Save three filtered plots\n",
    "    base_path = os.path.join(tsne_dir, f\"{prefix}_tsne\")\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[3, 4], save_prefix=f\"{base_path}_no_ood\")\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[4], save_prefix=f\"{base_path}_no_ood2\")\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[3], save_prefix=f\"{base_path}_no_ood1\")\n",
    "    print(f\"✅ Saved all t-SNE variations for {prefix}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
