{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from main_merck_all_real_mixup_n_context_n_mvalid import get_dataset\n",
    "from utils import set_seed, get_optimizer, InfIterator\n",
    "from arguments import get_arguments\n",
    "from main_origin import get_model\n",
    "from setenc import get_mixer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y_hat, y, test=False):\n",
    "    return F.mse_loss(y.cuda().squeeze(), y_hat.cuda().squeeze())\n",
    "\n",
    "def test(args, dataloader, contextloader=None, model=None, mixer_phi=None, embed_type=None, n_t=10, n_c=5):\n",
    "    model.eval()\n",
    "    mixer_phi.eval()\n",
    "    embedding_list = []\n",
    "    label_list= []\n",
    "    loss_list = []\n",
    "    # print('model ', model)\n",
    "    # print('mixer_phi ', mixer_phi)\n",
    "    if embed_type == \"train_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 't_x.pt')\n",
    "                    torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"ood1_none\" or embed_type == \"ood2_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 't_x.pt')\n",
    "                #     torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"train_context\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'tc_x.pt')\n",
    "                    torch.save(y, 'tc_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                        \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'tc_x_c.pt')\n",
    "                        torch.save(y_c, 'tc_y_c.pt')\n",
    "                        \n",
    "                        \n",
    "                    # print('$$$$$$')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    # context_samples.append(x_c)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    elif embed_type == \"context_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'c_x.pt')\n",
    "                    torch.save(y, 'c_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                    \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'c_x_c.pt')\n",
    "                        torch.save(y_c, 'c_y_c.pt')\n",
    "                    # print('====')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    \n",
    "                    # context_samples.append(x_c)\n",
    "                    \n",
    "                    # B, S, H = x_c.size() <- did this in model\n",
    "                    # x_c = x_c.view(B*S, H)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x_c.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    mse = sum(losses) / counts\n",
    "    return mse, embedding_list, label_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_one_datapoint_features(args, model, mixer_phi, embed_type, n_t, n_c):\n",
    "    assert args.model_no_context == False\n",
    "    \n",
    "    args.embed_test = 'lastlayer_ours_best'\n",
    "    \n",
    "    path = f\"/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_MIXUP_BILEVEL/{args.embed_test}_\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    if args.seed == 42:\n",
    "        f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_MIXUP_BILEVEL/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}.npz'\n",
    "    else:\n",
    "        f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_MIXUP_BILEVEL/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}_{args.seed}.npz'\n",
    "        \n",
    "    \n",
    "    if os.path.exists(f_path):\n",
    "        print(f\"â© {f_path} already exists. Skipping...\") \n",
    "        return\n",
    "    \n",
    "    if args.seed == 42:\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        set_seed(args.seed)\n",
    "        \n",
    "    args.batch_size = 1\n",
    "    args.tsne_plot = True # because of get_dataset\n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    args.specify_ood_dataset = [d for d in all_candidates if d != args.dataset]\n",
    "    trainloader_test, _, mvalidloader_test, _, contextloader_test, ood1_trainloader_test, ood2_trainloader_test = get_dataset(args=args, test=True)\n",
    "    \n",
    "    if \"ood\" not in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood1' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood1_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood2' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood2_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    # for i, emb in enumerate(embedding_list):\n",
    "    #     print(f\"Tensor {i}: {emb.shape}\")\n",
    "    \n",
    "    all_embeddings = torch.cat(embedding_list, dim=0)\n",
    "    all_labels = np.concatenate(label_list, axis=0)\n",
    "    all_losses = torch.cat(loss_list, dim=0)\n",
    "\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_losses = torch.tensor(all_losses)\n",
    "                \n",
    "    all_embeddings_np = all_embeddings.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    all_losses_np = all_losses.numpy()\n",
    "    \n",
    "    \n",
    "    np.savez(f_path, embeddings=all_embeddings_np, labels=all_labels_np, losses=all_losses_np)\n",
    "    print(f'>>> saved {f_path}')\n",
    "    \n",
    "    if 'ood1' in embed_type:\n",
    "        ood1_trainloader_test._iterator._shutdown_workers()\n",
    "    elif 'ood2' in embed_type:\n",
    "        ood2_trainloader_test._iterator._shutdown_workers()\n",
    "    else:\n",
    "        trainloader_test._iterator._shutdown_workers()\n",
    "        if 'context' in embed_type:\n",
    "            contextloader_test._iterator._shutdown_workers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(data):\n",
    "\n",
    "    model = data['model']\n",
    "    mixer_phi = data['mixer_phi']\n",
    "    optimizer = data['optimizer']\n",
    "    mixer_optimizer = data['mixer_optimizer']\n",
    "    \n",
    "    ltmse, lvmse, vmse, tmse = data['ltmse'], data['lvmse'], data['vmse'], data['tmse']\n",
    "    \n",
    "    print('>> ltmse ', ltmse)\n",
    "    print('>> tmse ', tmse)\n",
    "    print('>> lvmse ', lvmse)\n",
    "    print('>> vmse ', vmse)\n",
    "    \n",
    "    args_ = data['args']\n",
    "\n",
    "    args = get_arguments()\n",
    "\n",
    "    for k, v in args_.items():\n",
    "        setattr(args, k, v)\n",
    "        \n",
    "    os.environ['MIX_TYPE'] = 'MIXUP_BILEVEL'\n",
    "\n",
    "    if args.seed == 42:\n",
    "        set_seed(0)\n",
    "    else:\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    model = get_model(args=args)\n",
    "    mixer_phi = get_mixer(args=args)\n",
    "    # optimizer = get_optimizer(optimizer=args.optimizer, model=model, lr=args.lr, wd=args.wd)\n",
    "    # optimizermixer = None if mixer_phi is None else get_optimizer(optimizer=args.optimizer, model=mixer_phi, lr=args.clr, wd=args.cwd)\n",
    "\n",
    "    model.load_state_dict(data['model'])\n",
    "    mixer_phi.load_state_dict(data['mixer_phi'])\n",
    "    # optimizer.load_state_dict(data['optimizer'])\n",
    "    # mixer_optimizer.load_state_dict(data['mixer_optimizer'])\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    mixer_phi = mixer_phi.to(args.device)\n",
    "    \n",
    "    # for (n_t, n_c) in [(5, 10), (5, 100), (10, 5), (10, 100), (100, 5), (100, 10)]:\n",
    "    # for (n_t, n_c) in [(5, 10), (5, 50), (5, 100), (10, 5), (10, 40), (10, 100), (40, 5), (40, 10), (100, 5),]:\n",
    "    for (n_t, n_c) in [(10, 100)]: # (10, 40), \n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"context_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_context\", n_t, n_c)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood1_none\", 500, 10)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood2_none\", 500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=Sun May 25 17:57:14 2025\n",
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ NVITOP 1.5.0       Driver Version: 555.42.06      CUDA Driver Version: 12.5 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ GPU  Name        Persistence-Mâ”‚ Bus-Id        Disp.A â”‚ Volatile Uncorr. ECC â”‚\n",
      "â”‚ Fan  Temp  Perf  Pwr:Usage/Capâ”‚         Memory-Usage â”‚ GPU-Util  Compute M. â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚\u001b[33m   0  RTX A6000           Off  \u001b[0mâ”‚\u001b[33m 00000000:1E:00.0 Off \u001b[0mâ”‚\u001b[33m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[33m 30%   27C    P8    43W / 300W \u001b[0mâ”‚\u001b[33m   6185MiB / 47.99GiB \u001b[0mâ”‚\u001b[33m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   1  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:1F:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   32C    P2    64W / 300W \u001b[0mâ”‚\u001b[31m  45.91GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   2  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:20:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   56C    P2   293W / 300W \u001b[0mâ”‚\u001b[31m  23.86GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m    100%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   3  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:21:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   22C    P8    18W / 300W \u001b[0mâ”‚\u001b[31m  42.09GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m      0%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   4  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:22:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   41C    P2   287W / 300W \u001b[0mâ”‚\u001b[31m  44.88GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m    100%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   5  RTX A6000           Off  \u001b[0mâ”‚\u001b[31m 00000000:23:00.0 Off \u001b[0mâ”‚\u001b[31m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[31m 30%   45C    P2   294W / 300W \u001b[0mâ”‚\u001b[31m  37.36GiB / 47.99GiB \u001b[0mâ”‚\u001b[31m    100%      Default \u001b[0mâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[33m   6  RTX A6000           Off  \u001b[0mâ”‚\u001b[33m 00000000:24:00.0 Off \u001b[0mâ”‚\u001b[33m                  N/A \u001b[0mâ”‚\n",
      "â”‚\u001b[33m 30%   41C    P2    91W / 300W \u001b[0mâ”‚\u001b[33m  30.85GiB / 47.99GiB \u001b[0mâ”‚\u001b[33m     10%      Default \u001b[0mâ”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
      "\u001b[1m\u001b[36m[ CPU: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 80.1%     ]\u001b[0m  \u001b[1m( Load Average: 187.6 184.6 183.0 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 50.1%              ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ MAX ]\u001b[0m\n",
      "\n",
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ Processes:                                                      \u001b[1m\u001b[35mjinakim\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32mai16\u001b[0m â”‚\n",
      "â”‚ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM       TIME  COMMAND     â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚\u001b[33m   0\u001b[0m 2745748 C jinakim 410.0MiB   0     0 874.2   3.5      10:14  /c2/jinak.. â”‚\n",
      "â”‚\u001b[33m   0\u001b[0m \u001b[2m2036449 C  namsan  5760MiB   0     0   0.0   1.2  26.3 days  /c2/namsa..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   1\u001b[0m \u001b[2m3158080 C soyeong 45.90GiB   0     0 596.8   2.6   5.0 days  python /c..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   2\u001b[0m \u001b[2m2660891 C dohyeon 23.82GiB 100    38 100.3   4.7    1:41:12  python tr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   3\u001b[0m \u001b[2m2595210 C    suji 42.06GiB   0     0 102.8  15.2    4:26:25  python sr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   4\u001b[0m \u001b[2m1639820 C yukyeo+ 44.86GiB  99    76 104.3   1.2   64:08:11  python tr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[31m   5\u001b[0m \u001b[2m2666077 C dohyeon 37.32GiB  99    38 104.6   4.7    1:36:41  python tr..\u001b[0m â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚\u001b[33m   6\u001b[0m \u001b[2m3175157 C soyeong 30.84GiB  30    22 112.5   2.5   5.0 days  python /c..\u001b[0m â”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
      "\u001b[1m\u001b[31mERROR:\u001b[0m Failed to initialize `curses` (curs_set() returned ERR)\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_dsets_dpp4_bit_['None'].pth\n",
      ">> ltmse  1.2237557078340526\n",
      ">> tmse  1.2237557078340526\n",
      ">> lvmse  0.29942280385229325\n",
      ">> vmse  0.29942280385229325\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2747665/2716295367.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_losses = torch.tensor(all_losses)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_bit_10_100_train_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_bit_10_100_context_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_bit_10_100_train_context.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_bit_500_10_ood2_none.npz\n",
      "ğŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_dsets_dpp4_count_['None'].pth\n",
      ">> ltmse  1.4055574846734045\n",
      ">> tmse  1.4055574995964255\n",
      ">> lvmse  0.47119781374931335\n",
      ">> vmse  0.47119779719246757\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_count_10_100_train_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_count_10_100_context_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_count_10_100_train_context.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='dpp4' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_dpp4_count_500_10_ood2_none.npz\n",
      "ğŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_dsets_hivprot_bit_['None'].pth\n",
      ">> ltmse  0.751329948653036\n",
      ">> tmse  0.751329948653036\n",
      ">> lvmse  0.19542305171489716\n",
      ">> vmse  0.19542305171489716\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_bit_10_100_train_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_bit_10_100_context_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_bit_10_100_train_context.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_bit_500_10_ood2_none.npz\n",
      "ğŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_dsets_hivprot_count_['None'].pth\n",
      ">> ltmse  0.7815900943172511\n",
      ">> tmse  0.7815901023238453\n",
      ">> lvmse  0.3295025408267975\n",
      ">> vmse  0.3295025289058685\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_count_10_100_train_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_count_10_100_context_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_count_10_100_train_context.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='hivprot' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_hivprot_count_500_10_ood2_none.npz\n",
      "ğŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_dsets_nk1_bit_['None'].pth\n",
      ">> ltmse  0.44753094966979934\n",
      ">> tmse  0.44753094966979934\n",
      ">> lvmse  0.31549898684024813\n",
      ">> vmse  0.31549898684024813\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_bit_10_100_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_bit_10_100_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none.npz\n",
      "ğŸš€ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/Model_dsets_nk1_count_['None'].pth\n",
      ">> ltmse  0.45588512517165564\n",
      ">> tmse  0.4558851240278184\n",
      ">> lvmse  0.413865997393926\n",
      ">> vmse  0.413865997393926\n",
      "loading deepsets\n",
      "DSEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): PermEquiMax(\n",
      "      (Gamma): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Lambda): Linear(in_features=512, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_count_10_100_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_count_10_100_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_count_10_100_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_count_500_10_ood1_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='count'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/dsets_nk1_count_500_10_ood2_none.npz\n",
      "\n",
      "ğŸ All models loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory containing .pth files\n",
    "tsne_model_dir = '/c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/ours_best/'\n",
    "os.makedirs(tsne_model_dir, exist_ok=True)\n",
    "# List all .pth files\n",
    "pth_files = sorted([f for f in os.listdir(tsne_model_dir) if f.endswith('.pth')])\n",
    "\n",
    "# Load each file\n",
    "for i, f in enumerate(pth_files):\n",
    "    # if i > 5:\n",
    "    #     break\n",
    "    file_path = os.path.join(tsne_model_dir, f)\n",
    "    print(f\"ğŸš€ Loading {file_path}\")\n",
    "    \n",
    "    data = torch.load(file_path)\n",
    "    save_features(data)\n",
    "    # Now 'data' contains the loaded model or state dict or whatever was saved\n",
    "    # You can process it here if needed\n",
    "    # For example, just printing some keys if it's a checkpoint\n",
    "    # if isinstance(data, dict):\n",
    "    #     print(f\"âœ… Loaded {f}: keys = {list(data.keys())}\")\n",
    "    # else:\n",
    "    #     print(f\"âœ… Loaded {f}: type = {type(data)}\")\n",
    "\n",
    "print(\"\\nğŸ All models loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final (real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing group dsets_dpp4_bit\n",
      "âœ… Loaded dsets_dpp4_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_dpp4_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_dpp4_bit\n",
      "\n",
      "ğŸš€ Processing group dsets_dpp4_count\n",
      "âœ… Loaded dsets_dpp4_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_dpp4_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_dpp4_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_dpp4_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_dpp4_count\n",
      "\n",
      "ğŸš€ Processing group dsets_hivprot_bit\n",
      "âœ… Loaded dsets_hivprot_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_hivprot_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_hivprot_bit\n",
      "\n",
      "ğŸš€ Processing group dsets_hivprot_count\n",
      "âœ… Loaded dsets_hivprot_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_hivprot_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_hivprot_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_hivprot_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_hivprot_count\n",
      "\n",
      "ğŸš€ Processing group dsets_nk1_bit\n",
      "âœ… Loaded dsets_nk1_bit_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_bit_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_bit_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_nk1_bit\n",
      "\n",
      "ğŸš€ Processing group dsets_nk1_count\n",
      "âœ… Loaded dsets_nk1_count_10_100_context_none.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_count_10_100_train_context.npz: embeddings (1000, 64), labels (1000,)\n",
      "âœ… Loaded dsets_nk1_count_10_100_train_none.npz: embeddings (10, 64), labels (10,)\n",
      "âœ… Loaded dsets_nk1_count_500_10_ood1_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Loaded dsets_nk1_count_500_10_ood2_none.npz: embeddings (500, 64), labels (500,)\n",
      "âœ… Combined embeddings shape: (3010, 64)\n",
      "âœ… Saved all t-SNE variations for dsets_nk1_count\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by prefix ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    if len(parts) < 4:\n",
    "        continue  # Skip malformed filenames\n",
    "\n",
    "    method = parts[0]  # dsets or strans\n",
    "    dataset = parts[1]  # e.g., dpp4\n",
    "    vector = parts[2]   # bit or count\n",
    "    key = f\"{method}_{dataset}_{vector}\"\n",
    "    groups[key].append(f)\n",
    "    \n",
    "# for f in files:\n",
    "#     if 'strans_nk1_bit_10_100' in f:\n",
    "#         groups['strans_nk1_bit_10_100'].append(f)\n",
    "#     elif 'strans_nk1_bit_500_10_ood1_none.npz' in f:\n",
    "#         groups['strans_nk1_bit_10_100'].append(f)\n",
    "#     elif 'strans_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "#         groups['strans_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# --- Function to save plot with label exclusions ---\n",
    "def plot_tsne(embeddings_2d, all_labels, excluded_labels, save_prefix, specify_ood_dataset):\n",
    "    filtered_indices = [i for i, label in enumerate(all_labels) if label not in excluded_labels]\n",
    "    filtered_embeddings = embeddings_2d[filtered_indices]\n",
    "    filtered_labels = all_labels[filtered_indices]\n",
    "\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#228B22', 3: '#8B008B', 4: '#B22222'}\n",
    "    sizes = []\n",
    "    colors = []\n",
    "    for label in filtered_labels:\n",
    "        sizes.append(70 if label == 1 else 18 if label in [3, 4] else 13)\n",
    "        colors.append(color_map[label])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_embeddings[:, 0], filtered_embeddings[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.box(False)\n",
    "\n",
    "    import matplotlib.lines as mlines\n",
    "    legend_handles = [\n",
    "        mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='mixup'),\n",
    "        mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='mixup (w/o context)'),\n",
    "        mlines.Line2D([], [], color='#228B22', marker='o', linestyle='None', markersize=8, label='mixup (context)')\n",
    "    ]\n",
    "    if 3 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#8B008B', marker='o', linestyle='None', markersize=8, label=f'OOD ({specify_ood_dataset[0]})'))\n",
    "    if 4 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#B22222', marker='o', linestyle='None', markersize=8, label=f'OOD ({specify_ood_dataset[1]})'))\n",
    "\n",
    "    plt.legend(handles=legend_handles, loc='upper right', framealpha=0.6, prop={'size': 12})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_prefix}_ALL.pdf\", dpi=300)\n",
    "    # plt.savefig(f\"{save_prefix}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    print(f\"\\nğŸš€ Processing group {prefix}\")\n",
    "    all_embeddings, all_labels = [], []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        data = np.load(file_path)\n",
    "        all_embeddings.append(data['embeddings'])\n",
    "        all_labels.append(data['labels'])\n",
    "        print(f\"âœ… Loaded {f}: embeddings {data['embeddings'].shape}, labels {data['labels'].shape}\")\n",
    "\n",
    "    if not all_embeddings:\n",
    "        continue\n",
    "\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # Run t-SNE using scikit-learn\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Save three filtered plots\n",
    "    base_path = os.path.join(tsne_dir, f\"{prefix}_tsne\")\n",
    "    \n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    specify_ood_dataset = [d for d in all_candidates if d not in prefix]\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[], save_prefix=f\"{base_path}\", specify_ood_dataset=specify_ood_dataset)\n",
    "    \n",
    "    # plot_tsne(embeddings_2d, all_labels, excluded_labels=[3, 4], save_prefix=f\"{base_path}_no_ood\")\n",
    "    # plot_tsne(embeddings_2d, all_labels, excluded_labels=[4], save_prefix=f\"{base_path}_no_ood2\")\n",
    "    # plot_tsne(embeddings_2d, all_labels, excluded_labels=[3], save_prefix=f\"{base_path}_no_ood1\")\n",
    "    print(f\"âœ… Saved all t-SNE variations for {prefix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ cuML not available, falling back to CPU openTSNE\n",
      "\n",
      "ğŸš€ Processing group strans_nk1_bit_10_100\n",
      "âœ… Loaded strans_nk1_bit_10_100_context_none.npz: embeddings (1000, 32), labels (1000,)\n",
      "âœ… Loaded strans_nk1_bit_10_100_train_context.npz: embeddings (1000, 32), labels (1000,)\n",
      "âœ… Loaded strans_nk1_bit_10_100_train_none.npz: embeddings (10, 32), labels (10,)\n",
      "âœ… Combined embeddings shape: (2010, 32)\n",
      "âœ… Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_10_100_tsne_combined.pdf\n",
      "\n",
      "ğŸš€ Processing group strans_nk1_bit_10_40\n",
      "âœ… Loaded strans_nk1_bit_10_40_context_none.npz: embeddings (400, 32), labels (400,)\n",
      "âœ… Loaded strans_nk1_bit_10_40_train_context.npz: embeddings (400, 32), labels (400,)\n",
      "âœ… Loaded strans_nk1_bit_10_40_train_none.npz: embeddings (10, 32), labels (10,)\n",
      "âœ… Combined embeddings shape: (810, 32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 84\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# --- Run t-SNE ---\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# if gpu_available:\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#     embeddings_gpu = cp.asarray(all_embeddings)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m     83\u001b[0m tsne \u001b[38;5;241m=\u001b[39m cpuTSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m embeddings_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# --- Plot ---\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[0;32m/c2/jinakim/miniconda3/envs/drug/lib/python3.9/site-packages/openTSNE/tsne.py:1252\u001b[0m, in \u001b[0;36mTSNE.fit\u001b[0;34m(self, X, affinities, initialization)\u001b[0m\n\u001b[1;32m   1247\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_initial(X, affinities, initialization)\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# Early exaggeration with lower momentum to allow points to find more\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;66;03m# easily move around and find their neighbors\u001b[39;00m\n\u001b[0;32m-> 1252\u001b[0m     \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_exaggeration_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexaggeration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_exaggeration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpropagate_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;66;03m# Restore actual affinity probabilities and increase momentum to get\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;66;03m# final, optimized embedding\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m     embedding\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[1;32m   1263\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter,\n\u001b[1;32m   1264\u001b[0m         exaggeration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexaggeration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         propagate_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1268\u001b[0m     )\n",
      "File \u001b[0;32m/c2/jinakim/miniconda3/envs/drug/lib/python3.9/site-packages/openTSNE/tsne.py:679\u001b[0m, in \u001b[0;36mTSNEEmbedding.optimize\u001b[0;34m(self, n_iter, inplace, propagate_exception, **gradient_descent_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m _handle_nice_params(embedding, optim_params)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# Run gradient descent with the embedding optimizer so gains are\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# properly updated and kept\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     error, embedding \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffinities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptim_params\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationInterrupt \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    684\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization was interrupted with callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/c2/jinakim/miniconda3/envs/drug/lib/python3.9/site-packages/openTSNE/tsne.py:1790\u001b[0m, in \u001b[0;36mgradient_descent.__call__\u001b[0;34m(self, embedding, P, n_iter, objective_function, learning_rate, momentum, exaggeration, dof, min_gain, max_grad_norm, max_step_norm, theta, n_interpolation_points, min_num_intervals, ints_in_interval, reference_embedding, n_jobs, use_callbacks, callbacks, callbacks_every_iters, verbose)\u001b[0m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# Evaluate error on 50 iterations for logging, or when callbacks\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m should_eval_error \u001b[38;5;241m=\u001b[39m should_call_callback \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m   1788\u001b[0m     (verbose \u001b[38;5;129;01mand\u001b[39;00m (iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 1790\u001b[0m error, gradient \u001b[38;5;241m=\u001b[39m \u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbh_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbh_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfft_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfft_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_eval_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshould_eval_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;66;03m# Clip gradients to avoid points shooting off. This can be an issue\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;66;03m# when applying transform and points are initialized so that the new\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;66;03m# points overlap with the reference points, leading to large\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;66;03m# gradients\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/c2/jinakim/miniconda3/envs/drug/lib/python3.9/site-packages/openTSNE/tsne.py:1482\u001b[0m, in \u001b[0;36mkl_divergence_bh\u001b[0;34m(embedding, P, dof, bh_params, reference_embedding, should_eval_error, n_jobs, **_)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tree\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;66;03m# Compute positive gradient\u001b[39;00m\n\u001b[0;32m-> 1482\u001b[0m sum_P, kl_divergence_ \u001b[38;5;241m=\u001b[39m \u001b[43m_tsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_positive_gradient_nn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_eval_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshould_eval_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;66;03m# Computing positive gradients summed up only unnormalized q_ijs, so we\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;66;03m# have to include normalziation term separately\u001b[39;00m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_eval_error:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"âœ… Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"â© {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸš€ Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        #####\n",
    "        if 'ood' in file_path:\n",
    "            continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='mixup')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='mixup (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='mixup (context)')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"âœ… Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"â© {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸš€ Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        #####\n",
    "        if 'ood' in file_path:\n",
    "            continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='mixup')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='mixup (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='mixup (context)')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# # try:\n",
    "# #     import cupy as cp\n",
    "# #     from cuml.manifold import TSNE as cuTSNE\n",
    "# #     gpu_available = True\n",
    "# #     print(\"âœ… Using GPU cuML TSNE\")\n",
    "# # except ImportError:\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# gpu_available = False\n",
    "# print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "    \n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "#     if 'ood' not in f:\n",
    "#         groups[prefix].append(f)\n",
    "    \n",
    "#     prefix_ = '_'.join(parts[:3])\n",
    "#     if prefix_ in prefix and 'ood' in f:\n",
    "#         groups[prefix].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all.pdf\")\n",
    "    \n",
    "#     # if \"dpp4_bit\" in save_path:\n",
    "#     #     continue\n",
    "#     # --- Skip if already exists ---\n",
    "#     if os.path.exists(save_path):\n",
    "#         print(f\"â© {save_path} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\nğŸš€ Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "#         if len(group_files) != 5:\n",
    "#             print('group_files ', len(group_files))\n",
    "#             continue\n",
    "#         #####\n",
    "#         # if 'ood' in file_path:\n",
    "#         #     continue\n",
    "        \n",
    "#         # if 'train' not in file_path and 'context' not in file_path:\n",
    "#         #     continue\n",
    "#         #####\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "\n",
    "#         print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     # if gpu_available:\n",
    "#     #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "#     #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "#     #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "#     #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "#     # else:\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     import matplotlib.patches as mpatches\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Set global font\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     # Define color mapping\n",
    "#     color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "#     colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "#     # Set point sizes\n",
    "#     sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Slight soft grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Hide axis labels but keep grid\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # --- Add better legend ---\n",
    "#     import matplotlib.lines as mlines\n",
    "\n",
    "#     # Define custom legend handles (use Line2D for circles)\n",
    "#     orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#     red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "#     green_circle = mlines.Line2D([], [], color='#48b33c', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "#     bluegreen_circle = mlines.Line2D([], [], color='#3cadb3', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "#     # Add legend inside plot (upper right)\n",
    "#     plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "#             loc='upper right',  # inside the plot, top right\n",
    "#             framealpha=0.6,\n",
    "#             prop={'size': 12},\n",
    "#             handletextpad=0.4,\n",
    "#             borderpad=0.5)\n",
    "\n",
    "#     # Tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save figure\n",
    "#     plt.savefig(save_path, dpi=300)\n",
    "#     print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"âœ… Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "    \n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "#     if 'dsets_nk1_bit_10_100' in prefix:\n",
    "#         prefix_ = '_'.join(parts[:3])\n",
    "        \n",
    "#         if 'ood' not in f:\n",
    "#             groups[prefix].append(f)\n",
    "        \n",
    "#         # print('prefix ', prefix)\n",
    "#         # print('prefix_ ', prefix_)\n",
    "#         # print('f')\n",
    "#     # if prefix_ in prefix and 'ood' in f:\n",
    "#     #     groups[prefix].append(f)\n",
    "    \n",
    "#     if 'dsets_nk1_bit_500_10_ood1_none.npz' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "#     if 'dsets_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "#         groups['dsets_nk1_bit_10_100'].append(f)\n",
    "\n",
    "for f in files:\n",
    "    if 'strans_nk1_bit_10_100' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "    elif 'strans_nk1_bit_500_10_ood1_none.npz' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "    elif 'strans_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path_pdf = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all_final.pdf\")\n",
    "    save_path_png = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all_final.png\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path_pdf):\n",
    "        print(f\"â© {save_path_pdf} already exists. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    if os.path.exists(save_path_png):\n",
    "        print(f\"â© {save_path_png} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸš€ Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        if len(group_files) != 5:\n",
    "            print('group_files ', len(group_files))\n",
    "            continue\n",
    "        #####\n",
    "        # if 'ood' in file_path:\n",
    "        #     continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    # color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "    color_map = {0: '#FFA500', 1: '#2E8B57', -1: '#9B30FF', 3:'#D62728', 4:'#808080'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    # sizes = [60 if label == 1 else 15 for label in all_labels]\n",
    "    sizes = []\n",
    "    for label in all_labels:\n",
    "        if label == 1:         # mixup (w/o context)\n",
    "            sizes.append(60)   # larger to emphasize\n",
    "        # elif label == -1:      # mixup (context)\n",
    "        #     sizes.append(30)\n",
    "        # elif label == 0:       # mixup\n",
    "        #     sizes.append(30)\n",
    "        elif label in [3, 4]:  # OOD\n",
    "            sizes.append(20)   # fairly large to stand out\n",
    "        else:\n",
    "            sizes.append(15)   # default fallback\n",
    "\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#FFA500', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "    blue_circle = mlines.Line2D([], [], color='#2E8B57', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#9B30FF', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "    green_circle = mlines.Line2D([], [], color='#D62728', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "    bluegreen_circle = mlines.Line2D([], [], color='#808080', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path_pdf, dpi=300)\n",
    "    print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path_pdf}\")\n",
    "    plt.savefig(save_path_png, dpi=300)\n",
    "    print(f\"âœ… Saved t-SNE scatter plot with nice legend to {save_path_png}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO change path\n",
      "âš ï¸ cuML not available, falling back to CPU openTSNE\n",
      "\n",
      "ğŸš€ Processing group strans_nk1_bit_10_100\n",
      "âœ… Loaded strans_nk1_bit_10_100_context_none.npz: embeddings (1000, 32), labels (1000,), losses (1000,)\n",
      "âœ… Loaded strans_nk1_bit_10_100_train_context.npz: embeddings (1000, 32), labels (1000,), losses (1000,)\n",
      "âœ… Loaded strans_nk1_bit_10_100_train_none.npz: embeddings (10, 32), labels (10,), losses (10,)\n",
      "âœ… Loaded strans_nk1_bit_500_10_ood1_none_normalized.npz: embeddings (500, 32), labels (500,), losses (500,)\n",
      "âœ… Loaded strans_nk1_bit_500_10_ood2_none_normalized.npz: embeddings (500, 32), labels (500,), losses (500,)\n",
      "âœ… Combined embeddings shape: (3010, 32), labels shape: (3010,), losses shape: (3010,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_595405/2666035141.py:123: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved clean t-SNE plot for OOD3 to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_10_100_tsne_combined_ood3.png\n",
      "ğŸ“ˆ Loss statistics for OOD3 (raw, before truncation):\n",
      "  Mean    : 0.170870\n",
      "  Variance: 0.031984\n",
      "  Median  : 0.114062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_595405/2666035141.py:123: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved clean t-SNE plot for OOD4 to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_10_100_tsne_combined_ood4.png\n",
      "ğŸ“ˆ Loss statistics for OOD4 (raw, before truncation):\n",
      "  Mean    : 0.140922\n",
      "  Variance: 0.028459\n",
      "  Median  : 0.068468\n"
     ]
    }
   ],
   "source": [
    "print('TODO change path')\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "print(\"âš ï¸ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# --- Global matplotlib settings ---\n",
    "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 13\n",
    "mpl.rcParams['xtick.labelsize'] = 10\n",
    "mpl.rcParams['ytick.labelsize'] = 10\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['figure.titlesize'] = 16\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "mpl.rcParams['legend.title_fontsize'] = 13\n",
    "mpl.rcParams['grid.alpha'] = 0.3\n",
    "mpl.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "# --- Set your directory ---\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files manually ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    if 'strans_nk1_bit_10_100' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "    elif 'strans_nk1_bit_500_10_ood1_none_normalized' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "    elif 'strans_nk1_bit_500_10_ood2_none_normalized' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    base_save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined\")\n",
    "\n",
    "    print(f\"\\nğŸš€ Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    all_losses = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "\n",
    "        if len(group_files) != 5:\n",
    "            print('âš ï¸ Skipping group_files', len(group_files))\n",
    "            continue\n",
    "\n",
    "        data = np.load(file_path)\n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "        \n",
    "        # ood_loss = os.path.splitext(file_path)[0] + '_normalized.npz'\n",
    "        # data_loss = np.load(file_path)\n",
    "        losses = data['losses']\n",
    "\n",
    "        print(f\"âœ… Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}, losses {losses.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "        all_losses.append(losses)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "\n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_losses = np.concatenate(all_losses, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}, labels shape: {all_labels.shape}, losses shape: {all_losses.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Fixed normal class colors ---\n",
    "    fixed_color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}\n",
    "\n",
    "    # --- Function to plot each OOD separately ---\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.colors as mcolors\n",
    "    import matplotlib.cm as cm\n",
    "    import matplotlib.lines as mlines\n",
    "    from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "    from matplotlib.colors import LogNorm\n",
    "\n",
    "    from matplotlib.colors import LogNorm\n",
    "\n",
    "    from matplotlib.colors import LogNorm\n",
    "\n",
    "    from matplotlib.colors import LogNorm\n",
    "\n",
    "    def plot_one_ood(ood_mask, ood_label):\n",
    "        if not np.any(ood_mask):\n",
    "            print(f\"âš ï¸ No OOD{ood_label} points to plot.\")\n",
    "            return\n",
    "\n",
    "        losses_raw = all_losses\n",
    "        losses_ood = losses_raw[ood_mask]\n",
    "        epsilon = 1e-6\n",
    "        fixed_vmax = 0.4\n",
    "\n",
    "        # --- LogNorm color scale on raw loss ---\n",
    "        norm = LogNorm(vmin=epsilon, vmax=fixed_vmax)\n",
    "        cmap = cm.get_cmap('viridis')\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "        # --- Truncate OOD to first 200 points without sorting ---\n",
    "        ood_indices = np.where(all_labels == ood_label)[0][:100]\n",
    "\n",
    "        # --- Plot all ID points first (lighter background) ---\n",
    "        for i in range(len(embeddings_2d)):\n",
    "            label = all_labels[i]\n",
    "            if label == ood_label:\n",
    "                continue\n",
    "            if label in fixed_color_map:\n",
    "                plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1],\n",
    "                            color=fixed_color_map[label],\n",
    "                            s=20 if label in [0, -1] else 40,\n",
    "                            alpha=0.4)\n",
    "\n",
    "        # --- Plot OOD points with alpha and size by loss ---\n",
    "        for i in ood_indices:\n",
    "            loss = losses_raw[i]\n",
    "            clipped_loss = min(loss, fixed_vmax)\n",
    "            normed = clipped_loss / fixed_vmax\n",
    "            alpha = 0.3 + 0.7 * normed  # Range: 0.3â€“1.0\n",
    "            size = 20 + 30 * normed     # Range: 20â€“50\n",
    "\n",
    "            plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1],\n",
    "                        c=[cmap(norm(clipped_loss))],\n",
    "                        s=size, alpha=alpha)\n",
    "\n",
    "        # --- Plot settings ---\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_xticklabels([])\n",
    "        plt.gca().set_yticklabels([])\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.box(False)\n",
    "\n",
    "        # --- Legend ---\n",
    "        orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "        blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "        red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "        plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "                loc='upper right',\n",
    "                framealpha=0.6,\n",
    "                prop={'size': 11},\n",
    "                handletextpad=0.4,\n",
    "                borderpad=0.5)\n",
    "\n",
    "        # --- Colorbar using dummy scatter ---\n",
    "        scatter = plt.scatter([], [], c=[], cmap=cmap, norm=norm)\n",
    "        cbar = plt.colorbar(scatter, shrink=0.65, pad=0.01, aspect=35)\n",
    "        cbar.outline.set_visible(False)\n",
    "        cbar.ax.tick_params(labelsize=9, width=0.5, length=3)\n",
    "        cbar.ax.yaxis.set_major_formatter(FormatStrFormatter('%.2e'))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        final_save_path = f\"{base_save_path}_ood{ood_label}.png\"\n",
    "        plt.savefig(final_save_path, dpi=300)\n",
    "        print(f\"âœ… Saved clean t-SNE plot for OOD{ood_label} to {final_save_path}\")\n",
    "        plt.close()\n",
    "\n",
    "        # --- Stats ---\n",
    "        print(f\"ğŸ“ˆ Loss statistics for OOD{ood_label} (raw, before truncation):\")\n",
    "        print(f\"  Mean    : {losses_ood.mean():.6f}\")\n",
    "        print(f\"  Variance: {losses_ood.var(ddof=0):.6f}\")\n",
    "        print(f\"  Median  : {np.median(losses_ood):.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # def plot_one_ood(ood_mask, ood_label):\n",
    "    #     if not np.any(ood_mask):\n",
    "    #         print(f\"âš ï¸ No OOD{ood_label} points to plot.\")\n",
    "    #         return\n",
    "\n",
    "    #     losses_ood = all_losses[ood_mask]\n",
    "    #     upper_clip = np.percentile(losses_ood, 95)\n",
    "    #     norm = mcolors.Normalize(vmin=losses_ood.min(), vmax=upper_clip)\n",
    "    #     cmap = cm.get_cmap('viridis')\n",
    "\n",
    "    #     plt.figure(figsize=(8, 6))\n",
    "\n",
    "    #     # --- Prepare points ---\n",
    "    #     colors = []\n",
    "    #     alphas = []\n",
    "    #     sizes = []\n",
    "\n",
    "    #     for label, loss in zip(all_labels, all_losses):\n",
    "    #         if label in fixed_color_map:\n",
    "    #             colors.append(fixed_color_map[label])\n",
    "    #             alphas.append(0.4)  # lighter background\n",
    "    #             sizes.append(20 if label in [0, -1] else 40)\n",
    "    #         elif label == ood_label:\n",
    "    #             clipped_loss = min(loss, upper_clip)\n",
    "    #             colors.append(cmap(norm(clipped_loss)))\n",
    "    #             alphas.append(1.0)\n",
    "    #             sizes.append(30)\n",
    "    #         else:\n",
    "    #             colors.append(None)\n",
    "    #             alphas.append(None)\n",
    "    #             sizes.append(None)\n",
    "\n",
    "    #     # --- Plot OOD points first for colorbar ---\n",
    "    #     ood_coords = []\n",
    "    #     ood_colors = []\n",
    "    #     for i in range(len(embeddings_2d)):\n",
    "    #         if all_labels[i] == ood_label:\n",
    "    #             ood_coords.append(embeddings_2d[i])\n",
    "    #             clipped_loss = min(all_losses[i], upper_clip)\n",
    "    #             ood_colors.append(clipped_loss)\n",
    "\n",
    "    #     if ood_coords:\n",
    "    #         ood_coords = np.array(ood_coords)\n",
    "    #         ood_colors = np.array(ood_colors)\n",
    "\n",
    "    #         scatter = plt.scatter(ood_coords[:, 0], ood_coords[:, 1],\n",
    "    #                               c=ood_colors, cmap=cmap, norm=norm, s=30, alpha=1.0)\n",
    "\n",
    "    #     # --- Plot normal points ---\n",
    "    #     for i in range(len(embeddings_2d)):\n",
    "    #         if colors[i] is None or all_labels[i] == ood_label:\n",
    "    #             continue\n",
    "    #         plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1],\n",
    "    #                     color=colors[i], s=sizes[i], alpha=alphas[i])\n",
    "\n",
    "    #     plt.grid(True)\n",
    "    #     plt.gca().set_xticklabels([])\n",
    "    #     plt.gca().set_yticklabels([])\n",
    "    #     plt.xlabel(\"\")\n",
    "    #     plt.ylabel(\"\")\n",
    "    #     plt.box(False)\n",
    "\n",
    "    #     # --- Legend ---\n",
    "    #     orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='mixup')\n",
    "    #     blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='mixup (w/o context)')\n",
    "    #     red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='mixup (context)')\n",
    "\n",
    "    #     plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "    #                loc='upper right',\n",
    "    #                framealpha=0.6,\n",
    "    #                prop={'size': 11},\n",
    "    #                handletextpad=0.4,\n",
    "    #                borderpad=0.5)\n",
    "\n",
    "    #     # --- Prettier colorbar ---\n",
    "    #     if ood_coords.size > 0:\n",
    "    #         cbar = plt.colorbar(scatter, shrink=0.65, pad=0.01, aspect=35)\n",
    "    #         # cbar.set_label('Out-Of-Distribution Loss Value', fontsize=13, weight='bold', labelpad=8)\n",
    "    #         cbar.outline.set_visible(False)  # no outer box\n",
    "    #         cbar.ax.tick_params(labelsize=9, width=0.5, length=3)  # slim ticks\n",
    "    #         if losses_ood.max() > 10:\n",
    "    #             cbar.ax.yaxis.set_major_formatter(FormatStrFormatter('%.1e'))\n",
    "\n",
    "    #     # --- Title and layout ---\n",
    "    #     # plt.title(f'TSNE Plot - OOD{ood_label}', fontsize=16, weight='bold', pad=15)\n",
    "    #     plt.tight_layout()\n",
    "\n",
    "    #     final_save_path = f\"{base_save_path}_ood{ood_label}.png\"\n",
    "    #     plt.savefig(final_save_path, dpi=300)\n",
    "    #     print(f\"âœ… Saved clean t-SNE plot for OOD{ood_label} to {final_save_path}\")\n",
    "    #     plt.close()\n",
    "\n",
    "    #     # --- Loss statistics ---\n",
    "    #     mean_loss = losses_ood.mean()\n",
    "    #     var_loss = losses_ood.var(ddof=0)  # use ddof=0 for population variance\n",
    "    #     median_loss = np.median(losses_ood)\n",
    "\n",
    "    #     print(f\"ğŸ“ˆ Loss statistics for OOD{ood_label}:\")\n",
    "    #     print(f\"  Mean   : {mean_loss:.6f}\")\n",
    "    #     print(f\"  Variance: {var_loss:.6f}\")\n",
    "    #     print(f\"  Median : {median_loss:.6f}\")\n",
    "    \n",
    "    \n",
    "    # --- Plot separately for OOD1 and OOD2 ---\n",
    "    ood1_mask = (all_labels == 3)\n",
    "    ood2_mask = (all_labels == 4)\n",
    "\n",
    "    plot_one_ood(ood1_mask, ood_label=3)\n",
    "    plot_one_ood(ood2_mask, ood_label=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood1_baseline = np.load('/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none.npz')\n",
    "ood2_baseline = np.load()\n",
    "\n",
    "ood1_ours = np.load('/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_5000_10_ood1_none.npz')\n",
    "ood2_ours = np.load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def normalize_loss(npz1, npz2, path1, path2):\n",
    "    # Extract losses\n",
    "    loss1 = npz1['losses']\n",
    "    loss2 = npz2['losses']\n",
    "\n",
    "    # Compute global min and max\n",
    "    all_losses = np.concatenate([loss1, loss2])\n",
    "    min_loss = all_losses.min()\n",
    "    max_loss = all_losses.max()\n",
    "\n",
    "    # Normalize\n",
    "    norm1 = (loss1 - min_loss) / (max_loss - min_loss + 1e-8)\n",
    "    norm2 = (loss2 - min_loss) / (max_loss - min_loss + 1e-8)\n",
    "\n",
    "    # Build new paths\n",
    "    out_path1 = os.path.splitext(path1)[0] + '_normalized.npz'\n",
    "    out_path2 = os.path.splitext(path2)[0] + '_normalized.npz'\n",
    "\n",
    "    # Save npz1 with normalized loss\n",
    "    np.savez(out_path1, **{k: (norm1 if k == 'losses' else npz1[k]) for k in npz1.files})\n",
    "    np.savez(out_path2, **{k: (norm2 if k == 'losses' else npz2[k]) for k in npz2.files})\n",
    "\n",
    "    print(f\"âœ… Normalized files saved to:\\n  {out_path1}\\n  {out_path2}\")\n",
    "    print('max_loss ', max(norm1))\n",
    "    print('max_loss ', max(norm2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Normalized files saved to:\n",
      "  /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none_normalized.npz\n",
      "  /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none_normalized.npz\n",
      "max_loss  1.0\n",
      "max_loss  0.48899657\n"
     ]
    }
   ],
   "source": [
    "ood1_baseline_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none.npz'\n",
    "ood1_ours_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood1_none.npz'\n",
    "\n",
    "normalize_loss(ood1_baseline, ood1_ours, ood1_baseline_path, ood1_ours_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Normalized files saved to:\n",
      "  /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood2_none_normalized.npz\n",
      "  /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none_normalized.npz\n",
      "max_loss  0.98715436\n",
      "max_loss  1.0\n"
     ]
    }
   ],
   "source": [
    "ood2_baseline_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP_BILEVEL/lastlayer_ours_best_/strans_nk1_bit_500_10_ood2_none.npz'\n",
    "ood2_ours_path = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/dsets_nk1_bit_500_10_ood2_none.npz'\n",
    "\n",
    "normalize_loss(ood2_baseline, ood2_ours, ood2_baseline_path, ood2_ours_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by prefix ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    if 'dsets_nk1_bit_10_100' in f or 'dsets_nk1_bit_500_10_ood1_none.npz' in f or 'dsets_nk1_bit_500_10_ood2_none.npz' in f:\n",
    "        groups['dsets_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# --- Function to save plot with label exclusions ---\n",
    "def plot_tsne(embeddings_2d, all_labels, excluded_labels, save_prefix):\n",
    "    filtered_indices = [i for i, label in enumerate(all_labels) if label not in excluded_labels]\n",
    "    filtered_embeddings = embeddings_2d[filtered_indices]\n",
    "    filtered_labels = all_labels[filtered_indices]\n",
    "\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#228B22', 3: '#8B008B', 4: '#808080'}\n",
    "    sizes = []\n",
    "    colors = []\n",
    "    for label in filtered_labels:\n",
    "        sizes.append(70 if label == 1 else 18 if label in [3, 4] else 13)\n",
    "        colors.append(color_map[label])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_embeddings[:, 0], filtered_embeddings[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.box(False)\n",
    "\n",
    "    import matplotlib.lines as mlines\n",
    "    legend_handles = [\n",
    "        mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours'),\n",
    "        mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)'),\n",
    "        mlines.Line2D([], [], color='#228B22', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "    ]\n",
    "    if 3 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#8B008B', marker='o', linestyle='None', markersize=8, label='OOD'))\n",
    "    if 4 not in excluded_labels:\n",
    "        legend_handles.append(mlines.Line2D([], [], color='#808080', marker='o', linestyle='None', markersize=8, label='OOD'))\n",
    "\n",
    "    plt.legend(handles=legend_handles, loc='upper right', framealpha=0.6, prop={'size': 12})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_prefix}.pdf\", dpi=300)\n",
    "    plt.savefig(f\"{save_prefix}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    print(f\"\\nğŸš€ Processing group {prefix}\")\n",
    "    all_embeddings, all_labels = [], []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        data = np.load(file_path)\n",
    "        all_embeddings.append(data['embeddings'])\n",
    "        all_labels.append(data['labels'])\n",
    "        print(f\"âœ… Loaded {f}: embeddings {data['embeddings'].shape}, labels {data['labels'].shape}\")\n",
    "\n",
    "    if not all_embeddings:\n",
    "        continue\n",
    "\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"âœ… Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # Run t-SNE using scikit-learn\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Save three filtered plots\n",
    "    base_path = os.path.join(tsne_dir, f\"{prefix}_tsne\")\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[3, 4], save_prefix=f\"{base_path}_no_ood\")\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[4], save_prefix=f\"{base_path}_no_ood2\")\n",
    "    plot_tsne(embeddings_2d, all_labels, excluded_labels=[3], save_prefix=f\"{base_path}_no_ood1\")\n",
    "    print(f\"âœ… Saved all t-SNE variations for {prefix}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
