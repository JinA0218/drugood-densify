{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from main_merck_all_real import get_dataset\n",
    "from utils import set_seed, get_optimizer, InfIterator\n",
    "from arguments import get_arguments\n",
    "from main_origin import get_model\n",
    "from setenc import get_mixer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y_hat, y, test=False):\n",
    "    return F.mse_loss(y.cuda().squeeze(), y_hat.cuda().squeeze())\n",
    "\n",
    "def test(args, dataloader, contextloader=None, model=None, mixer_phi=None, embed_type=None, n_t=10, n_c=5):\n",
    "    model.eval()\n",
    "    # mixer_phi.eval()\n",
    "    embedding_list = []\n",
    "    label_list= []\n",
    "    loss_list = []\n",
    "    # print('model ', model)\n",
    "    # print('mixer_phi ', mixer_phi)\n",
    "    if embed_type == \"train_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 't_x.pt')\n",
    "                    torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"ood1_none\" or embed_type == \"ood2_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 't_x.pt')\n",
    "                #     torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    # elif embed_type == \"train_context\":\n",
    "    #     with torch.no_grad():\n",
    "    #         losses = []\n",
    "    #         counts = 0\n",
    "    #         for i, (x, y) in enumerate(dataloader):\n",
    "    #             if i == n_t:\n",
    "    #                 break\n",
    "                \n",
    "    #             context_samples = []\n",
    "                \n",
    "    #             if i == 0:\n",
    "    #                 torch.save(x, 'tc_x.pt')\n",
    "    #                 torch.save(y, 'tc_y.pt')\n",
    "\n",
    "    #             for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "    #                 if i_c == n_c:\n",
    "    #                     break\n",
    "    #                 x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "    #                 if args.n_context > 1:\n",
    "    #                     n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "    #                     x_c = x_c[:, :n]\n",
    "                        \n",
    "    #                 if i == 0 and i_c == 0:\n",
    "    #                     torch.save(x_c, 'tc_x_c.pt')\n",
    "    #                     torch.save(y_c, 'tc_y_c.pt')\n",
    "                        \n",
    "                        \n",
    "    #                 # print('$$$$$$')\n",
    "    #                 # print('x_c ', x_c.shape)\n",
    "    #                 # print('x ', x.shape)\n",
    "                    \n",
    "    #                 # return\n",
    "    #                 # context_samples.append(x_c)\n",
    "                \n",
    "    #             # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "    #             # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "    #             # print('### context_samples ', context_samples)\n",
    "    #             # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "    #                 y_hat, embedding_list, label_list = model(x=x.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "    #                 y = y.cuda().squeeze()\n",
    "    #                 y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "    #                 # y_hat = y_hat[:, 0]\n",
    "    #                 # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "    #                 loss = calc_loss(y_hat, y, test=True)\n",
    "    #                 loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "    #                 losses.append(loss.item() * x.size(0))\n",
    "    #                 counts += x.size(0)\n",
    "    # elif embed_type == \"context_none\":\n",
    "    #     with torch.no_grad():\n",
    "    #         losses = []\n",
    "    #         counts = 0\n",
    "    #         for i, (x, y) in enumerate(dataloader):\n",
    "    #             if i == n_t:\n",
    "    #                 break\n",
    "                \n",
    "    #             context_samples = []\n",
    "                \n",
    "    #             if i == 0:\n",
    "    #                 torch.save(x, 'c_x.pt')\n",
    "    #                 torch.save(y, 'c_y.pt')\n",
    "\n",
    "    #             for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "    #                 if i_c == n_c:\n",
    "    #                     break\n",
    "    #                 x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "    #                 if args.n_context > 1:\n",
    "    #                     n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "    #                     x_c = x_c[:, :n]\n",
    "                    \n",
    "    #                 if i == 0 and i_c == 0:\n",
    "    #                     torch.save(x_c, 'c_x_c.pt')\n",
    "    #                     torch.save(y_c, 'c_y_c.pt')\n",
    "    #                 # print('====')\n",
    "    #                 # print('x_c ', x_c.shape)\n",
    "    #                 # print('x ', x.shape)\n",
    "                    \n",
    "    #                 # return\n",
    "                    \n",
    "    #                 # context_samples.append(x_c)\n",
    "                    \n",
    "    #                 # B, S, H = x_c.size() <- did this in model\n",
    "    #                 # x_c = x_c.view(B*S, H)\n",
    "                \n",
    "    #             # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "    #             # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "    #             # print('### context_samples ', context_samples)\n",
    "    #             # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "    #                 y_hat, embedding_list, label_list = model(x=x_c.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "    #                 y = y.cuda().squeeze()\n",
    "    #                 y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "    #                 # y_hat = y_hat[:, 0]\n",
    "    #                 # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "    #                 loss = calc_loss(y_hat, y, test=True)\n",
    "    #                 loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "    #                 losses.append(loss.item() * x.size(0))\n",
    "    #                 counts += x.size(0)\n",
    "    mse = sum(losses) / counts\n",
    "    return mse, embedding_list, label_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_one_datapoint_features(args, model, mixer_phi, embed_type, n_t, n_c):\n",
    "    assert args.model_no_context == False\n",
    "    \n",
    "    args.embed_test = 'lastlayer_ours_best'\n",
    "    \n",
    "    path = f\"/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_MLP/{args.embed_test}_\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_MLP/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}.npz'\n",
    "    \n",
    "    \n",
    "    if os.path.exists(f_path):\n",
    "        print(f\"‚è© {f_path} already exists. Skipping...\") \n",
    "        return\n",
    "    \n",
    "    set_seed(0)\n",
    "    args.batch_size = 1\n",
    "    args.tsne_plot = True # because of get_dataset\n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    args.specify_ood_dataset = [d for d in all_candidates if d != args.dataset]\n",
    "    trainloader_test, _, mvalidloader_test, _, contextloader_test, ood1_trainloader_test, ood2_trainloader_test = get_dataset(args=args, test=True)\n",
    "    \n",
    "    if \"ood\" not in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood1' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood1_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood2' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood2_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    all_embeddings = torch.cat(embedding_list, dim=0)\n",
    "    all_labels = np.concatenate(label_list, axis=0)\n",
    "    all_losses = torch.cat(loss_list, dim=0)\n",
    "\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_losses = torch.tensor(all_losses)\n",
    "                \n",
    "    all_embeddings_np = all_embeddings.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    all_losses_np = all_losses.numpy()\n",
    "    \n",
    "    \n",
    "    np.savez(f_path, embeddings=all_embeddings_np, labels=all_labels_np, losses=all_losses_np)\n",
    "    print(f'>>> saved {f_path}')\n",
    "    \n",
    "    if 'ood1' in embed_type:\n",
    "        ood1_trainloader_test._iterator._shutdown_workers()\n",
    "    elif 'ood2' in embed_type:\n",
    "        ood2_trainloader_test._iterator._shutdown_workers()\n",
    "    else:\n",
    "        trainloader_test._iterator._shutdown_workers()\n",
    "        if 'context' in embed_type:\n",
    "            contextloader_test._iterator._shutdown_workers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(data):\n",
    "\n",
    "    model = data['model']\n",
    "    # mixer_phi = data['mixer_phi']\n",
    "    optimizer = data['optimizer']\n",
    "    # mixer_optimizer = data['mixer_optimizer']\n",
    "    \n",
    "    ltmse, lvmse, vmse, tmse = data['ltmse'], data['lvmse'], data['vmse'], data['tmse ']\n",
    "    \n",
    "    print('>> ltmse ', ltmse)\n",
    "    print('>> tmse ', tmse)\n",
    "    print('>> lvmse ', lvmse)\n",
    "    print('>> vmse ', vmse)\n",
    "    \n",
    "    args_ = data['args']\n",
    "\n",
    "    args = get_arguments()\n",
    "\n",
    "    for k, v in args_.items():\n",
    "        setattr(args, k, v)\n",
    "\n",
    "    os.environ['MVALID_DEFAULT'] = '0'\n",
    "    \n",
    "    set_seed(0)\n",
    "\n",
    "    model = get_model(args=args)\n",
    "    # mixer_phi = get_mixer(args=args)\n",
    "    # optimizer = get_optimizer(optimizer=args.optimizer, model=model, lr=args.lr, wd=args.wd)\n",
    "    # optimizermixer = None if mixer_phi is None else get_optimizer(optimizer=args.optimizer, model=mixer_phi, lr=args.clr, wd=args.cwd)\n",
    "\n",
    "    model.load_state_dict(data['model'])\n",
    "    # mixer_phi.load_state_dict(data['mixer_phi'])\n",
    "    # optimizer.load_state_dict(data['optimizer'])\n",
    "    # mixer_optimizer.load_state_dict(data['mixer_optimizer'])\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    # mixer_phi = mixer_phi.to(args.device)\n",
    "    \n",
    "    # for (n_t, n_c) in [(5, 10), (5, 100), (10, 5), (10, 100), (100, 5), (100, 10)]:\n",
    "    for (n_t, n_c) in [(5, 10), (5, 50), (5, 100), (10, 5), (10, 40), (10, 100), (40, 5), (40, 10), (100, 5),]:\n",
    "        save_one_datapoint_features(args, model, None, \"train_none\", n_t, n_c)\n",
    "        # save_one_datapoint_features(args, model, None, \"context_none\", n_t, n_c)\n",
    "        # save_one_datapoint_features(args, model, None, \"train_context\", n_t, n_c)\n",
    "        # save_one_datapoint_features(args, model, None, \"ood1_none\", 100, n_c)\n",
    "        # save_one_datapoint_features(args, model, None, \"ood2_none\", 100, n_c)\n",
    "    \n",
    "    save_one_datapoint_features(args, model, None, \"ood1_none\", 500, 10)\n",
    "    save_one_datapoint_features(args, model, None, \"ood2_none\", 500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixFalse/ours_best/Model_strans_dpp4_bit_None.pth\n",
      ">> ltmse  1.8426339907867693\n",
      ">> tmse  1.8426339907867693\n",
      ">> lvmse  1.0149125986629062\n",
      ">> vmse  1.0149125986629062\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_5_10_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_5_50_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_5_100_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_10_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_10_40_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_10_100_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_40_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_40_10_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_100_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_500_10_ood1_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_500_10_ood2_none.npz already exists. Skipping...\n",
      "üöÄ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixFalse/ours_best/Model_strans_hivprot_bit_None.pth\n",
      ">> ltmse  2.2958212041143162\n",
      ">> tmse  2.2958212041143162\n",
      ">> lvmse  0.9413831472396851\n",
      ">> vmse  0.9413831472396851\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_5_10_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_5_50_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_5_100_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_10_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_10_40_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_10_100_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_40_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_40_10_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_100_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_500_10_ood1_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_500_10_ood2_none.npz already exists. Skipping...\n",
      "üöÄ Loading /c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixFalse/ours_best/Model_strans_nk1_bit_None.pth\n",
      ">> ltmse  1.2019554919567423\n",
      ">> tmse  1.2019554919567423\n",
      ">> lvmse  0.9131193439165751\n",
      ">> vmse  0.9131193439165751\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_5_10_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_5_50_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_5_100_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_10_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_10_40_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_10_100_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_40_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_40_10_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_100_5_train_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none.npz already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_500_10_ood2_none.npz already exists. Skipping...\n",
      "\n",
      "üèÅ All models loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory containing .pth files\n",
    "tsne_model_dir = '/c2/jinakim/Drug_Discovery_j/tsne_model/tsne_model2_mNctFalse_RYV1_mixFalse/ours_best/'\n",
    "os.makedirs(tsne_model_dir, exist_ok=True)\n",
    "# List all .pth files\n",
    "pth_files = sorted([f for f in os.listdir(tsne_model_dir) if f.endswith('.pth')])\n",
    "\n",
    "# Load each file\n",
    "for i, f in enumerate(pth_files):\n",
    "    # if i > 5:\n",
    "    #     break\n",
    "    file_path = os.path.join(tsne_model_dir, f)\n",
    "    print(f\"üöÄ Loading {file_path}\")\n",
    "    \n",
    "    data = torch.load(file_path)\n",
    "    save_features(data)\n",
    "    # Now 'data' contains the loaded model or state dict or whatever was saved\n",
    "    # You can process it here if needed\n",
    "    # For example, just printing some keys if it's a checkpoint\n",
    "    # if isinstance(data, dict):\n",
    "    #     print(f\"‚úÖ Loaded {f}: keys = {list(data.keys())}\")\n",
    "    # else:\n",
    "    #     print(f\"‚úÖ Loaded {f}: type = {type(data)}\")\n",
    "\n",
    "print(\"\\nüèÅ All models loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è cuML not available, falling back to CPU openTSNE\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "üöÄ Processing group strans_dpp4_bit_500_10\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_dpp4_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_100_5_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_10_100_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_10_40_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_10_5_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_40_10_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_40_5_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "üöÄ Processing group strans_hivprot_bit_500_10\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_5_100_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_5_10_tsne_combined.pdf already exists. Skipping...\n",
      "‚è© /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_hivprot_bit_5_50_tsne_combined.pdf already exists. Skipping...\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_100_100\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_100_10\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_100_40\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_100_50\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_100_5\n",
      "‚úÖ Loaded strans_nk1_bit_100_5_train_none.npz: embeddings (100, 32), labels (100,)\n",
      "‚úÖ Combined embeddings shape: (100, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 3.00 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_100_5_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_10_100\n",
      "‚úÖ Loaded strans_nk1_bit_10_100_train_none.npz: embeddings (10, 32), labels (10,)\n",
      "‚úÖ Combined embeddings shape: (10, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 3.00 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_10_100_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_10_40\n",
      "‚úÖ Loaded strans_nk1_bit_10_40_train_none.npz: embeddings (10, 32), labels (10,)\n",
      "‚úÖ Combined embeddings shape: (10, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 3.00 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_10_40_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_10_5\n",
      "‚úÖ Loaded strans_nk1_bit_10_5_train_none.npz: embeddings (10, 32), labels (10,)\n",
      "‚úÖ Combined embeddings shape: (10, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 13.00 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_10_5_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_40_10\n",
      "‚úÖ Loaded strans_nk1_bit_40_10_train_none.npz: embeddings (40, 32), labels (40,)\n",
      "‚úÖ Combined embeddings shape: (40, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 13.00 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_40_10_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_40_5\n",
      "‚úÖ Loaded strans_nk1_bit_40_5_train_none.npz: embeddings (40, 32), labels (40,)\n",
      "‚úÖ Combined embeddings shape: (40, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 1.33 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_40_5_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_5000_10\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_500_10\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_5_100\n",
      "‚úÖ Loaded strans_nk1_bit_5_100_train_none.npz: embeddings (5, 32), labels (5,)\n",
      "‚úÖ Combined embeddings shape: (5, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 1.33 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_5_100_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_5_10\n",
      "‚úÖ Loaded strans_nk1_bit_5_10_train_none.npz: embeddings (5, 32), labels (5,)\n",
      "‚úÖ Combined embeddings shape: (5, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity value 30 is too high. Using perplexity 1.33 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_5_10_tsne_combined.pdf\n",
      "\n",
      "üöÄ Processing group strans_nk1_bit_5_50\n",
      "‚úÖ Loaded strans_nk1_bit_5_50_train_none.npz: embeddings (5, 32), labels (5,)\n",
      "‚úÖ Combined embeddings shape: (5, 32)\n",
      "‚úÖ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/strans_nk1_bit_5_50_tsne_combined.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"‚úÖ Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"‚ö†Ô∏è cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"‚è© {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüöÄ Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        #####\n",
    "        if 'ood' in file_path:\n",
    "            continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"‚úÖ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"‚úÖ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"‚úÖ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_2_3'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['1','2','3','4']\n",
    "'_'.join(a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# # try:\n",
    "# #     import cupy as cp\n",
    "# #     from cuml.manifold import TSNE as cuTSNE\n",
    "# #     gpu_available = True\n",
    "# #     print(\"‚úÖ Using GPU cuML TSNE\")\n",
    "# # except ImportError:\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# gpu_available = False\n",
    "# print(\"‚ö†Ô∏è cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "    \n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "#     if 'ood' not in f:\n",
    "#         groups[prefix].append(f)\n",
    "    \n",
    "#     prefix_ = '_'.join(parts[:3])\n",
    "#     if prefix_ in prefix and 'ood' in f:\n",
    "#         groups[prefix].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all.pdf\")\n",
    "    \n",
    "#     # if \"dpp4_bit\" in save_path:\n",
    "#     #     continue\n",
    "#     # --- Skip if already exists ---\n",
    "#     if os.path.exists(save_path):\n",
    "#         print(f\"‚è© {save_path} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\nüöÄ Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "#         # if len(group_files) != 5:\n",
    "#         #     print('group_files ', len(group_files))\n",
    "#         #     continue\n",
    "#         #####\n",
    "#         # if 'ood' in file_path:\n",
    "#         #     continue\n",
    "        \n",
    "#         # if 'train' not in file_path and 'context' not in file_path:\n",
    "#         #     continue\n",
    "#         #####\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "\n",
    "#         print(f\"‚úÖ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"‚úÖ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     # if gpu_available:\n",
    "#     #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "#     #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "#     #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "#     #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "#     # else:\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     import matplotlib.patches as mpatches\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Set global font\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     # Define color mapping\n",
    "#     color_map = {1: '#0000CD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "#     colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "#     # Set point sizes\n",
    "#     sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Slight soft grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Hide axis labels but keep grid\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # --- Add better legend ---\n",
    "#     import matplotlib.lines as mlines\n",
    "\n",
    "#     # Define custom legend handles (use Line2D for circles)\n",
    "#     # orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context, w/o mvalid)')\n",
    "#     # red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "#     green_circle = mlines.Line2D([], [], color='#48b33c', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "#     bluegreen_circle = mlines.Line2D([], [], color='#3cadb3', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "#     # Add legend inside plot (upper right)\n",
    "#     plt.legend(handles=[blue_circle, green_circle, bluegreen_circle],\n",
    "#             loc='upper right',  # inside the plot, top right\n",
    "#             framealpha=0.6,\n",
    "#             prop={'size': 12},\n",
    "#             handletextpad=0.4,\n",
    "#             borderpad=0.5)\n",
    "\n",
    "#     # Tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save figure\n",
    "#     plt.savefig(save_path, dpi=300)\n",
    "#     print(f\"‚úÖ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.colors as mcolors\n",
    "# import matplotlib.lines as mlines\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "\n",
    "# print(\"‚ö†Ô∏è cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "#     if 'ood' not in f:\n",
    "#         groups[prefix].append(f)\n",
    "#     prefix_ = '_'.join(parts[:3])\n",
    "#     if prefix_ in prefix and 'ood' in f:\n",
    "#         groups[prefix].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all_loss.pdf\")\n",
    "    \n",
    "#     if os.path.exists(save_path):\n",
    "#         print(f\"‚è© {save_path} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\nüöÄ Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "#     all_losses = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "\n",
    "#         if len(group_files) != 3:\n",
    "#             print('‚ö†Ô∏è group_files ', len(group_files))\n",
    "#             continue\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "#         losses = data['losses']\n",
    "\n",
    "#         print(f\"‚úÖ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}, losses {losses.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "#         all_losses.append(losses)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "\n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "#     all_losses = np.concatenate(all_losses, axis=0)\n",
    "\n",
    "#     print(f\"‚úÖ Combined embeddings shape: {all_embeddings.shape}, labels shape: {all_labels.shape}, losses shape: {all_losses.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # Fixed colors for normal points\n",
    "#     fixed_color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}\n",
    "\n",
    "#     # OOD points normalization\n",
    "#     ood_mask = np.isin(all_labels, [3, 4])\n",
    "#     losses_for_ood = all_losses[ood_mask]\n",
    "\n",
    "#     if len(losses_for_ood) > 0:\n",
    "#         norm = mcolors.Normalize(vmin=np.min(losses_for_ood), vmax=np.max(losses_for_ood))\n",
    "#     else:\n",
    "#         norm = mcolors.Normalize(vmin=0, vmax=1)  # fallback\n",
    "#     cmap = cm.get_cmap('viridis')\n",
    "\n",
    "#     # Create colors\n",
    "#     colors = []\n",
    "#     for label, loss in zip(all_labels, all_losses):\n",
    "#         if label in fixed_color_map:\n",
    "#             colors.append(fixed_color_map[label])\n",
    "#         else:  # ood1 and ood2\n",
    "#             colors.append(cmap(norm(loss)))\n",
    "\n",
    "#     # Point sizes\n",
    "#     sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Remove axis labels\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # Legend for fixed classes\n",
    "#     orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#     red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "#     plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "#                loc='upper right',\n",
    "#                framealpha=0.6,\n",
    "#                prop={'size': 12},\n",
    "#                handletextpad=0.4,\n",
    "#                borderpad=0.5)\n",
    "\n",
    "#     # Colorbar for OOD\n",
    "#     if np.any(ood_mask):\n",
    "#         cbar = plt.colorbar(scatter)\n",
    "#         cbar.set_label('OOD Loss Value', fontsize=12)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(save_path, dpi=300)\n",
    "#     print(f\"‚úÖ Saved t-SNE scatter plot with loss-colored OOD to {save_path}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.colors as mcolors\n",
    "# import matplotlib.lines as mlines\n",
    "# import matplotlib as mpl\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# print(\"‚ö†Ô∏è cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # --- Global matplotlib settings ---\n",
    "# mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "# mpl.rcParams['axes.titlesize'] = 16\n",
    "# mpl.rcParams['axes.labelsize'] = 13\n",
    "# mpl.rcParams['xtick.labelsize'] = 10\n",
    "# mpl.rcParams['ytick.labelsize'] = 10\n",
    "# mpl.rcParams['legend.fontsize'] = 12\n",
    "# mpl.rcParams['figure.titlesize'] = 16\n",
    "# mpl.rcParams['figure.dpi'] = 300\n",
    "# mpl.rcParams['savefig.dpi'] = 300\n",
    "# mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "# mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "# mpl.rcParams['legend.title_fontsize'] = 13\n",
    "# mpl.rcParams['grid.alpha'] = 0.3\n",
    "# mpl.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "# # --- Set your directory ---\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MLP/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files manually ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     if 'strans_nk1_bit_10_100' in f:\n",
    "#         groups['strans_nk1_bit_10_100'].append(f)\n",
    "#     elif 'strans_nk1_bit_500_10_ood1' in f:\n",
    "#         groups['strans_nk1_bit_10_100'].append(f)\n",
    "#     elif 'strans_nk1_bit_500_10_ood2' in f:\n",
    "#         groups['strans_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     base_save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined\")\n",
    "\n",
    "#     print(f\"\\nüöÄ Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "#     all_losses = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "\n",
    "#         if len(group_files) != 3:\n",
    "#             print('‚ö†Ô∏è Skipping group_files', len(group_files))\n",
    "#             continue\n",
    "\n",
    "#         data = np.load(file_path)\n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "#         losses = data['losses']\n",
    "\n",
    "#         print(f\"‚úÖ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}, losses {losses.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "#         all_losses.append(losses)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "\n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "#     all_losses = np.concatenate(all_losses, axis=0)\n",
    "\n",
    "#     print(f\"‚úÖ Combined embeddings shape: {all_embeddings.shape}, labels shape: {all_labels.shape}, losses shape: {all_losses.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Fixed normal class colors ---\n",
    "#     fixed_color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}\n",
    "\n",
    "#     # --- Function to plot each OOD separately ---\n",
    "#     def plot_one_ood(ood_mask, ood_label):\n",
    "#         if not np.any(ood_mask):\n",
    "#             print(f\"‚ö†Ô∏è No OOD{ood_label} points to plot.\")\n",
    "#             return\n",
    "\n",
    "#         losses_ood = all_losses[ood_mask]\n",
    "#         upper_clip = np.percentile(losses_ood, 95)\n",
    "#         norm = mcolors.Normalize(vmin=losses_ood.min(), vmax=upper_clip)\n",
    "#         cmap = cm.get_cmap('viridis')\n",
    "\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "\n",
    "#         # --- Prepare points ---\n",
    "#         colors = []\n",
    "#         alphas = []\n",
    "#         sizes = []\n",
    "\n",
    "#         for label, loss in zip(all_labels, all_losses):\n",
    "#             if label in fixed_color_map:\n",
    "#                 colors.append(fixed_color_map[label])\n",
    "#                 alphas.append(0.4)  # lighter background\n",
    "#                 sizes.append(20 if label in [0, -1] else 40)\n",
    "#             elif label == ood_label:\n",
    "#                 clipped_loss = min(loss, upper_clip)\n",
    "#                 colors.append(cmap(norm(clipped_loss)))\n",
    "#                 alphas.append(1.0)\n",
    "#                 sizes.append(30)\n",
    "#             else:\n",
    "#                 colors.append(None)\n",
    "#                 alphas.append(None)\n",
    "#                 sizes.append(None)\n",
    "\n",
    "#         # --- Plot OOD points first for colorbar ---\n",
    "#         ood_coords = []\n",
    "#         ood_colors = []\n",
    "#         for i in range(len(embeddings_2d)):\n",
    "#             if all_labels[i] == ood_label:\n",
    "#                 ood_coords.append(embeddings_2d[i])\n",
    "#                 clipped_loss = min(all_losses[i], upper_clip)\n",
    "#                 ood_colors.append(clipped_loss)\n",
    "\n",
    "#         if ood_coords:\n",
    "#             ood_coords = np.array(ood_coords)\n",
    "#             ood_colors = np.array(ood_colors)\n",
    "\n",
    "#             scatter = plt.scatter(ood_coords[:, 0], ood_coords[:, 1],\n",
    "#                                   c=ood_colors, cmap=cmap, norm=norm, s=30, alpha=1.0)\n",
    "\n",
    "#         # --- Plot normal points ---\n",
    "#         for i in range(len(embeddings_2d)):\n",
    "#             if colors[i] is None or all_labels[i] == ood_label:\n",
    "#                 continue\n",
    "#             plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1],\n",
    "#                         color=colors[i], s=sizes[i], alpha=alphas[i])\n",
    "\n",
    "#         plt.grid(True)\n",
    "#         plt.gca().set_xticklabels([])\n",
    "#         plt.gca().set_yticklabels([])\n",
    "#         plt.xlabel(\"\")\n",
    "#         plt.ylabel(\"\")\n",
    "#         plt.box(False)\n",
    "\n",
    "#         # --- Legend ---\n",
    "#         # orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#         blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#         # red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "#         plt.legend(handles=[blue_circle],\n",
    "#                    loc='upper right',\n",
    "#                    framealpha=0.6,\n",
    "#                    prop={'size': 11},\n",
    "#                    handletextpad=0.4,\n",
    "#                    borderpad=0.5)\n",
    "\n",
    "#         # --- Prettier colorbar ---\n",
    "#         if ood_coords.size > 0:\n",
    "#             cbar = plt.colorbar(scatter, shrink=0.65, pad=0.01, aspect=35)\n",
    "#             cbar.set_label('Out-Of-Distribution Loss Value', fontsize=13, weight='bold', labelpad=8)\n",
    "#             cbar.outline.set_visible(False)  # no outer box\n",
    "#             cbar.ax.tick_params(labelsize=9, width=0.5, length=3)  # slim ticks\n",
    "#             if losses_ood.max() > 10:\n",
    "#                 cbar.ax.yaxis.set_major_formatter(FormatStrFormatter('%.1e'))\n",
    "\n",
    "#         # --- Title and layout ---\n",
    "#         plt.title(f'TSNE Plot - OOD{ood_label}', fontsize=16, weight='bold', pad=15)\n",
    "#         plt.tight_layout()\n",
    "\n",
    "#         final_save_path = f\"{base_save_path}_ood{ood_label}.pdf\"\n",
    "#         plt.savefig(final_save_path, dpi=300)\n",
    "#         print(f\"‚úÖ Saved clean t-SNE plot for OOD{ood_label} to {final_save_path}\")\n",
    "#         plt.close()\n",
    "\n",
    "#         # --- Loss statistics ---\n",
    "#         mean_loss = losses_ood.mean()\n",
    "#         var_loss = losses_ood.var(ddof=0)  # use ddof=0 for population variance\n",
    "#         median_loss = np.median(losses_ood)\n",
    "\n",
    "#         print(f\"üìà Loss statistics for OOD{ood_label}:\")\n",
    "#         print(f\"  Mean   : {mean_loss:.6f}\")\n",
    "#         print(f\"  Variance: {var_loss:.6f}\")\n",
    "#         print(f\"  Median : {median_loss:.6f}\")\n",
    "#     # --- Plot separately for OOD1 and OOD2 ---\n",
    "#     ood1_mask = (all_labels == 3)\n",
    "#     ood2_mask = (all_labels == 4)\n",
    "\n",
    "#     plot_one_ood(ood1_mask, ood_label=3)\n",
    "#     plot_one_ood(ood2_mask, ood_label=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
