{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from main_merck_all_real_mixup import get_dataset\n",
    "from utils import set_seed, get_optimizer, InfIterator\n",
    "from arguments import get_arguments\n",
    "from main_origin import get_model\n",
    "from setenc import get_mixer\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y_hat, y, test=False):\n",
    "    return F.mse_loss(y.cuda().squeeze(), y_hat.cuda().squeeze())\n",
    "\n",
    "def test(args, dataloader, contextloader=None, model=None, mixer_phi=None, embed_type=None, n_t=10, n_c=5):\n",
    "    model.eval()\n",
    "    mixer_phi.eval()\n",
    "    embedding_list = []\n",
    "    label_list= []\n",
    "    loss_list = []\n",
    "    # print('model ', model)\n",
    "    # print('mixer_phi ', mixer_phi)\n",
    "    if embed_type == \"train_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 't_x.pt')\n",
    "                    torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"ood1_none\" or embed_type == \"ood2_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 't_x.pt')\n",
    "                #     torch.save(y, 't_y.pt')\n",
    "                #     return\n",
    "                \n",
    "\n",
    "                y_hat, embedding_list, label_list = model(x=x.to(args.device), context=None, mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                y = y.cuda().squeeze()\n",
    "                y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                # y_hat = y_hat[:, 0]\n",
    "                # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                loss = calc_loss(y_hat, y, test=True)\n",
    "                loss_scalar = loss.detach().item()\n",
    "                loss_list.append(torch.full((x.shape[0],), loss_scalar))\n",
    "\n",
    "                # print('loss_scalar ', loss_scalar)\n",
    "                # print('x ', x.size(0))\n",
    "                # print('y_hat ', y_hat)\n",
    "                # print('embedding_list ', embedding_list)\n",
    "                losses.append(loss_scalar * x.size(0))\n",
    "                counts += x.size(0)\n",
    "                # if i == 0:\n",
    "                #     torch.save(x, 'tn_x.pt')\n",
    "                #     torch.save(y, 'tn_y.pt')\n",
    "        # self.model.eval()\n",
    "    elif embed_type == \"train_context\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'tc_x.pt')\n",
    "                    torch.save(y, 'tc_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                        \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'tc_x_c.pt')\n",
    "                        torch.save(y_c, 'tc_y_c.pt')\n",
    "                        \n",
    "                        \n",
    "                    # print('$$$$$$')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    # context_samples.append(x_c)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    elif embed_type == \"context_none\":\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            counts = 0\n",
    "            for i, (x, y) in enumerate(dataloader):\n",
    "                if i == n_t:\n",
    "                    break\n",
    "                \n",
    "                context_samples = []\n",
    "                \n",
    "                if i == 0:\n",
    "                    torch.save(x, 'c_x.pt')\n",
    "                    torch.save(y, 'c_y.pt')\n",
    "\n",
    "                for i_c, (x_c, y_c) in enumerate(contextloader):\n",
    "                    if i_c == n_c:\n",
    "                        break\n",
    "                    x_c = x_c.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                    if args.n_context > 1:\n",
    "                        n = torch.randint(1, x_c.size(1), size=(1,)).item()\n",
    "                        x_c = x_c[:, :n]\n",
    "                    \n",
    "                    if i == 0 and i_c == 0:\n",
    "                        torch.save(x_c, 'c_x_c.pt')\n",
    "                        torch.save(y_c, 'c_y_c.pt')\n",
    "                    # print('====')\n",
    "                    # print('x_c ', x_c.shape)\n",
    "                    # print('x ', x.shape)\n",
    "                    \n",
    "                    # return\n",
    "                    \n",
    "                    # context_samples.append(x_c)\n",
    "                    \n",
    "                    # B, S, H = x_c.size() <- did this in model\n",
    "                    # x_c = x_c.view(B*S, H)\n",
    "                \n",
    "                # context_samples = torch.cat(context_samples, dim=0).to(args.device)\n",
    "                # context_samples = context_samples.reshape(args.batch_size, -1, x_c.size(-1))\n",
    "                \n",
    "                # print('### context_samples ', context_samples)\n",
    "                # torch.save(context_samples, f'context_samples_{i}.pth')\n",
    "                    y_hat, embedding_list, label_list = model(x=x_c.to(args.device), context=x_c.to(args.device), mixer_phi=mixer_phi, embedding_list=embedding_list, label_list=label_list, embed_type=embed_type, embed_test=args.embed_test)\n",
    "\n",
    "                    y = y.cuda().squeeze()\n",
    "                    y_hat = y_hat.cuda().squeeze()\n",
    "\n",
    "                    # y_hat = y_hat[:, 0]\n",
    "                    # print(f\"in test: {y.size()=} {y_hat.size()=}\")\n",
    "\n",
    "                    loss = calc_loss(y_hat, y, test=True)\n",
    "                    loss_list.append(torch.full((x.shape[0],), loss.detach().item()))\n",
    "\n",
    "                    losses.append(loss.item() * x.size(0))\n",
    "                    counts += x.size(0)\n",
    "    mse = sum(losses) / counts\n",
    "    return mse, embedding_list, label_list, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_one_datapoint_features(args, model, mixer_phi, embed_type, n_t, n_c):\n",
    "    assert args.model_no_context == False\n",
    "    \n",
    "    args.embed_test = 'lastlayer_ours_best'\n",
    "    \n",
    "    path = f\"/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_MIXUP/{args.embed_test}_\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    f_path = f'/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNct{args.model_no_context}_RYV1_MIXUP/{args.embed_test}_/{args.sencoder}_{args.dataset}_{args.vec_type}_{n_t}_{n_c}_{embed_type}.npz'\n",
    "    \n",
    "    \n",
    "    if os.path.exists(f_path):\n",
    "        print(f\"⏩ {f_path} already exists. Skipping...\") \n",
    "        return\n",
    "    \n",
    "    set_seed(0)\n",
    "    args.batch_size = 1\n",
    "    args.tsne_plot = True # because of get_dataset\n",
    "    all_candidates = ['hivprot', 'dpp4', 'nk1']\n",
    "    args.specify_ood_dataset = [d for d in all_candidates if d != args.dataset]\n",
    "    trainloader_test, _, mvalidloader_test, _, contextloader_test, ood1_trainloader_test, ood2_trainloader_test = get_dataset(args=args, test=True)\n",
    "    \n",
    "    if \"ood\" not in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood1' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood1_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    elif 'ood2' in embed_type:\n",
    "        mse, embedding_list, label_list, loss_list = test(args=args, dataloader=ood2_trainloader_test, contextloader=contextloader_test, model=model, mixer_phi=mixer_phi, embed_type=embed_type, n_t=n_t, n_c=n_c)\n",
    "    else:\n",
    "        raise Exception()\n",
    "    \n",
    "    # for i, emb in enumerate(embedding_list):\n",
    "    #     print(f\"Tensor {i}: {emb.shape}\")\n",
    "    \n",
    "    all_embeddings = torch.cat(embedding_list, dim=0)\n",
    "    all_labels = np.concatenate(label_list, axis=0)\n",
    "    all_losses = torch.cat(loss_list, dim=0)\n",
    "\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_losses = torch.tensor(all_losses)\n",
    "                \n",
    "    all_embeddings_np = all_embeddings.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    all_losses_np = all_losses.numpy()\n",
    "    \n",
    "    \n",
    "    np.savez(f_path, embeddings=all_embeddings_np, labels=all_labels_np, losses=all_losses_np)\n",
    "    print(f'>>> saved {f_path}')\n",
    "    \n",
    "    if 'ood1' in embed_type:\n",
    "        ood1_trainloader_test._iterator._shutdown_workers()\n",
    "    elif 'ood2' in embed_type:\n",
    "        ood2_trainloader_test._iterator._shutdown_workers()\n",
    "    else:\n",
    "        trainloader_test._iterator._shutdown_workers()\n",
    "        if 'context' in embed_type:\n",
    "            contextloader_test._iterator._shutdown_workers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(data):\n",
    "\n",
    "    model = data['model']\n",
    "    mixer_phi = data['mixer_phi']\n",
    "    optimizer = data['optimizer']\n",
    "    # mixer_optimizer = data['mixer_optimizer']\n",
    "    \n",
    "    ltmse, lvmse, vmse, tmse = data['ltmse'], data['lvmse'], data['vmse'], data['tmse ']\n",
    "    \n",
    "    print('>> ltmse ', ltmse)\n",
    "    print('>> tmse ', tmse)\n",
    "    print('>> lvmse ', lvmse)\n",
    "    print('>> vmse ', vmse)\n",
    "    \n",
    "    args_ = data['args']\n",
    "\n",
    "    args = get_arguments()\n",
    "\n",
    "    for k, v in args_.items():\n",
    "        setattr(args, k, v)\n",
    "        \n",
    "    os.environ['MIX_TYPE'] = 'MIXUP'\n",
    "\n",
    "    set_seed(0)\n",
    "\n",
    "    model = get_model(args=args)\n",
    "    mixer_phi = get_mixer(args=args)\n",
    "    # optimizer = get_optimizer(optimizer=args.optimizer, model=model, lr=args.lr, wd=args.wd)\n",
    "    # optimizermixer = None if mixer_phi is None else get_optimizer(optimizer=args.optimizer, model=mixer_phi, lr=args.clr, wd=args.cwd)\n",
    "\n",
    "    model.load_state_dict(data['model'])\n",
    "    mixer_phi.load_state_dict(data['mixer_phi'])\n",
    "    # optimizer.load_state_dict(data['optimizer'])\n",
    "    # mixer_optimizer.load_state_dict(data['mixer_optimizer'])\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    mixer_phi = mixer_phi.to(args.device)\n",
    "    \n",
    "    # for (n_t, n_c) in [(5, 10), (5, 100), (10, 5), (10, 100), (100, 5), (100, 10)]:\n",
    "    # for (n_t, n_c) in [(5, 10), (5, 50), (5, 100), (10, 5), (10, 40), (10, 100), (40, 5), (40, 10), (100, 5),]:\n",
    "    for (n_t, n_c) in [(10, 40), (10, 100)]:\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"context_none\", n_t, n_c)\n",
    "        save_one_datapoint_features(args, model, mixer_phi, \"train_context\", n_t, n_c)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood1_none\", 500, 10)\n",
    "    save_one_datapoint_features(args, model, mixer_phi, \"ood2_none\", 500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Loading /c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP/ours_best/Model_strans_nk1_bit_['None'].pth\n",
      ">> ltmse  0.4454459672567548\n",
      ">> tmse  0.4454459672567548\n",
      ">> lvmse  0.30273041625817615\n",
      ">> vmse  0.30273041625817615\n",
      "loading set transformer layer='max'\n",
      "STEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_586647/140253672.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_losses = torch.tensor(all_losses)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_40_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_40_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_40_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_100_train_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_100_context_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_100_train_context.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_500_10_ood1_none.npz\n",
      "Inner args.dataset='nk1' args.vec_type='bit'\n",
      ">>> saved /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_500_10_ood2_none.npz\n",
      "\n",
      "🏁 All models loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory containing .pth files\n",
    "tsne_model_dir = '/c2/jinakim/Drug_Discovery_j/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP/ours_best/'\n",
    "os.makedirs(tsne_model_dir, exist_ok=True)\n",
    "# List all .pth files\n",
    "pth_files = sorted([f for f in os.listdir(tsne_model_dir) if f.endswith('.pth')])\n",
    "\n",
    "# Load each file\n",
    "for i, f in enumerate(pth_files):\n",
    "    # if i > 5:\n",
    "    #     break\n",
    "    file_path = os.path.join(tsne_model_dir, f)\n",
    "    print(f\"🚀 Loading {file_path}\")\n",
    "    \n",
    "    data = torch.load(file_path)\n",
    "    save_features(data)\n",
    "    # Now 'data' contains the loaded model or state dict or whatever was saved\n",
    "    # You can process it here if needed\n",
    "    # For example, just printing some keys if it's a checkpoint\n",
    "    # if isinstance(data, dict):\n",
    "    #     print(f\"✅ Loaded {f}: keys = {list(data.keys())}\")\n",
    "    # else:\n",
    "    #     print(f\"✅ Loaded {f}: type = {type(data)}\")\n",
    "\n",
    "print(\"\\n🏁 All models loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ cuML not available, falling back to CPU openTSNE\n",
      "\n",
      "🚀 Processing group strans_nk1_bit_10_100\n",
      "✅ Loaded strans_nk1_bit_10_100_context_none.npz: embeddings (1000, 32), labels (1000,)\n",
      "✅ Loaded strans_nk1_bit_10_100_train_context.npz: embeddings (1000, 32), labels (1000,)\n",
      "✅ Loaded strans_nk1_bit_10_100_train_none.npz: embeddings (10, 32), labels (10,)\n",
      "✅ Combined embeddings shape: (2010, 32)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_100_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group strans_nk1_bit_10_40\n",
      "✅ Loaded strans_nk1_bit_10_40_context_none.npz: embeddings (400, 32), labels (400,)\n",
      "✅ Loaded strans_nk1_bit_10_40_train_context.npz: embeddings (400, 32), labels (400,)\n",
      "✅ Loaded strans_nk1_bit_10_40_train_none.npz: embeddings (10, 32), labels (10,)\n",
      "✅ Combined embeddings shape: (810, 32)\n",
      "✅ Saved t-SNE scatter plot with nice legend to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_40_tsne_combined.pdf\n",
      "\n",
      "🚀 Processing group strans_nk1_bit_500_10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# try:\n",
    "#     import cupy as cp\n",
    "#     from cuml.manifold import TSNE as cuTSNE\n",
    "#     gpu_available = True\n",
    "#     print(\"✅ Using GPU cuML TSNE\")\n",
    "# except ImportError:\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "gpu_available = False\n",
    "print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# Set your directory\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    parts = f.split('_')\n",
    "    prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    groups[prefix].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined.pdf\")\n",
    "    \n",
    "    # if \"dpp4_bit\" in save_path:\n",
    "    #     continue\n",
    "    # --- Skip if already exists ---\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"⏩ {save_path} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "        #####\n",
    "        if 'ood' in file_path:\n",
    "            continue\n",
    "        \n",
    "        # if 'train' not in file_path and 'context' not in file_path:\n",
    "        #     continue\n",
    "        #####\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "\n",
    "        print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    # if gpu_available:\n",
    "    #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "    #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "    #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "    #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "    # else:\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Plot ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Set global font\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "    # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Define color mapping\n",
    "    color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}  # orange and blue\n",
    "    colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "    # Set point sizes\n",
    "    sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "    # Slight soft grid\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Hide axis labels but keep grid\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.box(False)\n",
    "\n",
    "    # --- Add better legend ---\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    # Define custom legend handles (use Line2D for circles)\n",
    "    orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "    blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "    red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "    # Add legend inside plot (upper right)\n",
    "    plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "            loc='upper right',  # inside the plot, top right\n",
    "            framealpha=0.6,\n",
    "            prop={'size': 12},\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Try to use GPU TSNE (cuML), fallback to CPU TSNE (openTSNE)\n",
    "# # try:\n",
    "# #     import cupy as cp\n",
    "# #     from cuml.manifold import TSNE as cuTSNE\n",
    "# #     gpu_available = True\n",
    "# #     print(\"✅ Using GPU cuML TSNE\")\n",
    "# # except ImportError:\n",
    "# from openTSNE import TSNE as cpuTSNE\n",
    "# gpu_available = False\n",
    "# print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# # Set your directory\n",
    "# tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1/lastlayer_ours_best_/'\n",
    "\n",
    "# # List all .npz files\n",
    "# files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# # --- Group files by their starting prefix (before 3rd underscore) ---\n",
    "# groups = defaultdict(list)\n",
    "# for f in files:\n",
    "#     parts = f.split('_')\n",
    "    \n",
    "#     prefix = '_'.join(parts[:5])  # e.g., dsets_dpp4_count\n",
    "    \n",
    "#     if 'ood' not in f:\n",
    "#         groups[prefix].append(f)\n",
    "    \n",
    "#     prefix_ = '_'.join(parts[:3])\n",
    "#     if prefix_ in prefix and 'ood' in f:\n",
    "#         groups[prefix].append(f)\n",
    "\n",
    "# # --- Process each group ---\n",
    "# for prefix, group_files in groups.items():\n",
    "#     save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined_all.pdf\")\n",
    "    \n",
    "#     # if \"dpp4_bit\" in save_path:\n",
    "#     #     continue\n",
    "#     # --- Skip if already exists ---\n",
    "#     if os.path.exists(save_path):\n",
    "#         print(f\"⏩ {save_path} already exists. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "#     all_embeddings = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for f in group_files:\n",
    "#         file_path = os.path.join(tsne_dir, f)\n",
    "        \n",
    "#         if len(group_files) != 5:\n",
    "#             print('group_files ', len(group_files))\n",
    "#             continue\n",
    "#         #####\n",
    "#         # if 'ood' in file_path:\n",
    "#         #     continue\n",
    "        \n",
    "#         # if 'train' not in file_path and 'context' not in file_path:\n",
    "#         #     continue\n",
    "#         #####\n",
    "        \n",
    "#         data = np.load(file_path)\n",
    "        \n",
    "#         embeddings = data['embeddings']\n",
    "#         labels = data['labels']\n",
    "\n",
    "#         print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}\")\n",
    "\n",
    "#         all_embeddings.append(embeddings)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "#     if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Concatenate all\n",
    "#     all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     print(f\"✅ Combined embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "#     # --- Run t-SNE ---\n",
    "#     # if gpu_available:\n",
    "#     #     embeddings_gpu = cp.asarray(all_embeddings)\n",
    "#     #     tsne = cuTSNE(n_components=2, random_state=42)\n",
    "#     #     embeddings_2d_gpu = tsne.fit_transform(embeddings_gpu)\n",
    "#     #     embeddings_2d = cp.asnumpy(embeddings_2d_gpu)\n",
    "#     # else:\n",
    "#     tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "#     embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "#     # --- Plot ---\n",
    "#     import matplotlib.patches as mpatches\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Set global font\n",
    "#     plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "#     plt.rcParams['font.size'] = 10\n",
    "\n",
    "#     # --- t-SNE Scatter Plot with Nice Legend and Slight Grid ---\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     # Define color mapping\n",
    "#     color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD', 3:'#48b33c', 4:'#3cadb3'}  # orange and blue\n",
    "#     colors = [color_map[label] for label in all_labels]\n",
    "\n",
    "#     # Set point sizes\n",
    "#     sizes = [40 if label == 1 else 15 for label in all_labels]\n",
    "\n",
    "#     # Scatter plot\n",
    "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, s=sizes, alpha=0.8)\n",
    "\n",
    "#     # Slight soft grid\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "#     # Hide axis labels but keep grid\n",
    "#     plt.gca().set_xticklabels([])\n",
    "#     plt.gca().set_yticklabels([])\n",
    "#     plt.xlabel(\"\")\n",
    "#     plt.ylabel(\"\")\n",
    "#     plt.box(False)\n",
    "\n",
    "#     # --- Add better legend ---\n",
    "#     import matplotlib.lines as mlines\n",
    "\n",
    "#     # Define custom legend handles (use Line2D for circles)\n",
    "#     orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "#     blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "#     red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "#     green_circle = mlines.Line2D([], [], color='#48b33c', marker='o', linestyle='None', markersize=8, label='OOD1')\n",
    "#     bluegreen_circle = mlines.Line2D([], [], color='#3cadb3', marker='o', linestyle='None', markersize=8, label='OOD2')\n",
    "\n",
    "#     # Add legend inside plot (upper right)\n",
    "#     plt.legend(handles=[orange_circle, blue_circle, red_circle, green_circle, bluegreen_circle],\n",
    "#             loc='upper right',  # inside the plot, top right\n",
    "#             framealpha=0.6,\n",
    "#             prop={'size': 12},\n",
    "#             handletextpad=0.4,\n",
    "#             borderpad=0.5)\n",
    "\n",
    "#     # Tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save figure\n",
    "#     plt.savefig(save_path, dpi=300)\n",
    "#     print(f\"✅ Saved t-SNE scatter plot with nice legend to {save_path}\")\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO change path\n",
      "⚠️ cuML not available, falling back to CPU openTSNE\n",
      "\n",
      "🚀 Processing group strans_nk1_bit_10_100\n",
      "✅ Loaded strans_nk1_bit_10_100_context_none.npz: embeddings (1000, 32), labels (1000,), losses (1000,)\n",
      "✅ Loaded strans_nk1_bit_10_100_train_context.npz: embeddings (1000, 32), labels (1000,), losses (1000,)\n",
      "✅ Loaded strans_nk1_bit_10_100_train_none.npz: embeddings (10, 32), labels (10,), losses (10,)\n",
      "✅ Loaded strans_nk1_bit_500_10_ood1_none.npz: embeddings (500, 32), labels (500,), losses (500,)\n",
      "✅ Loaded strans_nk1_bit_500_10_ood2_none.npz: embeddings (500, 32), labels (500,), losses (500,)\n",
      "✅ Combined embeddings shape: (3010, 32), labels shape: (3010,), losses shape: (3010,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_586647/4238003690.py:101: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved clean t-SNE plot for OOD3 to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_100_tsne_combined_ood3.pdf\n",
      "📈 Loss statistics for OOD3:\n",
      "  Mean   : 1.849176\n",
      "  Variance: 4.449352\n",
      "  Median : 1.019940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_586647/4238003690.py:101: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap('viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved clean t-SNE plot for OOD4 to /c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/strans_nk1_bit_10_100_tsne_combined_ood4.pdf\n",
      "📈 Loss statistics for OOD4:\n",
      "  Mean   : 1.242078\n",
      "  Variance: 2.314384\n",
      "  Median : 0.562863\n"
     ]
    }
   ],
   "source": [
    "print('TODO change path')\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from openTSNE import TSNE as cpuTSNE\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "print(\"⚠️ cuML not available, falling back to CPU openTSNE\")\n",
    "\n",
    "# --- Global matplotlib settings ---\n",
    "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 13\n",
    "mpl.rcParams['xtick.labelsize'] = 10\n",
    "mpl.rcParams['ytick.labelsize'] = 10\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['figure.titlesize'] = 16\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "mpl.rcParams['legend.title_fontsize'] = 13\n",
    "mpl.rcParams['grid.alpha'] = 0.3\n",
    "mpl.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "# --- Set your directory ---\n",
    "tsne_dir = '/c2/jinakim/Drug_Discovery_j/analysis/tsne_last_REAL2_mNctFalse_RYV1_MIXUP/lastlayer_ours_best_/'\n",
    "\n",
    "# List all .npz files\n",
    "files = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.npz')])\n",
    "\n",
    "# --- Group files manually ---\n",
    "groups = defaultdict(list)\n",
    "for f in files:\n",
    "    if 'strans_nk1_bit_10_100' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "    elif 'strans_nk1_bit_500_10_ood1' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "    elif 'strans_nk1_bit_500_10_ood2' in f:\n",
    "        groups['strans_nk1_bit_10_100'].append(f)\n",
    "\n",
    "# --- Process each group ---\n",
    "for prefix, group_files in groups.items():\n",
    "    base_save_path = os.path.join(tsne_dir, f\"{prefix}_tsne_combined\")\n",
    "\n",
    "    print(f\"\\n🚀 Processing group {prefix}\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    all_losses = []\n",
    "\n",
    "    for f in group_files:\n",
    "        file_path = os.path.join(tsne_dir, f)\n",
    "\n",
    "        if len(group_files) != 5:\n",
    "            print('⚠️ Skipping group_files', len(group_files))\n",
    "            continue\n",
    "\n",
    "        data = np.load(file_path)\n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "        losses = data['losses']\n",
    "\n",
    "        print(f\"✅ Loaded {f}: embeddings {embeddings.shape}, labels {labels.shape}, losses {losses.shape}\")\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(labels)\n",
    "        all_losses.append(losses)\n",
    "\n",
    "    if len(all_embeddings) == 0 or len(all_labels) == 0:\n",
    "        continue\n",
    "\n",
    "    # Concatenate all\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_losses = np.concatenate(all_losses, axis=0)\n",
    "\n",
    "    print(f\"✅ Combined embeddings shape: {all_embeddings.shape}, labels shape: {all_labels.shape}, losses shape: {all_losses.shape}\")\n",
    "\n",
    "    # --- Run t-SNE ---\n",
    "    tsne = cpuTSNE(n_components=2, n_jobs=8, random_state=42)\n",
    "    embeddings_2d = tsne.fit(all_embeddings)\n",
    "\n",
    "    # --- Fixed normal class colors ---\n",
    "    fixed_color_map = {0: '#ffb347', 1: '#0000CD', -1: '#DDA0DD'}\n",
    "\n",
    "    # --- Function to plot each OOD separately ---\n",
    "    def plot_one_ood(ood_mask, ood_label):\n",
    "        if not np.any(ood_mask):\n",
    "            print(f\"⚠️ No OOD{ood_label} points to plot.\")\n",
    "            return\n",
    "\n",
    "        losses_ood = all_losses[ood_mask]\n",
    "        upper_clip = np.percentile(losses_ood, 95)\n",
    "        norm = mcolors.Normalize(vmin=losses_ood.min(), vmax=upper_clip)\n",
    "        cmap = cm.get_cmap('viridis')\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "        # --- Prepare points ---\n",
    "        colors = []\n",
    "        alphas = []\n",
    "        sizes = []\n",
    "\n",
    "        for label, loss in zip(all_labels, all_losses):\n",
    "            if label in fixed_color_map:\n",
    "                colors.append(fixed_color_map[label])\n",
    "                alphas.append(0.4)  # lighter background\n",
    "                sizes.append(20 if label in [0, -1] else 40)\n",
    "            elif label == ood_label:\n",
    "                clipped_loss = min(loss, upper_clip)\n",
    "                colors.append(cmap(norm(clipped_loss)))\n",
    "                alphas.append(1.0)\n",
    "                sizes.append(30)\n",
    "            else:\n",
    "                colors.append(None)\n",
    "                alphas.append(None)\n",
    "                sizes.append(None)\n",
    "\n",
    "        # --- Plot OOD points first for colorbar ---\n",
    "        ood_coords = []\n",
    "        ood_colors = []\n",
    "        for i in range(len(embeddings_2d)):\n",
    "            if all_labels[i] == ood_label:\n",
    "                ood_coords.append(embeddings_2d[i])\n",
    "                clipped_loss = min(all_losses[i], upper_clip)\n",
    "                ood_colors.append(clipped_loss)\n",
    "\n",
    "        if ood_coords:\n",
    "            ood_coords = np.array(ood_coords)\n",
    "            ood_colors = np.array(ood_colors)\n",
    "\n",
    "            scatter = plt.scatter(ood_coords[:, 0], ood_coords[:, 1],\n",
    "                                  c=ood_colors, cmap=cmap, norm=norm, s=30, alpha=1.0)\n",
    "\n",
    "        # --- Plot normal points ---\n",
    "        for i in range(len(embeddings_2d)):\n",
    "            if colors[i] is None or all_labels[i] == ood_label:\n",
    "                continue\n",
    "            plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1],\n",
    "                        color=colors[i], s=sizes[i], alpha=alphas[i])\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_xticklabels([])\n",
    "        plt.gca().set_yticklabels([])\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.box(False)\n",
    "\n",
    "        # --- Legend ---\n",
    "        orange_circle = mlines.Line2D([], [], color='#ffb347', marker='o', linestyle='None', markersize=8, label='ours')\n",
    "        blue_circle = mlines.Line2D([], [], color='#0000CD', marker='o', linestyle='None', markersize=8, label='ours (w/o context)')\n",
    "        red_circle = mlines.Line2D([], [], color='#DDA0DD', marker='o', linestyle='None', markersize=8, label='ours (context)')\n",
    "\n",
    "        plt.legend(handles=[orange_circle, blue_circle, red_circle],\n",
    "                   loc='upper right',\n",
    "                   framealpha=0.6,\n",
    "                   prop={'size': 11},\n",
    "                   handletextpad=0.4,\n",
    "                   borderpad=0.5)\n",
    "\n",
    "        # --- Prettier colorbar ---\n",
    "        if ood_coords.size > 0:\n",
    "            cbar = plt.colorbar(scatter, shrink=0.65, pad=0.01, aspect=35)\n",
    "            cbar.set_label('Out-Of-Distribution Loss Value', fontsize=13, weight='bold', labelpad=8)\n",
    "            cbar.outline.set_visible(False)  # no outer box\n",
    "            cbar.ax.tick_params(labelsize=9, width=0.5, length=3)  # slim ticks\n",
    "            if losses_ood.max() > 10:\n",
    "                cbar.ax.yaxis.set_major_formatter(FormatStrFormatter('%.1e'))\n",
    "\n",
    "        # --- Title and layout ---\n",
    "        plt.title(f'TSNE Plot - OOD{ood_label}', fontsize=16, weight='bold', pad=15)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        final_save_path = f\"{base_save_path}_ood{ood_label}.pdf\"\n",
    "        plt.savefig(final_save_path, dpi=300)\n",
    "        print(f\"✅ Saved clean t-SNE plot for OOD{ood_label} to {final_save_path}\")\n",
    "        plt.close()\n",
    "\n",
    "        # --- Loss statistics ---\n",
    "        mean_loss = losses_ood.mean()\n",
    "        var_loss = losses_ood.var(ddof=0)  # use ddof=0 for population variance\n",
    "        median_loss = np.median(losses_ood)\n",
    "\n",
    "        print(f\"📈 Loss statistics for OOD{ood_label}:\")\n",
    "        print(f\"  Mean   : {mean_loss:.6f}\")\n",
    "        print(f\"  Variance: {var_loss:.6f}\")\n",
    "        print(f\"  Median : {median_loss:.6f}\")\n",
    "\n",
    "    # --- Plot separately for OOD1 and OOD2 ---\n",
    "    ood1_mask = (all_labels == 3)\n",
    "    ood2_mask = (all_labels == 4)\n",
    "\n",
    "    plot_one_ood(ood1_mask, ood_label=3)\n",
    "    plot_one_ood(ood2_mask, ood_label=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
