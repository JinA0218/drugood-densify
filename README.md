# Robust Molecular Property Prediction via Densifying Scarce Labeled Data

Official implementation of **[_Robust Molecular Property Prediction via Densifying Scarce Labeled Data_](https://openreview.net/forum?id=UF3Iq9cd3W) [[arXiv]](https://arxiv.org/abs/2506.11877)**.

> üè´ [Jina Kim*](https://jina0218.github.io/), üè´ [Jeffery Willette*](https://jeffwillette.github.io/), üè´ [Bruno Andreis*](https://andreisbruno.github.io/), ü§ñ [Sung Ju Hwang](http://www.sungjuhwang.com/)  
> *Equal contribution  
> üè´ [KAIST](https://www.kaist.ac.kr/en/), ü§ñ [DeepAuto.ai](http://deepauto.ai/)  
> üìç Accepted at [GenBio Workshop @ ICML 2025](https://genbio-workshop.github.io/2025/)


## üß¨ Overview

![Concept Figure](doc/concept_figure.png)

We address the challenge of molecular property prediction under **covariate shift**‚Äîa major obstacle in real-world drug discovery. Our method improves generalization to **out-of-distribution (OOD)** molecules by **densifying scarce labeled data** through the use of **domain-informed unlabeled data** and a **meta-learning framework with bilevel optimization**.


## üßæ Abstract

A widely recognized limitation of molecular prediction models is their reliance on structures observed in the training data, resulting in poor generalization to out-of-distribution compounds. Yet in drug discovery, the compounds most critical for advancing research often lie beyond the training set, making the bias toward the training data particularly problematic. This mismatch introduces substantial **covariate shift**, under which standard deep learning models produce unstable and inaccurate predictions. Furthermore, the scarcity of labeled data‚Äîstemming from the onerous and costly nature of experimental validation‚Äîfurther exacerbates the difficulty of achieving reliable generalization. To address these limitations, we propose a novel **meta-learning-based approach** that leverages **unlabeled data** to interpolate between in-distribution (ID) and out-of-distribution (OOD) data, enabling the model to meta-learn how to generalize beyond the training distribution. We demonstrate significant performance gains over state-of-the-art methods on challenging real-world datasets that exhibit substantial covariate shift.


## üìä Results

![Merck Results](doc/merck_result.png)

We benchmark our method on the [Merck Molecular Activity Challenge (Merck)](https://www.kaggle.com/c/MerckActivity/data), which contains 15 datasets exhibiting real-world **covariate shifts** in molecular property prediction. Following [Q-SAVI](https://proceedings.mlr.press/v202/klarner23a/klarner23a.pdf), we focus on the three most challenging targets: **HIVPROT**, **DPP4**, and **NK1**, each evaluated using both **count vector** and **bit vector** molecular encodings.

Our model achieves **up to 65% reduction in mean squared error (MSE)** over strong baselines on the HIVPROT dataset‚Äîone of the most difficult OOD generalization settings‚Äîhighlighting its **robustness to distributional shift**.

> üìå Detailed implementation notes for Mixup and Manifold Mixup variants are available in **Appendix A.1**.


## üåÄ t-SNE Analysis

![t-SNE Visualization](doc/tsne.png)

We visualize the learned feature representations using **t-SNE** to qualitatively assess generalization under covariate shift.

- **Ours** produces well-separated clusters for in-distribution, context, and OOD samples, indicating **clear structure** and **robust latent features**.
- In contrast, **Mixup (w/ outlier exposure)** and **Manifold Mixup (w/ bilevel optim.)** exhibit overlapping clusters, suggesting degraded OOD discrimination and less effective generalization.

## üß© Key Contributions

- **Context-Guided Interpolation**: We introduce a learnable set function (e.g., DeepSets or Set Transformer) that interpolates labeled training data with unlabeled external context points to improve representation quality.

- **Bilevel Optimization**: We employ a meta-learning framework where interpolation is guided by a meta-validation loss with pseudo-labels, enabling better generalization to unseen distributions.

- **Effective Densification**: Our approach densifies sparse regions of the training distribution by leveraging unlabeled molecules to learn more robust and structured latent representations.

- **Robust OOD Generalization**: Our method consistently outperforms state-of-the-art baselines on the Merck Molecular Activity Challenge, demonstrating strong resilience under significant covariate shift.


## üîÅ How to reproduce

### 1. üõ† Installation

Clone the repository and install the required Python packages:

```sh
git clone https://github.com/JinA0218/drugood-densify.git
cd drugood-densify
pip install -r requirements.txt
```

### 2. üß™ Merck Experiment (Table 1)

| Model Variant                          | Hyperparameter Tuning Script Path                                                   | Test Result Script Path                                               |
|----------------------------------------|--------------------------------------------------------------------------------------|------------------------------------------------------------------------|
| **Ours (Deepsets)**                    | `scripts/hyper_tuning/cmixer_dsets_hp_sweep_final_n_mvalid.sh`                      | `scripts/final_report/final_n_mvalid_ours.sh`                         |
| **Ours (Set Trans.)**                  | `scripts/hyper_tuning/cmixer_strans_hp_sweep_final_n_mvalid.sh`                     | `scripts/final_report/final_n_mvalid_ours.sh`                         |
| **Mixup**                              | `scripts/hyper_tuning/cmixer_dsets_hp_sweep_final_n_mvalid_mixup.sh`                | `scripts/hyper_tuning/final_n_mvalid_mixup.sh`                        |
| **Mixup (w/ outlier exposure)**        | `scripts/hyper_tuning/cmixer_dsets_hp_sweep_final_n_mvalid_mixup_bilevel.sh`        | `scripts/hyper_tuning/final_n_mvalid_mixup_bilevel.sh`               |
| **Manifold Mixup**                     | `scripts/hyper_tuning/cmixer_dsets_hp_sweep_final_n_mvalid_manmixup.sh`             | `scripts/hyper_tuning/final_n_mvalid_manmixup.sh`                    |
| **Manifold Mixup (w/ bilevel)**        | `scripts/hyper_tuning/cmixer_dsets_hp_sweep_final_n_mvalid_manmixup_bilevel.sh`     | `scripts/hyper_tuning/final_n_mvalid_manmixup_bilevel.sh`            |

> üîß Implementation details for Mixup and Manifold Mixup variants are provided in **Appendix A.1**.  
> üîç Hyperparameter search ranges are defined in the files located under `src/model/`, and the specific values used in our experiments are described in **Appendix A.3**.


### 3. üß™ Ablation Study (Table 2)

| Model Variant                                | Hyperparameter Tuning Script Path                                                   | Test Result Script Path                                                           |
|---------------------------------------------|--------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|
| **Ours (Deepsets)**, `‚úì ctx`, `‚úó bilevel`, `rand` | `scripts/hyper_tuning/cmixer_dsets_strans_hp_sweep_final_n_mvalid_no_bilevel.sh`    | `scripts/final_report/final_n_mvalid_ours_no_bilevel.sh`                          |
| **Ours (Set Trans.)**, `‚úì ctx`, `‚úó bilevel`, `rand` | `scripts/hyper_tuning/cmixer_dsets_strans_hp_sweep_final_n_mvalid_no_bilevel.sh`    | `scripts/final_report/final_n_mvalid_ours_no_bilevel.sh`                          |
| **Ours (MLP)**, `‚úó ctx`, `‚úó bilevel`, `rand`       | `scripts/hyper_tuning/cmixer_dsets_hp_sweep_final_n_mvalid_mlp.sh`                   | `scripts/final_report/final_n_mvalid_ours_mlp.sh`                                 |
| **Ours (Deepsets)**, `‚úì ctx`, `‚úì bilevel`, `real`  | `scripts/hyper_tuning/cmixer_dsets_strans_hp_sweep_final_n_mvalid_realy.sh`          | `scripts/final_report/final_n_mvalid_ours_realy.sh`                               |
| **Ours (Set Trans.)**, `‚úì ctx`, `‚úì bilevel`, `real`| `scripts/hyper_tuning/cmixer_dsets_strans_hp_sweep_final_n_mvalid_realy.sh`          | `scripts/final_report/final_n_mvalid_ours_realy.sh`                               |

> üîß Implementation details for each ablation study variant are provided in **Appendix A.2**.  
> üîç Hyperparameter search ranges are defined in the files located under `src/model/`, and the specific values used in our experiments can be found in **Appendix A.3**.


### 4. üìâ t-SNE Visualization

Scripts for generating t-SNE visualizations are located in `scripts/plot_tsne/`:

- **(a) Ours**: [`test_context_lastlayer_random_y_mNctFalse.ipynb`](scripts/plot_tsne/test_context_lastlayer_random_y_mNctFalse.ipynb)  
- **(b) Mixup (w/ outlier exposure)**: [`test_context_lastlayer_random_y_mNctFalse_MIXUP_BILEVEL.ipynb`](scripts/plot_tsne/test_context_lastlayer_random_y_mNctFalse_MIXUP_BILEVEL.ipynb)  
- **(c) Manifold Mixup (w/ bilevel optimization)**: [`test_context_lastlayer_random_y_mNctFalse_MANMIXUP_BILEVEL.ipynb`](scripts/plot_tsne/test_context_lastlayer_random_y_mNctFalse_MANMIXUP_BILEVEL.ipynb)

To save the corresponding model checkpoints for visualization, set `SAVE_TSNE_MODEL=1` in the following training scripts:

- **(a) Ours**: `scripts/final_report/final_n_mvalid_ours.sh`  
- **(b) Mixup (w/ outlier exposure)**: `scripts/final_report/final_n_mvalid_mixup.sh`  
- **(c) Manifold Mixup (w/ bilevel optimization)**: `scripts/final_report/final_n_mvalid_manmixup.sh`

Example model checkpoint directories:

- **(a) Ours**: `tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue/`  
- **(b) Mixup (w/ outlier exposure)**: `tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MIXUP_BILEVEL/`  
- **(c) Manifold Mixup (w/ bilevel optimization)**: `tsne_model/tsne_model2_mNctFalse_RYV1_mixTrue_MANIFOLD_MIXUP_BILEVEL/`


## üìö Citation

```BibTeX
@misc{kim2025robustmolecularpropertyprediction,
      title={Robust Molecular Property Prediction via Densifying Scarce Labeled Data}, 
      author={Jina Kim and Jeffrey Willette and Bruno Andreis and Sung Ju Hwang},
      year={2025},
      eprint={2506.11877},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.11877}, 
}
```